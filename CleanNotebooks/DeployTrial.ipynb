{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface_hub==0.23.2\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.23.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub==0.23.2) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.23.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub==0.23.2) (2020.6.20)\n",
      "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.24.6\n",
      "    Uninstalling huggingface-hub-0.24.6:\n",
      "      Successfully uninstalled huggingface-hub-0.24.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U peft\n",
    "!pip install -q -U trl\n",
    "!pip install -q -U accelerate\n",
    "!pip install -q -U transformers\n",
    "%pip  install huggingface_hub==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: huggingface_hub: command not found\n"
     ]
    }
   ],
   "source": [
    "!huggingface_hub --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mhello\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from termcolor import colored\n",
    "\n",
    "def printt(strr, color='red',  attrs=['bold']):\n",
    "    print(colored(strr, color, attrs=attrs))\n",
    "printt('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Merged FT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8218b90228a047578f6d827006f31b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    # load_in_4bit=True,\n",
    "    # bnb_4bit_use_double_quant=True,\n",
    "    # bnb_4bit_quant_type=\"nf4\",\n",
    "    # bnb_4bit_compute_dtype=torch.bfloat16#/////////////////////////////this line is crucial \n",
    "    # llm_int8_enable_fp32_cpu_offload=True,  # Enable offloading to CPU\n",
    "    load_in_8bit=True\n",
    ")\n",
    "# Define the local cache directory\n",
    "cache_dir = './my_local_cache'\n",
    "\n",
    "model_id = \"google/gemma-2-27b-it\"#\"google/gemma-2-27b-it\"#\"YoussefPearls/gemma2_27_ppe_merged\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, cache_dir =cache_dir, device_map=\"cuda\" , torch_dtype=torch.bfloat16)#torch_dtype=torch.bfloat16,, quantization_config=bnb_config , device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Move model to appropriate device WORKS FOR GEMMA 27B takes ~3min\u001b[39;00m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/big_modeling.py:457\u001b[0m, in \u001b[0;36mdispatch_model.<locals>.add_warning.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt move a model that has some modules offloaded to cpu or disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:2883\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2881\u001b[0m \u001b[38;5;66;03m# Checks if the model has been loaded in 8-bit\u001b[39;00m\n\u001b[1;32m   2882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2884\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2885\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2886\u001b[0m     )\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mGPTQ:\n\u001b[1;32m   2888\u001b[0m     \u001b[38;5;66;03m# For GPTQ models, we prevent users from casting the model to another dytpe to restrict unwanted behaviours.\u001b[39;00m\n\u001b[1;32m   2889\u001b[0m     \u001b[38;5;66;03m# the correct API should be to load the model with the desired dtype directly through `from_pretrained`.\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m     dtype_present_in_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: `.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the model has already been set to the correct devices and casted to the correct `dtype`."
     ]
    }
   ],
   "source": [
    "# Move model to appropriate device WORKS FOR GEMMA 27B takes ~3min\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer_dragon = AutoTokenizer.from_pretrained('facebook/dragon-plus-query-encoder')\n",
    "query_encoder = AutoModel.from_pretrained('facebook/dragon-plus-query-encoder').to(device)\n",
    "context_encoder = AutoModel.from_pretrained('facebook/dragon-plus-context-encoder').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer_dragon_RoBERTa = AutoTokenizer.from_pretrained('facebook/dragon-roberta-query-encoder')\n",
    "query_encoder_RoBERTa = AutoModel.from_pretrained('facebook/dragon-roberta-query-encoder').to(device)\n",
    "context_encoder_RoBERTa = AutoModel.from_pretrained('facebook/dragon-roberta-context-encoder').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Opening JSON file\n",
    "# f = open(r'/notebooks/MetadataFinal_Textual.json')\n",
    "\n",
    "# # returns JSON object as \n",
    "# # a dictionary\n",
    "# text_data = json.load(f)\n",
    "# text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Employers and employees must adhere to a comprehensive list of safety regulations and standards, including Saudi Labor Law, Modon Safety guidelines, SASO standards, and various ISO and ANSI regulations. These cover personal protective equipment like helmets, shoes, eye and face protectors, and hand protection, ensuring safety in work environments. The standards span numerous specific regulations (e.g., SASO3001, ANSI Z87.1, ASTM D120), emphasizing the importance of compliance with occupational safety and health guidelines to prevent workplace injuries and hazards.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_data[0]['sections'][0]['summarized_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['employers employees shall adhere saudi labor law modon safety occupational health guidelines saso3001 occupational safety health procedures work environment safety helmet saso guide occupational safety health – safety shoes saso2992 occupational safety health procedures work environment safety shoes saso technical regulation personal protective equipment clothing saso 1938 personal eye protection – mesh eya face protectors saso 174 saso 207 saso 208 saso 379 saso 1731 saso guide occupational safety health – hand protection saso3000 occupational safety health procedures work environment protect hands niosh iso 4850 ansi / isea z87. 1 – 2010 ansi z87. 1 – 2003 ansi z87. 1 – 1989 ( r – 1998 ) ansi / compressed gas association commodity specification air g – 7. 1 – 1989 ansi z89. 1 – 2009 ansi z89. 1 – 2003 ansi z89. 1 – 1997 ansi z41 – 1999 ansi z41 – 1991 astm f – 2412 – 2005 astm d120 – 09 astm d178 – 01 ( 2010 ) astm d1048 – 12 astm d1049 – 98 ( 2010 ) astm d1050 – 05 ( 2011 ) astm d10',\n",
       " '##2 – 2005 astm d120 – 09 astm d178 – 01 ( 2010 ) astm d1048 – 12 astm d1049 – 98 ( 2010 ) astm d1050 – 05 ( 2011 ) astm d1051 – 08 astm f1236 – 96 ( 2012 ) astm f819 – 10 gso iso 20344 gso iso20346 gso iso347 iso21420 iso13997 iso15388 iso374 iso21420iso11393 saso iso 11612 is014116 iso710 iso3873 iso20471 iso16321 iso19734 iso4007iso12312 iso18527 iso12401iso20471iso14116 iso150225 iso11611 iec6182 iec61482 en166 en149 en13034 en13758 iso11393 iso13998 iso27065 en352 iso4869 en60903 en60903 iso21420 iec61482 iso15797 iso20471 as / nfs13371 directive 89 / 686 / eecand',\n",
       " '##065 en352 iso4869 en60903 en60903 iso21420 iec61482 iso15797 iso20471 as / nfs13371 directive 89 / 686 / eecand occupational safety health regulations issued kingdom stipulate need use personal protective equipment',\n",
       " 'application ( 1 ) protective equipment including personal protective equipment eyes face head extremities protective clothing respiratory devices protective shields barriers shall provided used maintained sanitary reliable condition wherever necessary reason hazards processes environment chemical hazards radiological hazards mechanical irritants encountered manner capable causing injury impairment function part body absorption inhalation physical contact',\n",
       " 'employeeowned equipment ( 1 ) employees provide protective equipment employer shall responsible assure adequacy including proper maintenance sanitation equipment ( 2 ) worker shall use preserve personal protective equipment designated process shall carry instructions established protect health injuries diseases shall refrain action omission may lead failure implement instructions misuse impair devices provided protect workplace well health safety fellow workers per saudi labor law article 124.',\n",
       " 'design personal protective equipment shall safe design construction work performed',\n",
       " 'hazard assessment equipment selection ( 1 ) employer shall assess workplace determine hazards present likely present necessitate use personal protective equipment ( ppe ) hazards present likely present employer shall ( i ) select affected employee use types ppe protect affected employee hazards identified hazard assessment ( ii ) communicate selection decisions affected employee ( iii ) select ppe properly fits affected employee ( 2 ) employer shall verify required workplace hazard assessment performed written certification identifies workplace evaluated person certifying evaluation performed date ( s ) hazard assessment identifies document certification hazard assessment ( 3 ) employer shall inform worker prior engaging work hazards job shall require use prescribed protective equipment employer shall supply workers appropriate personal gear train useas per saudi labor law article 123.',\n",
       " 'defective damaged equipment defective damaged personal protective equipment shall used',\n",
       " 'training ( 1 ) employer shall provide training employee required section use ppe employee shall trained know least following ( i ) ppe necessary ( ii ) ppe necessary ( iii ) properly doff adjust wear ppe ( iv ) limitations ppe ( v ) proper care maintenance useful life disposal ppe ( 2 ) affected employee shall demonstrate understanding training specified paragraph ( f ) ( 1 ) section ability use ppe properly allowed perform work requiring use ppe ( 3 ) employer reason believe affected employee already trained understanding skill required paragraph ( f ) ( 2 ) section employer shall retrain employee circumstances retraining required include limited situations ( i ) changes workplace render previous training obsolete ( ii ) changes types ppe used render previous training obsolete ( iii ) inadequacies affected employees knowledge use assigned ppe indicate employee retained requisite understanding skill',\n",
       " 'general requirements ( 1 ) appropriate eye protection shall worn performing following tasks ( i ) using type adhesives and / or solvent solutions ( ii ) grinding leveling concrete surfaces ( iii ) working environments containing gases ( iv ) handling chemical materials ( v ) performing operations generate dust ( 2 ) employer shall provide means equipment prevent bad vision protect hazing ( saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ) ( 3 ) employer shall ensure affected employee uses eye protection provides side protection hazard flying objects detachable side protectors ( eg clipon slideon side shields ) meeting pertinent requirements section acceptable ( 4 ) employer shall ensure affected employee wears prescription lenses engaged operations involve eye hazards wears eye protection incorporates prescription design wears eye protection worn prescription lenses without disturbing proper position prescription lenses protective lenses ( 5 ) eye face ppe shall distinctly marked facilitate identification manufacturer ( 6 ) employer shall ensure affected employee uses equipment filter lenses shade number appropriate work performed protection injurious light radiation following listing appropriate shade numbers various operations 1 filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon',\n",
       " 'filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon arc welding operations plate thickness inches plate thickness mm minimum protective shade gas welding light 1 / 8 3. 2 4 medium 1 / 8 ½ 3. 2 12. 7 5 heavy ½ 12. 7 6 oxygen cutting light 1 25 3 medium 1 6 25 150 4 heavy 6 150 5 details found sasoen1938 personal eye protection – mesh eya face protectors saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ansi / isea z87. 1 – 2010 ansi z87. 1 – 2003 ansi z87. 1 – 1989 ( r – 1998 ) directive 89 / 686 / eec as / nfs1337. 1.',\n",
       " 'criteria protective eye face protection ( 1 ) protective eye face protection devices must comply relevant consensus standards following ( i ) saso technical regulation personal protective equipment clothing ( ii ) saso 1938 personal eye protection – mesh eya face protectors ( iii ) saso 4850 ( iso 4850 ) saso 174 saso 207 saso 208 saso 379 saso 1731 equivalent ( iv ) ansi / isea z87. 1 – 2010 occupational educational personal eye face protection devices ( v ) ansi z87. 1 – 2003 occupational educational personal eye face protection devices ( vi ) ansi z87. 1 – 1989 ( r – 1998 ) practice occupational educational eye face protection ( 2 ) protective eye face protection devices employer demonstrates least effective protective eye face protection devices constructed accordance one consensus standards deemed compliance requirements section ( 3 ) marking user must require marking product time purchase check receipt according standards used illustrated examples marking lenses frame accordance ansi 87',\n",
       " 'permissible practice ( 1 ) control occupational diseases caused breathing air contaminated harmful dusts fogs fumes mists gases smokes sprays vapours primary objective shall prevent atmospheric contamination shall accomplished far feasible accepted engineering control measures ( for example enclosure confinement operation general local ventilation substitution less toxic materials ) effective engineering controls feasible instituted appropriate respirators shall used pursuant section ( 2 ) respirator shall provided employee equipment necessary protect health employee employer shall provide respirators applicable suitable purpose intended employer shall responsible establishment maintenance respiratory protection program shall include requirements outlined paragraph ( c ) section program shall cover employee required section use respirator definitions following definitions important terms used respiratory protection standard section ( 1 ) airpurifying respirator means respirator airpurifying filter cartridge canister removes specific air contaminants passing ambient air airpurifying element ( 2 ) assigned protection factor ( apf ) means workplace level respiratory protection respirator class respirators expected provide employees employerimplements continuing effective respiratory protection program specified section ( 3 ) atmospheresupplying respirator means respirator supplies respirator user breathing air source independent ambient atmosphere includes supplied air respirators ( sars ) selfcontained breathing apparatus ( scba ) units ( 4 ) can',\n",
       " '( 3 ) atmospheresupplying respirator means respirator supplies respirator user breathing air source independent ambient atmosphere includes supplied air respirators ( sars ) selfcontained breathing apparatus ( scba ) units ( 4 ) canister cartridge means container filter sorbent catalyst combination items removes specific contaminants air passed container ( 5 ) demand respirator means atmospheresupplying respirator admits breathing air facepiece negative pressure created inside facepiece inhalation ( 6 ) emergency situation means occurrence limited equipment failure rupture containers failure control equipment may result uncontrolled significant release airborne contaminant ( 7 ) employee exposure means exposure concentration airborne contaminant would occur employee using respiratory protection ( 8 ) endofservicelife indicator ( esli ) means system warns respirator user approach end adequate respiratory protection example sorbent approaching saturation longer effective ( 9 ) escapeonly respirator means respirator intended used emergency exit ( 10 ) filter air purifying element means component used respirators remove solid liquid aerosols inspired air ( 11 ) filtering facepiece ( dust mask ) means negative pressure particulate respirator filter integral part facepiece entire facepiece composed filtering medium (',\n",
       " 'filter air purifying element means component used respirators remove solid liquid aerosols inspired air ( 11 ) filtering facepiece ( dust mask ) means negative pressure particulate respirator filter integral part facepiece entire facepiece composed filtering medium ( 12 ) fit factor means quantitative estimate fit particular respirator specific individual typically estimates ratio concentration substance ambient air concentration inside respirator worn ( 13 ) fit test means use protocol qualitatively quantitatively evaluate fit respirator individual ( see also qualitative fit test qlft quantitative fit test qnft ) ( 14 ) helmet means rigid respiratory inlet covering also provides head protection impact penetration ( 15 ) high efficiency particulate air ( hepa ) filter means filter least 99. 97 efficient removing monodisperse particles 0. 3 micrometers diameter ( 16 ) hood means respiratory inlet covering completely covers head neck may also cover portions shoulders torso ( 17 ) immediately dangerous life health ( idlh ) means atmosphere poses immediate threat life would cause irreversible adverse health effects would impair individuals ability escape dangerous atmosphere ( 18 ) interior structural firefighting means physical activity fire suppression rescue inside buildings enclosed structures involved fire situation beyond incipient stage ( 19 ) loosefitting facepiece means respiratory inlet covering designed form',\n",
       " '##ible adverse health effects would impair individuals ability escape dangerous atmosphere ( 18 ) interior structural firefighting means physical activity fire suppression rescue inside buildings enclosed structures involved fire situation beyond incipient stage ( 19 ) loosefitting facepiece means respiratory inlet covering designed form partial seal face ( 20 ) maximum use concentration ( muc ) means maximum atmospheric concentration hazardous substance employee expected protected wearing respirator determined assigned protection factor respirator class respirators exposure limit hazardous substance muc determined mathematically multiplying assigned protection factor specified respirator required permissible exposure limit shortterm exposure limit ceiling limit exposure limit available hazardous substance employer must determine muc basis relevant available information informed professional judgment ( 21 ) negative pressure respirator ( tight fitting ) means respirator air pressure inside facepiece negative inhalation respect ambient air pressure outside respirator ( 22 ) oxygen deficient atmosphere means atmosphere oxygen content 19. 5 volume ( 23 ) physician licensed health care professional ( plhcp ) means individual whose legally permitted scope practice ( ie license registration certification ) allows independently provide delegated responsibility provide health care services required paragraph ( e ) section ( 24 ) positive pressure respirator means respirator pressure inside respiratory inlet covering exceeds ambient air pressure outside respirator ( 25 ) powered',\n",
       " '( ie license registration certification ) allows independently provide delegated responsibility provide health care services required paragraph ( e ) section ( 24 ) positive pressure respirator means respirator pressure inside respiratory inlet covering exceeds ambient air pressure outside respirator ( 25 ) powered airpurifying respirator ( papr ) means airpurifying respirator uses blower force ambient air airpurifying elements inlet covering ( 26 ) pressure demand respirator means positive pressure atmospheresupplying respirator admits breathing air facepiece positive pressure reduced inside facepiece inhalation ( 27 ) qualitative fit test ( qlft ) means pass / fail fit test assess adequacy respirator fit relies individuals response test agent ( 28 ) quantitative fit test ( qnft ) means assessment adequacy respirator fit numerically measuring amount leakage respirator ( 29 ) respiratory inlet covering means portion respirator forms protective barrier users respiratory tract airpurifying device breathing air source may facepiece helmet hood suit mouthpiece respirator nose clamp ( 30 ) selfcontained breathing apparatus ( scba ) means atmospheresupplying respirator breathing air source designed carried user ( 31 ) service life means period time respirator filter sorbent',\n",
       " 'suit mouthpiece respirator nose clamp ( 30 ) selfcontained breathing apparatus ( scba ) means atmospheresupplying respirator breathing air source designed carried user ( 31 ) service life means period time respirator filter sorbent respiratory equipment provides adequate protection wearer ( 32 ) suppliedair respirator ( sar ) airline respirator means atmospheresupplying respirator source breathing air designed carried user ( 33 ) tightfitting facepiece means respiratory inlet covering forms complete seal face ( 34 ) user seal check means action conducted respirator user determine respirator properly seated face',\n",
       " 'respiratory protection program paragraph requires employer develop implement written respiratory protection program required worksitespecific procedures elements required respirator use program must administered suitably trained program administrator addition certain program elements may required voluntary use prevent potential hazards associated use respirator ( 1 ) workplace respirators necessary protect health employee whenever respirators required employer employer shall establishimplement written respiratory protection program worksitespecific procedures program shall updated necessary reflect changes workplace conditions affect respirator use employer shall include program following provisions section applicable ( i ) procedures selecting respirators use workplace ( ii ) medical evaluations employees required use respirators ( iii ) fit testing procedures tightfitting respirators ( iv ) procedures proper use respirators routine reasonably foreseeable emergency situations ( v ) procedures schedules cleaning disinfecting storing inspecting repairing discarding otherwise maintaining respirators ( vi ) procedures ensure adequate air quality quantity flow breathing air atmospheresupplying respirators ( vii ) training employees respiratory hazards potentially exposed routine emergency situations ( viii ) training employees proper use respirators including putting removing limitations use maintenance ( ix ) procedures regularly evaluating effectiveness program ( 2 ) respirator use required ( i ) employer may provide respi',\n",
       " ') training employees respiratory hazards potentially exposed routine emergency situations ( viii ) training employees proper use respirators including putting removing limitations use maintenance ( ix ) procedures regularly evaluating effectiveness program ( 2 ) respirator use required ( i ) employer may provide respirators request employees permit employees use respirators employer determines respirator use create hazard employer determines voluntary respirator use permissible employer shall provide respirator users needed information ( ii ) addition employer must establish implement elements written respiratory protection program necessary ensure employee using respirator voluntarily medically able use respirator respirator cleaned stored maintained use present health hazard user exception employers required include written respiratory protection program employees whose use respirators involves voluntary use filtering facepieces ( dust masks ) ( 3 ) employer shall designate program administrator qualified appropriate training experience commensurate complexity program administer oversee respiratory protection program conduct required evaluations program effectiveness ( 4 ) employer shall provide respirators training medical evaluations cost employee',\n",
       " 'selection respirators paragraph requires employer evaluate respiratory hazard ( s ) workplace identify relevant workplace user factors base respirator selection factors paragraph also specifies appropriately protective respirators use idlh ( immediately dangerous life health ) atmospheres limits selection use airpurifying respirators ( 1 ) general requirements ( i ) employer shall select provide appropriate respirator based respiratory hazard ( s ) worker exposed workplace user factors affect respirator performance reliability ( ii ) employer shall select nioshcertified respirator ecc certified respirator certified respirator equivalent respirator shall used compliance conditions certification ( iii ) employer shall identify evaluate respiratory hazard ( s ) workplace evaluation shall include reasonable estimate employee exposures respiratory hazard ( s ) identification contaminants chemical state physical form employer cannot identify reasonably estimate employee exposure employer shall consider atmosphere idlh ( immediately dangerous life health ) ( iv ) employer shall ensure affected employees wear appropriate respiratory devices engaging industrial activities ( a ) using type adhesives and / or solvent solutions ( b ) grinding levelling concrete surfaces ( c ) working environments containing gases ( d ) handling chemical materials ( e ) performing operations generate dust ( f ) “ msds ” safety data sheet requirements “ section8 ’ ( v ) employer shall select res',\n",
       " 'solutions ( b ) grinding levelling concrete surfaces ( c ) working environments containing gases ( d ) handling chemical materials ( e ) performing operations generate dust ( f ) “ msds ” safety data sheet requirements “ section8 ’ ( v ) employer shall select respirators sufficient number respirator models sizes respirator acceptable correctly fits user ( 2 ) respirators idlh atmospheres ( i ) employer shall provide following respirators employee use idlh atmospheres ( a ) full facepiece pressure demand scba certified niosh authorities like ec minimum service life thirty minutes ( b ) combination full facepiece pressure demand suppliedair respirator ( sar ) auxiliary selfcontained air supply ( ii ) respirators provided escape idlh atmospheres shall nioshcertified authorities like ec escape atmosphere used ( iii ) oxygendeficient atmospheres shall considered idlh exception employer demonstrates foreseeable conditions oxygen concentration maintained within ranges specified table 4 section ( ie altitudes set table ) atmospheresupplying respirator may used ( 3 ) respirators atmospheres idlh ( i ) employer shall provide respirator adequate protect health employee ( a ) assigned protection factors ( apfs ) employers must use assigned protection factors',\n",
       " 'atmospheresupplying respirator may used ( 3 ) respirators atmospheres idlh ( i ) employer shall provide respirator adequate protect health employee ( a ) assigned protection factors ( apfs ) employers must use assigned protection factors listed table 3 select respirator meets exceeds required level employee protection using combination respirator ( eg airline respirators airpurifying filter ) employers must ensure assigned protection factor appropriate mode operation respirator used type respirator quarter mask half mask full facepiece helmet / hood loose fitting facepiece1. airpurifying respirator 5 10 50 2. powered air purifying respirator ( papr ) 50 1000 25 / 1000 25 3. suppliedair respirator ( sar ) airline respirator demand mode 10 50 continuous flow mode 50 1000 25 / 1000 25 pressuredemand positive pressure mode 50 1000 4. selfcontained breathing apparatus ( scba ) demand mode 10 50 50 pressuredemand positive pressure mode ( eg open / closed circuit ) 10000 10000 ( b ) maximum use concentration ( muc ) ( 1 ) employer must select respirator employee use maintains employees exposure hazardous substance measured outside respirator muc ( 2 ) employers must apply mucs conditions immediately',\n",
       " '/ closed circuit ) 10000 10000 ( b ) maximum use concentration ( muc ) ( 1 ) employer must select respirator employee use maintains employees exposure hazardous substance measured outside respirator muc ( 2 ) employers must apply mucs conditions immediately dangerous life health ( idlh ) instead must use respirators listed idlh conditions paragraph ( d ) ( 2 ) standard ( 3 ) calculated muc exceeds idlh level hazardous substance performance limits cartridge canister employers must set maximum muc lower limit ( ii ) respirator selected shall appropriate chemical state physical form contaminant ( iii ) protection gases vapors employer shall provide ( a ) atmospheresupplying respirator ( b ) airpurifying respirator provided ( 1 ) respirator equipped endofservicelife indicator ( esli ) certified niosh authorities like ec contaminant ( 2 ) esli appropriate conditions employers workplace employer implements change schedule canisters cartridges based objective information data ensure canisters cartridges changed end service life employer shall describe respirator program information data relied upon basis canister cartridge change schedule basis reliance data ( iv ) protection particulates employer shall provide ( a ) atmospheresupplying respirator ( b ) air',\n",
       " '##s cartridges changed end service life employer shall describe respirator program information data relied upon basis canister cartridge change schedule basis reliance data ( iv ) protection particulates employer shall provide ( a ) atmospheresupplying respirator ( b ) airpurifying respirator equipped filter certified niosh equivalent authorities ( such ec ) high efficiency particulate air ( hepa ) filter airpurifying respirator equipped filter certified particulates niosh equivalent authorities ( such ec ) ( c ) contaminants consisting primarily particles mass median aerodynamic diameters ( mmad ) least 2 micrometers airpurifying respirator equipped filter certified particulates niosh equivalent authorities ( such ec ) table4 attitude ( ft ) oxygen deficient atmospheres ( o ) employer may rely atmospheresupplying respirators less 3001 16. 019. 5 30014000 16. 419. 5 40015000 17. 119. 5 50016000 17. 819. 5 60017000 18. 519. 5 70018000 19. 319. 5',\n",
       " 'medical evaluation using respirator may place physiological burden employees varies type respirator worn job workplace conditions respirator used medical status employee accordingly paragraph specifies minimum requirements medical evaluation employers must implement determine employees ability use respirator ( 1 ) general employer shall provide medical evaluation determine employees ability use respirator employee fit tested required use respirator workplace employer may discontinue employees medical evaluations employee longer required use respirator ( 2 ) medical evaluation procedures ( i ) employer shall identify physician licensed health care professional ( plhcp ) perform medical evaluations using medical questionnaire initial medical examination obtains information medical questionnaire ( ii ) medical evaluation shall obtain information requested medical questionnaire ( 3 ) followup medical examination ( i ) employer shall ensure followup medical examination provided employee gives positive response question among questions medical questionnaire whose initial medical examination demonstrates need follow medical examination ( ii ) followup medical examination shall include medical tests consultations diagnostic procedures plhcp deems necessary make final determination ( 4 ) administration medical questionnaire examinations ( i ) medical questionnaire examinations shall administered confidentially employees normal working hours time place convenient employee medical questionnaire shall administered manner ensures employee understands content ( ii ) employer shall provide employee opportunity discuss questionnaire examination results plhcp ( 5 ) supplemental information',\n",
       " 'examinations ( i ) medical questionnaire examinations shall administered confidentially employees normal working hours time place convenient employee medical questionnaire shall administered manner ensures employee understands content ( ii ) employer shall provide employee opportunity discuss questionnaire examination results plhcp ( 5 ) supplemental information plhcp ( i ) following information must provided plhcp plhcp makes recommendation concerning employees ability use respirator ( a ) type weight respirator used employee ( b ) duration frequency respirator use ( including use rescue escape ) ( c ) expected physical work effort ( d ) additional protective clothing equipment worn ( e ) temperature humidity extremes may encountered ( ii ) supplemental information provided previously plhcp regarding employee need provided subsequent medical evaluation information plhcp remain ( iii ) employer shall provide plhcp copy written respiratory protection program copy section ( 6 ) medical determination determining employees ability use respirator employer shall ( i ) obtain written recommendation regarding employees ability use respirator plhcp recommendation shall provide following information ( a ) limitations respirator use related medical condition employee relating workplace conditions respirator used including whether employee medically able use respirator ( b ) need followup medical evaluations ( c ) statement plhcp provided employee copy plhcps written recommendation ( ii ) respirator',\n",
       " 'related medical condition employee relating workplace conditions respirator used including whether employee medically able use respirator ( b ) need followup medical evaluations ( c ) statement plhcp provided employee copy plhcps written recommendation ( ii ) respirator negative pressure respirator plhcp finds medical condition may place employees health increased risk respirator used employer shall provide papr plhcps medical evaluation finds employee use respirator subsequent medical evaluation finds employee medically able use negative pressure respirator employer longer required provide papr ( 7 ) additional medical evaluations minimum employer shall provide additional medical evaluations comply requirements section ( i ) employee reports medical signs symptoms related ability use respirator ( ii ) plhcp supervisor respirator program administrator informs employer employee needs reevaluated ( iii ) information respiratory protection program including observations made fit testing program evaluation indicates need employee reevaluation ( iv ) change occurs workplace conditions ( eg physical work effort protective clothing temperature ) may result substantial increase physiological burden placed employee',\n",
       " 'fit testing paragraph requires employee may required use respirator negative positive pressure tightfitting facepiece employee must fit tested make model style size respirator used paragraph specifies kinds fit tests allowed procedures conducting results fit tests must used ( 1 ) employer shall ensure employees using tightfitting facepiece respirator pass appropriate qualitative fit test ( qlft ) quantitative fit test ( qnft ) stated paragraph ( 2 ) employer shall ensure employee using tightfitting facepiece respirator fit tested prior initial use respirator whenever different respirator facepiece ( size style model make ) used least annually thereafter ( 3 ) employer shall conduct additional fit test whenever employee reports employer plhcp supervisor program administrator makes visual observations changes employees physical condition could affect respirator fit conditions include limited facial scarring dental changes cosmetic surgery obvious change body weight ( 4 ) passing qlft qnft employee subsequently notifies employer program administrator supervisor plhcp fit respirator unacceptable employee shall given reasonable opportunity select different respirator facepiece retested ( 5 ) fit test shall administered using qlft qnft protocol ( 6 ) qlft may used fit test negative pressure airpurifying respirators must achieve fit factor 100 less ( 7 ) fit factor determined',\n",
       " 'facepiece retested ( 5 ) fit test shall administered using qlft qnft protocol ( 6 ) qlft may used fit test negative pressure airpurifying respirators must achieve fit factor 100 less ( 7 ) fit factor determined qnft protocol equal greater 100 tightfitting half facepieces equal greater 500 tightfitting full facepieces qnft passed respirator ( 8 ) fit testing tightfitting atmospheresupplying respirators tightfitting powered air purifying respirators shall accomplished performing quantitative qualitative fit testing negative pressure mode regardless mode operation ( negative positive pressure ) used respiratory protection ( i ) qualitative fit testing respirators shall accomplished temporarily converting respirator users actual facepiece negative pressure respirator appropriate filters using identical negative pressure airpurifying respirator facepiece sealing surfaces surrogate atmospheresupplying powered air purifying respirator facepiece ( ii ) quantitative fit testing respirators shall accomplished modifying facepiece allow sampling inside facepiece breathing zone user midway nose mouth requirement shall accomplished installing permanent sampling probe onto surrogate facepiece using sampling adapter designed temporarily provide means sampling air inside facepiece ( iii ) modifications respirator facepiece fit',\n",
       " 'shall accomplished modifying facepiece allow sampling inside facepiece breathing zone user midway nose mouth requirement shall accomplished installing permanent sampling probe onto surrogate facepiece using sampling adapter designed temporarily provide means sampling air inside facepiece ( iii ) modifications respirator facepiece fit testing shall completely removed facepiece restored nioshapproved configuration facepiece used workplace',\n",
       " 'use respirators paragraph requires employers establish implement procedures proper use respirators requirements include prohibiting conditions may result facepiece seal leakage preventing employees removing respirators hazardous environments taking actions ensure continued effective respirator operation throughout work shift establishing procedures use respirators idlh atmospheres interior structural firefighting situations ( 1 ) facepiece seal protection ( i ) employer shall permit respirators tightfitting facepieces worn employees ( a ) facial hair comes sealing surface facepiece face interferes valve function ( b ) condition interferes facetofacepiece seal valve function ( ii ) employee wears corrective glasses goggles personal protective equipment employer shall ensure equipment worn manner interfere seal facepiece face user ( iii ) tightfitting respirators employer shall ensure employees perform user seal check time put respirator done procedures recommended respirator manufacturer employer demonstrates effective ( 2 ) continuing respirator effectiveness ( i ) appropriate surveillance shall maintained work area conditions degree employee exposure stress change work area conditions degree employee exposure stress may affect respirator effectiveness employer shall reevaluate continued effectiveness respirator ( ii ) employer shall ensure employees leave respirator use area ( a ) wash faces respirator facepieces necessary prevent eye skin irritation associated respi',\n",
       " 'exposure stress may affect respirator effectiveness employer shall reevaluate continued effectiveness respirator ( ii ) employer shall ensure employees leave respirator use area ( a ) wash faces respirator facepieces necessary prevent eye skin irritation associated respirator use ( b ) detect vapor gas breakthrough changes breathing resistance leakage facepiece ( c ) replace respirator filter cartridge canister elements ( iii ) employee detects vapor gas breakthrough changes breathing resistance leakage facepiece employer must replace repair respirator allowing employee return work area ( 3 ) procedures idlh atmospheres idlh atmospheres employer shall ensure ( i ) one employee needed one employee located outside idlh atmosphere ( ii ) visual voice signal line communication maintained employee ( s ) idlh atmosphere employee ( s ) located outside idlh atmosphere ( iii ) employee ( s ) located outside idlh atmosphere trained equipped provide effective emergency rescue ( iv ) employer designee notified employee ( s ) located outside idlh atmosphere enter idlh atmosphere provide emergency rescue ( v ) employer designee authorized employer notified provides necessary assistance appropriate situation ( vi ) employee ( s ) located outside idlh atmospheres equipped ( a ) pressure demand positive pressure scbas pressure demand positive pressure suppliedair respirator',\n",
       " 'atmosphere provide emergency rescue ( v ) employer designee authorized employer notified provides necessary assistance appropriate situation ( vi ) employee ( s ) located outside idlh atmospheres equipped ( a ) pressure demand positive pressure scbas pressure demand positive pressure suppliedair respirator auxiliary scba either ( b ) appropriate retrieval equipment removing employee ( s ) enter ( s ) hazardous atmospheres retrieval equipment would contribute rescue employee ( s ) would increase overall risk resulting entry ( c ) equivalent means rescue retrieval equipment required paragraph ( g ) ( 3 ) ( vi ) ( b ) ( 4 ) procedures interior structural firefighting addition requirements set forth paragraph ( g ) ( 3 ) interior structural fires employer shall ensure ( i ) least two employees enter idlh atmosphere remain visual voice contact one another times ( ii ) least two employees located outside idlh atmosphere ( iii ) employees engaged interior structural firefighting use scbas',\n",
       " 'maintenance care respirators paragraph requires employer provide cleaning disinfecting storage inspection repair respirators used employees ( 1 ) cleaning disinfecting employer shall provide respirator user respirator clean sanitary good working order employer shall ensure respirators cleaned disinfected using procedures recommended respirator manufacturer provided procedures equivalent effectiveness respirators shall cleaned disinfected following intervals ( i ) respirators issued exclusive use employee shall cleaned disinfected often necessary maintained sanitary condition ( ii ) respirators issued one employee shall cleaned disinfected worn different individuals ( iii ) respirators maintained emergency use shall cleaned disinfected use ( iv ) respirators used fit testing training shall cleaned disinfected use ( 2 ) storage employer shall ensure respirators stored follows ( i ) respirators shall stored protect damage contamination dust sunlight extreme temperatures excessive moisture damaging chemicals shall packed stored prevent deformation facepiece exhalation valve ( ii ) addition requirements paragraph ( h ) ( 2 ) ( i ) section emergency respirators shall ( a ) kept accessible work area ( b ) stored compartments covers clearly marked containing emergency respirators ( c ) stored accordance applicable manufacturer instructions ( 3 )',\n",
       " 'addition requirements paragraph ( h ) ( 2 ) ( i ) section emergency respirators shall ( a ) kept accessible work area ( b ) stored compartments covers clearly marked containing emergency respirators ( c ) stored accordance applicable manufacturer instructions ( 3 ) inspection ( i ) employer shall ensure respirators inspected follows ( a ) respirators used routine situations shall inspected use cleaning ( b ) respirators maintained use emergency situations shall inspected least monthly accordance manufacturers recommendations shall checked proper function use ( c ) emergency escapeonly respirators shall inspected carried workplace use ( ii ) employer shall ensure respirator inspections include following ( a ) check respirator function tightness connections condition various parts including limited facepiece head straps valves connecting tube cartridges canisters filters ( b ) check elastomeric parts pliability signs deterioration ( iii ) addition requirements paragraphs ( h ) ( 3 ) ( i ) ( ii ) section self contained breathing apparatus shall inspected monthly air oxygen cylinders shall maintained fully charged state shall recharged pressure falls 90 manufacturers recommended pressure level employer shall determine regulator warning devices function properly ( iv ) respirators maintained emergency use employer shall ( a ) certify respirator documenting date inspection performed name ( or signature ) person',\n",
       " 'state shall recharged pressure falls 90 manufacturers recommended pressure level employer shall determine regulator warning devices function properly ( iv ) respirators maintained emergency use employer shall ( a ) certify respirator documenting date inspection performed name ( or signature ) person made inspection findings required remedial action serial number means identifying inspected respirator ( b ) provide information tag label attached storage compartment respirator kept respirator included inspection reports stored paper electronic files information shall maintained replaced following subsequent certification ( 4 ) repairs employer shall ensure respirators fail inspection otherwise found defective removed service discarded repaired adjusted accordance following procedures repairs adjustments respirators made persons appropriately trained perform operations shall use respirator manufacturers niosh approved parts designed respirator repairs shall made according manufacturers recommendations specifications type extent repairs performed reducing admission valves regulators alarms shall adjusted repaired manufacturer technician trained manufacturer ( i ) breathing air quality use paragraph requires employer provide employees using atmospheresupplying respirators ( suppliedair scba ) breathing gases high purity ( 1 ) employer shall ensure compressed air compressed oxygen liquid air liquid oxygen used respiration accords following specifications ( 2 ) compressed liquid oxygen shall meet united states pharmacopoeia requirements medical breathing oxygen compressed breathing air shall meet least requirements grade breathing air described ansi',\n",
       " ') employer shall ensure compressed air compressed oxygen liquid air liquid oxygen used respiration accords following specifications ( 2 ) compressed liquid oxygen shall meet united states pharmacopoeia requirements medical breathing oxygen compressed breathing air shall meet least requirements grade breathing air described ansi / compressed gas association commodity specification air g – 7. 1 – 1989 include ( a ) oxygen content ( v / v ) 19. 5 – 23. 5 ( b ) hydrocarbon ( condensed ) content 5 milligrams per cubic meter air less ( c ) carbon monoxide ( co ) content 10 ppm less ( d ) carbon dioxide content 1000 ppm less ( e ) lack noticeable odor ( 3 ) employer shall ensure compressed oxygen used atmospheresupplying respirators previously used compressed air ( 4 ) employer shall ensure oxygen concentrations greater 23. 5 used equipment designed oxygen service distribution ( 5 ) employer shall ensure cylinders used supply breathing air respirators meet following requirements ( i ) cylinders tested maintained ( ii ) cylinders purchased breathing air certificate analysis supplier breathing air meets requirements grade breathing air ( iii ) moisture content cylinder exceed dew point −50 °f ( −45. 6 °c ) 1 atmosphere pressure ( 6 ) employer shall ensure compressors used supply breathing air respirators constructed situated ( i )',\n",
       " 'supplier breathing air meets requirements grade breathing air ( iii ) moisture content cylinder exceed dew point −50 °f ( −45. 6 °c ) 1 atmosphere pressure ( 6 ) employer shall ensure compressors used supply breathing air respirators constructed situated ( i ) prevent entry contaminated air airsupply system ( ii ) minimize moisture content dew point 1 atmosphere pressure 10 degrees f ( 5. 56 °c ) ambient temperature ( iii ) suitable inline airpurifying sorbent beds filters ensure breathing air quality sorbent beds filters shall maintained replaced refurbished periodically following manufacturers instructions ( iv ) tag containing recent change date signature person authorized employer perform change tag shall maintained compressor ( 7 ) compressors oillubricated employer shall ensure carbon monoxide levels breathing air exceed 10 ppm ( 8 ) oillubricated compressors employer shall use hightemperature carbon monoxide alarm monitor carbon monoxide levels hightemperature alarms used air supply shall monitored intervals sufficient prevent carbon monoxide breathing air exceeding 10 ppm ( 9 ) employer shall ensure breathing air couplings incompatible outlets nonrespirable worksite air gas systems asphyxiating substance shall introduced breathing air lines ( 10 ) employer shall use respirator manufacturers nioshapproved breathinggas containers marked maintained accordance quality assurance provisions niosh',\n",
       " 'ensure breathing air couplings incompatible outlets nonrespirable worksite air gas systems asphyxiating substance shall introduced breathing air lines ( 10 ) employer shall use respirator manufacturers nioshapproved breathinggas containers marked maintained accordance quality assurance provisions niosh approval scba issued accordance niosh respirator certification standard',\n",
       " 'identification filters cartridges canisters employer shall ensure filters cartridges canisters used workplace labeled color coded niosh approval label label removed remains legible',\n",
       " 'training information paragraph requires employer provide effective training employees required use respirators training must comprehensive understandable recur annually often necessary ( 1 ) employer shall ensure employee demonstrate knowledge least following ( i ) respirator necessary improper fit usage maintenance compromise protective effect respirator ( ii ) limitations capabilities respirator ( iii ) use respirator effectively emergency situations including situations respirator malfunctions ( iv ) inspect put remove use check seals respirator ( v ) procedures maintenance storage respirator ( vi ) recognize medical signs symptoms may limit prevent effective use respirators ( vii ) general requirements section ( 2 ) training shall conducted manner understandable employee ( 3 ) employer shall provide training prior requiring employee use respirator workplace ( 4 ) employer able demonstrate new employee received training within last 12 months addresses elements specified paragraph ( j ) ( 1 ) ( i ) ( vii ) required repeat training provided required paragraph ( j ) ( 1 ) employee demonstrate knowledge element ( s ) previous training repeated initially employer must provided later 12 months date previous training ( 5 ) retraining shall administered annually following situations occur ( i ) changes workplace type respirator render previous training obsolete ( ii ) inadequacies employees knowledge use respirator indicate employee retained requisite understanding skill (',\n",
       " '12 months date previous training ( 5 ) retraining shall administered annually following situations occur ( i ) changes workplace type respirator render previous training obsolete ( ii ) inadequacies employees knowledge use respirator indicate employee retained requisite understanding skill ( iii ) situation arises retraining appears necessary ensure safe respirator use ( 6 ) basic advisory information respirators shall provided employer written oral format employees wear respirators use required section employer',\n",
       " 'program evaluation section requires employer conduct evaluations workplace ensure written respiratory protection program properly implemented consult employees ensure using respirators properly ( 1 ) employer shall conduct evaluations workplace necessary ensure provisions current written program effectively implemented continues effective ( 2 ) employer shall regularly consult employees required use respirators assess employees views program effectiveness identify problems problems identified assessment shall corrected factors assessed include limited ( i ) respirator fit ( including ability use respirator without interfering effective workplace performance ) ( ii ) appropriate respirator selection hazards employee exposed ( iii ) proper respirator use workplace conditions employee encounters ( iv ) proper respirator maintenance',\n",
       " 'recordkeeping section requires employer establish retain written information regarding medical evaluations fit testing respirator program information facilitate employee involvement respirator program assist employer auditing adequacy program ( 1 ) medical evaluation records medical evaluations required section must retained ( 2 ) fit testing ( i ) employer shall establish record qualitative quantitative fit tests administered employee including ( a ) name identification employee tested type fit test performed specific make model style size respirator tested date test pass / fail results qlfts fit factor strip chart recording recording test results qnfts ( ii ) fit test records shall retained respirator users next fit test administered ( 3 ) written copy current respirator program shall retained employer ( 4 ) written materials required retained paragraph shall made available upon request affected employees authorized authority designee examination copying',\n",
       " 'personal protective equipment used protection respiratory ( 1 ) personal protective equipment clothing designed protection respiratory shall supply user breathable fresh air upon exposure polluted air and / or insufficient oxygen concentration ( 2 ) necessary breathable air supplied user personal protective equipment shall proper mean filtration polluted air equipment unpolluted external source ( 3 ) materials components used types personal protective equipment clothing shall chosen upon designing manufacturing ensure proper breathing user fresh breathing device use ( 4 ) leakage pollutant shall low possible cause harm user case using respiratory protection devices face masks filtration devices polluted air ( 5 ) personal protective equipment clothing shall include details characteristics equipment help user qualified trained use equipment properly upon reading instructions',\n",
       " 'types respiratory protection ( 1 ) two main types respiratory protection ( niosh ec ) — airpurifying respirators ( aprs ) atmospheresupplying respirators ( asrs ) respirator type provides different level protection based design therefore it ’ s important choose right type respirator specific exposure ( 2 ) nioshapproved particulate filtering respirators classification ten classes nioshapproved particulate filtering respirators types respirators use filters remove particles air breathed n r p designations refer filter ’ s oil resistance described table filter class per niosh filter class description n95 n99 n100 filters least 95 99 99. 97 airborne particles resistant oil r95 r99 r100 filters least 95 99 99. 97 airborne particles somewhat resistant oil p95 p99 p100 filters least 95 99 99. 97 airborne particles strongly resistant oil ( high efficiency particulate air ) filters least 99. 97 airborne particles use paprs paprs use filters ( 3 ) en 149 standard defines performance requirements three classes half masks ffp1 ffp2 ffp3. protection provided ffp2 ( or ffp3 ) mask includes protection provided mask lowernumbered classes mask conforming standard must class written along',\n",
       " '( 3 ) en 149 standard defines performance requirements three classes half masks ffp1 ffp2 ffp3. protection provided ffp2 ( or ffp3 ) mask includes protection provided mask lowernumbered classes mask conforming standard must class written along name standard year publication well applicable option codes eg “ en 1492001 ffp1 nr d ” manufacturers use addition colour elastic band identify mask class however en 149 standard specify colour coding different manufacturers used different colour schemes filter class per en 149 class6 filter penetration limit ( at 95 l / min air flow ) inward leakage typical elastic band ffp1 filters least 80 airborne particles 22 yellow ffp2 filters least 94 airborne particles 8 blue whiteffp3 filters least 99 airborne particles 2 red',\n",
       " 'marking ( 1 ) united states european union require specific standards design manufacturing testing product markings personal protective equipment ( ppe ) us niosh ( national institute occupational safety health ) approved n95 respirators filtering facepiece respirators ( ffr ) need marked approval number verified niosh certified equipment list ( cel ) niosh trustedsource page nioshapproved ffrs always one following designations n95 n99 n100 r95 r99 r100 p95 p99 p100. example exterior marking per niosh',\n",
       " 'gas filters ( 1 ) gas filters provide protection vapours chemical substances toxic gases usually consist bed activated carbon described according 2 criteria filter type class ( 2 ) various types gas filter defined specific filter given gas family gases vapours indicated marking consisting letter strip certain colour filter designed protect several families gas simultaneously call combined filter designated juxtaposition letter corresponding colour strips example ab filters organic gases / vapours inorganic gases / vapours bk filters inorganic vapours ammonia ammonia derivatives ( 3 ) select right class efficiency gas filter aerosol filters three classes protective filters based capacity ( in words best balance volume effectiveness absorbent material ) ( i ) class 1 gas concentrations less 0. 1 volume lowest capacity ( filters half masks ) – eg a1 ( ii ) class 2 gas concentrations 0. 1 0. 5 volume medium capacity ( cartridge ) – eg abek2 ( iii ) class 3 gas concentrations 0. 5 1 volume largest capacity ( largecapacity canister worn waistlevel ) ( 4 ) equivalent ambient concentration level class 3 filter operate longer either class 2 class 1 filter filter colour code per niosh ec ( 5 ) long gas filter effective gas filter longer functions properly carbon granules become saturated starts let pollutants contact reason gas filter needs replaced regular basis filter becomes totally',\n",
       " 'class 3 filter operate longer either class 2 class 1 filter filter colour code per niosh ec ( 5 ) long gas filter effective gas filter longer functions properly carbon granules become saturated starts let pollutants contact reason gas filter needs replaced regular basis filter becomes totally saturated important know minimum breakthrough time required nf en 14387 a1 standard filter type class minimum breakdown time filter type class test gas test gas concentration ( ppm ) minimum breakdown time ( min ) ai cyclohexane 1000 70 chlore 1000 20 b1 hydrogen sulfide 1000 40 hydrogen cyanide 1000 25 el sulfur dioxide 1000 20 ki ammoniac 1000 50 a2 cyclohexane 5000 35 chlore 5000 20 b2 hydrogen sulfide 5000 40 hydrogen cyanide 5000 25 e2 sulfur dioxide 5000 20 k2 ammoniac 5000 40 a3 cyclohexane 8000 65 chlore 10000 30',\n",
       " 'general requirements ( 1 ) employer shall ensure affected employee wears protective helmet working areas potential injury head falling objects ( 2 ) employer shall ensure protective helmet designed reduce electrical shock hazard worn affected employee near exposed electrical conductors could contact head details found saso guide occupational safety health ( safety helmet ) – general requirements saso3001 occupational safety health procedures work environment safety helmet ansi z89. 1 – industrial head protection iso 3873 industrial safety helmets',\n",
       " 'criteria head protection ( 1 ) head protection must comply following consensus standards ( i ) saso3001 occupational safety health procedures work environment safety helmet sasoguide occupational safety healthsafety helmet equivalent saso standards additional details found american national standards institute ( ansi ) z89. 1 “ american national standard industrial head protection american national standards institute ( ansi ) z89. 1 “ american national standard personnel protection — protective headwear industrial workers — requirements ” ( 2 ) head protection devices employer demonstrates least effective head protection devices constructed accordance one consensus standards deemed compliance requirements section',\n",
       " 'marking ( 1 ) safety helmets marked following markings',\n",
       " 'types head protection ( 1 ) standards identify type 1 type 2 helmets ( i ) type 1 helmets incorporate full brim ( the brim fully encircles dome hat ) ( ii ) type 2 helmets encircling brim may include short bill front ( similar baseball cap ) ( 2 ) terms electrical performance ansi z89. 1 recognizes three classes ( i ) class helmets intended reduce force impact falling objects reduce danger contact exposed lowvoltage electrical conductors certification sample shells prooftested 2200 volts electrical charge ( ii ) class b helmets intended reduce force impact falling objects reduce danger contact exposed highvoltage electrical conductors sample shells prooftested 20000 volts ( iii ) class c helmets intended reduce force impact falling objects offer electrical protection',\n",
       " 'general requirements ( 1 ) employer shall provide protective footwear according work nature risk without required payment ( 2 ) employee shall ensure continuous supervision workers make sure wearing protective footwear working ( 3 ) employee shall provide training workers choose use protective footwear ( 4 ) employers shall wear protective footwear required ( 5 ) employers shall shall maintain protective footwear integrity store appropriately details found saso guide occupational safety health – safety shoes – general requirements saso2992 occupational safety health procedures work environment safety shoes gso iso 20345 gso iso 20346 gso iso 20347 gso iso 20344.',\n",
       " 'criteria protective footwear ( 1 ) protective footwear must comply following consensus standards ( i ) saso2992 occupational safety health procedures work environment safety shoes equivalent ( ii ) saso guide occupational safety health – safety shoes ( iii ) astm f – 2412 – 2005 “ standard test methods foot protection ” astm f – 2413 – 2005 “ standard specification performance requirements protective footwear ” additional information found ansi z41 – 1999 “ american national standard personal protection — protective footwear ” ansi z41 – 1991 “ american national standard personal protection — protective footwear ” ( 2 ) protective footwear employer demonstrates least effective protective footwear constructed accordance one consensus standards deemed compliance requirements section',\n",
       " 'types shoeswide range styles professional footwear depending degree protection two main types ( 1 ) safety protective footwear minimum impact resistance 200 joules compressive strength least 15 kn toe cap addition characteristics antistatic ( 2 ) occupational footwear case toecap insole impactresistant comply antislip waterrepellent protection criteria',\n",
       " 'marking marking shoes shall compliance iso20345 / iso20346 / iso20347',\n",
       " 'design requirements specific types electrical protective equipment rubber insulating blankets rubber insulating matting rubber insulating covers rubber insulating line hose rubber insulating gloves rubber insulating sleeves shall meet following requirements ( 1 ) characteristics protective equipment shall determined respect function may eg protection effects ( i ) overcurrent ( overload shortcircuit ) ( ii ) earth fault current ( iii ) overvoltage ( iv ) undervoltage novoltage protective devices shall operate values current voltage timewhich suitably related characteristics circuits possibilities danger ( sbc 401 electrical chapter 12 122. 8 protective equipment ) ( 2 ) manufacture marking rubber insulating equipment ( i ) blankets gloves sleeves shall produced seamless process ( ii ) item shall clearly marked follows ( a ) class 00 equipment shall marked class 00. ( b ) class 0 equipment shall marked class 0. ( c ) class 1 equipment shall marked class 1. ( d ) class 2 equipment shall marked class 2. ( e ) class 3 equipment shall marked class 3. ( f ) class 4 equipment shall marked class 4. ( g ) nonozoneresistant equipment shall marked type ( h ) ozoneresistant equipment shall marked type ii ( i ) relevant markings manufacturers identification size equipment may also provided ( iii ) markings',\n",
       " 'f ) class 4 equipment shall marked class 4. ( g ) nonozoneresistant equipment shall marked type ( h ) ozoneresistant equipment shall marked type ii ( i ) relevant markings manufacturers identification size equipment may also provided ( iii ) markings shall nonconducting shall applied manner impair insulating qualities equipment ( iv ) markings gloves shall confined cuff portion glove ( 3 ) electrical requirements ( i ) equipment shall capable withstanding ac prooftest voltage specified table 8 dc prooftest voltage specified table 9. ( a ) proof test shall reliably indicate equipment withstand voltage involved ( b ) test voltage shall applied continuously 3 minutes equipment matting shall applied continuously 1 minute matting ( c ) gloves shall also capable separately withstanding ac prooftest voltage specified table 8after 16hour water soak ( ii ) ac proof test used gloves 60hertz prooftest current may exceed values specified table 8 time test period ( a ) ac proof test made frequency 60 hertz permissible proof test current shall computed direct ratio frequencies ( b ) test gloves ( right side out ) shall filled tap water immersed water depth accordance table 10. water shall added removed glove necessary water level inside outside glove ( c ) 16hour water soak 60hertz prooftest current may exceed values',\n",
       " 'frequencies ( b ) test gloves ( right side out ) shall filled tap water immersed water depth accordance table 10. water shall added removed glove necessary water level inside outside glove ( c ) 16hour water soak 60hertz prooftest current may exceed values given table 8by 2 milliamperes ( iii ) equipment subjected minimum breakdown voltage test may used electrical protection ( iv ) material used type ii insulating equipment shall capable withstanding ozone test visible effects ozone test shall reliably indicate material resist ozone exposure actual use visible signs ozone deterioration material checking cracking breaks pitting evidence failure meet requirements ozoneresistant material ( 4 ) workmanship finish ( i ) equipment shall free physical irregularities adversely affect insulating properties equipment detected tests inspections required section ( ii ) surface irregularities may present rubber goods ( because imperfections forms molds inherent difficulties manufacturing process ) may appear indentations protuberances imbedded foreign material acceptable following conditions ( a ) indentation protuberance blends smooth slope material stretched ( b ) foreign material remains place insulating material folded stretches insulating material surroundingrequirements types electrical protective equipment found astm d120 – 09 astm d178 – 01 ( 2010 ) astm d1048 – 12 astm d1049',\n",
       " 'foreign material remains place insulating material folded stretches insulating material surroundingrequirements types electrical protective equipment found astm d120 – 09 astm d178 – 01 ( 2010 ) astm d1048 – 12 astm d1049 – 98 ( 2010 ) astm d1050 – 05 ( 2011 ) astm d1051 – 08 astm f1236 – 96 ( 2012 ) astm f819 – 10',\n",
       " 'design requirements types electrical protective equipment following requirements apply design manufacture electrical protective equipment covered paragraph ( a ) section ( 1 ) voltage withstands insulating equipment used protection employees shall capable withstanding without failure voltages may imposed upon ( 2 ) equipment current ( i ) protective equipment used primary insulation employees energized circuit parts shall capable passing current test subjected highest nominal voltage equipment used ( ii ) insulating equipment tested accordance paragraph ( b ) ( 2 ) ( i ) section equipment current may exceed 1 microampere per kilovolt phaseto phase applied voltage',\n",
       " 'inservice care use electrical protective equipment — ( 1 ) general electrical protective equipment shall maintained safe reliable condition ( 2 ) specific requirements following specific requirements apply rubber insulating blankets rubber insulating covers rubber insulating line hose rubber insulating gloves rubber insulating sleeves ( i ) maximum use voltages shall conform listed table 11. ( ii ) insulating equipment shall inspected damage days use immediately following incident reasonably suspected causing damage insulating gloves shall given air test along inspection details found astm f123696. ( iii ) insulating equipment following defects may used ( a ) hole tear puncture cut ( b ) ozone cutting ozone checking ( that series interlacing cracks produced ozone rubber mechanical stress ) ( c ) embedded foreign object ( d ) following texture changes swelling softening hardening becoming sticky inelastic ( e ) defect damages insulating properties ( iv ) insulating equipment found defects might affect insulating properties shall removed service returned testing paragraphs ( c ) ( 2 ) ( viii ) ( c ) ( 2 ) ( ix ) section ( v ) insulating equipment shall cleaned needed remove foreign substances ( vi ) insulating equipment shall stored location manner protect light temperature extremes excessive humidity ozone damaging substances conditions ( vii ) protector gloves shall worn insulating gloves except follows ( a )',\n",
       " '( ix ) section ( v ) insulating equipment shall cleaned needed remove foreign substances ( vi ) insulating equipment shall stored location manner protect light temperature extremes excessive humidity ozone damaging substances conditions ( vii ) protector gloves shall worn insulating gloves except follows ( a ) protector gloves need used class 0 gloves limiteduse conditions small equipment parts manipulation necessitate unusually high finger dexterity ( b ) voltage exceed 250 volts ac 375 volts dc protector gloves need used class 00 gloves limiteduse conditions small equipment parts manipulation necessitate unusually high finger dexterity ( c ) class glove may used without protector gloves limiteduse conditions small equipment parts manipulation necessitate unusually high finger dexterity employer demonstrate possibility physical damage gloves small class glove one class higher required voltage involved ( d ) insulating gloves used without protector gloves may reused tested provisions paragraphs ( c ) ( 2 ) ( viii ) ( c ) ( 2 ) ( ix ) section ( viii ) electrical protective equipment shall subjected periodic electrical tests test voltages maximum intervals tests shall accordance table 11 table 12. ( ix ) test method used paragraphs ( c ) ( 2 ) ( viii ) ( c ) ( 2 ) ( xi ) section shall reliably indicate whether insulating equipment withstand voltages involved details test methods found astm d120',\n",
       " '12. ( ix ) test method used paragraphs ( c ) ( 2 ) ( viii ) ( c ) ( 2 ) ( xi ) section shall reliably indicate whether insulating equipment withstand voltages involved details test methods found astm d120 – 09 astm d178 – 01 ( 2010 ) astm d1048 – 12 astm d1049 – 98 ( 2010 ) astm d1050 – 05 ( 2011 ) astm d1051 – 08 astm f478 – 09 astm f479 – 06 ( 2011 ) astm f496 – 08. ( x ) insulating equipment failing pass inspections electrical tests may used employees except follows ( a ) rubber insulating line hose may used shorter lengths defective portion cut ( b ) rubber insulating blankets may salvaged severing defective area undamaged portion blanket resulting undamaged area may smaller 560 millimeters 560 millimeters ( 22 inches 22 inches ) class 1 2 3 4 blankets ( c ) rubber insulating blankets may repaired using compatible patch results physical electrical properties equal blanket ( d ) rubber insulating gloves sleeves minor physical defects small cuts tears punctures may repaired application compatible patch also rubber insulating gloves sleeves minor surface blemishes may repaired compatible liquid compound repaired',\n",
       " 'may repaired using compatible patch results physical electrical properties equal blanket ( d ) rubber insulating gloves sleeves minor physical defects small cuts tears punctures may repaired application compatible patch also rubber insulating gloves sleeves minor surface blemishes may repaired compatible liquid compound repaired area shall electricalphysical properties equal surrounding material repairs gloves permitted area wrist reinforced edge opening ( xi ) repaired insulating equipment shall retested may used employees ( xii ) employer shall certify equipment tested accordance requirements paragraphs ( c ) ( 2 ) ( iv ) ( c ) ( 2 ) ( vii ) ( d ) ( c ) ( 2 ) ( viii ) ( c ) ( 2 ) ( ix ) ( c ) ( 2 ) ( xi ) section certification shall identify equipment passed test date tested class equipment proodtest voltage rms v maximum prooftest current ( gloves only ) 280mm ( 11in ) glove 360mm ( 14in ) glove 410mm ( 16in ) glove 460mm ( 18 in ) glove 00 2500 8 12 0 5000 8 12 14 16 1 10000 14 16 18 2 20000 16 18 20 3 30000 18 20 22 4 40000 22 24 class equipment proof – test voltage 00 10000 0 20000 1 40000 2 50000 3 60000class equipment maximum use voltage ac',\n",
       " '16 1 10000 14 16 18 2 20000 16 18 20 3 30000 18 20 22 4 40000 22 24 class equipment proof – test voltage 00 10000 0 20000 1 40000 2 50000 3 60000class equipment maximum use voltage ac rms retest voltage ac rms retest voltage dc avg 00 500 2500 10000 0 1000 5000 20000 1 7500 10000 40000 2 17000 20000 50000 3 26500 30000 60000 4 36000 40000 70000 type equipment test rubber insulating line hose indication insulating value suspect repair rubber insulating covers upon indication insulating value suspect repair rubber insulating blankets first issue every 12 months thereafter upon indication insulating value suspect repair rubber insulating gloves efore first issue every 6 months thereafter upon indication insulating value suspect repair use without protectors rubber insulating sleeves first issue every 12 months thereafter upon indication insulating value suspect repair',\n",
       " 'general requirements ( 1 ) employers shall select require employees use appropriate hand protection employees hands exposed hazards skin absorption harmful substances severe cuts lacerations severe abrasions punctures chemical burns thermal burns harmful temperature extremes ( 2 ) employer shall provide appropriate hand protection according work nature risk without required payment ( 3 ) employee shall ensure continuous supervision workers make sure wearing hand protection working ( 4 ) employee shall provide training workers choose use hand protection ( 5 ) employers shall wear hand protection required details found saso guide occupational safety health – hand protection – general requirements saso3000 occupational safety health procedures work environment protect hands employers shall base selection appropriate hand protection evaluation performance characteristics hand protection relative task ( s ) performed conditions present duration use hazards potential hazards identified',\n",
       " 'mechanical protection levels protective glove performance mechanical hazards described american standard ansi / isea 105. cut resistance based version astm f 1790 standard adopted 1997. corresponds force deployed cutthrough distance 25 mm puncture resistance must measured according version en 388 standard corresponds maximum force established using probe conical head 4. 5 mm diameter two properties illustrated table six levels higher level greater resistance material ( 1 ) classification proposed american standard ( 2 ) performance criteria per european standards european standard protective gloves uses performance criteria described european standard en 388. ( 3 ) classification european standards',\n",
       " 'electrical protection 2 / 5 electrical protection insulation provided gloves direct contact live electrical components classified follows voltage ratings ( 1 ) 1 / 2 / 5 volts 500 ac 750 dc ( 2 ) 2 / 2 / 5 volts 1000 ac 1500 dc ( 3 ) 3 / 2 / 5 volts 7500 ac 11250 dc ( 4 ) 4 / 2 / 5 volts 17000 ac 25500 dc ( 5 ) 5 / 2 / 5 volts 26500 ac 39500 dc ( 6 ) 6 / 2 / 5 volts 36000 ac 54000 dc',\n",
       " 'chemical protection ( 1 ) categorization chemicalresistant gloves chemical resistant gloves categorized three classes type type b type c shown table table 151 pictogram 3 types glovethird row type b symbols shows chemicals material protected found table chemical resistant gloves use instruction sheets provide information penetration chemicals penetrate holes material degradation expressed percentage ( ) addition chemical resistant gloves may provide information whether protect bacteria fungi viruses instance biohazard symbol shown glove specific microorganism protects listed alongside ( 2 ) glove material uk hse guide protective gloves recommends following suitable materials different chemical groups ( water soluble substances organic solvents strong acids etc ) chemical group glove material natural rubber nitrile rubber neoprenetm pvc butyl vitontmwater miscible substances weak acids / alkalis oils chlorinated hydrocarbons aromatic solvents aliphatic solvents strong acids strong alkalis pcbs',\n",
       " 'heat flame protection ( 1 ) 1 / 4 / 5 thermal insulation resistance resistance heat transfer duration heat exposure direct flame removal occurs ( 2 ) 2 / 4 / 5 flame damage resistance resistance damage resulting exposure flames ( thermal ignition resistance ) ( 3 ) 3 / 4 / 5 conductive heat resistance protection heat touching hot surface ( 4 ) 5 / 5 heat reduction resistance heat transfer across spectrum frequencies ( 5 ) 6 / 5 heat resistance grade',\n",
       " 'scope application section establishes performance care use criteria personal fall protection systems employer must ensure personal fall protection system used comply part must meet requirements section',\n",
       " 'definitions ( 1 ) anchorage means secure point attachment equipment lifelines lanyards deceleration devices ( 2 ) belt terminal means end attachment window cleaners positioning system used securing belt harness window cleaners belt anchor ( 3 ) body belt means strap means securing waist attaching components lanyard used positioning systems travel restraint systems ladder safety systems ( 4 ) body harness means straps secure employee manner distribute fall arrest forces least thighs pelvis waist chest shoulders means attaching harness components personal fall protection system ( 5 ) carabiner means connector generally comprised trapezoidal oval shaped body closed gate similar arrangement may opened attach another object released automatically closes retain object ( 6 ) competent person means person capable identifying existing predictable hazards personal fall protection system component well application uses related equipment authorization take prompt corrective action eliminate identified hazards ( 7 ) connector means device used couple ( connect ) parts fall protection system together ( 8 ) dring means connector used ( 9 ) ( i ) harness integral attachment element fall arrest attachment ( 10 ) ( ii ) lanyard energy absorber lifeline anchorage connector integral connector ( 11 ) ( iii ) positioning travel restraint system attachment element ( 12 ) deceleration device means mechanism serves dissipate energy fall ( 13 ) deceleration distance means vertical distance falling employee travels point deceleration device',\n",
       " 'lifeline anchorage connector integral connector ( 11 ) ( iii ) positioning travel restraint system attachment element ( 12 ) deceleration device means mechanism serves dissipate energy fall ( 13 ) deceleration distance means vertical distance falling employee travels point deceleration device begins operate excluding lifeline elongation free fall distance stopping measured distance location employees body harness attachment point moment activation ( at onset fall arrest forces ) deceleration device fall location attachment point employee comes full stop ( 14 ) equivalent means alternative designs equipment materials methods employer demonstrate provide equal greater degree safety employees compared designs equipment materials methods specified standard ( 15 ) free fall means act falling personal fall arrest system begins apply force arrest fall ( 16 ) free fall distance means vertical displacement fall arrest attachment point employees body belt body harness onset fall system begins apply force arrest fall distance excludes deceleration distance lifeline lanyard elongation includes deceleration device slide distance selfretracting lifeline / lanyard extension devices operate fall arrest forces occur ( 17 ) lanyard means flexible line rope wire rope strap generally connector end connecting body belt body harness deceleration device lifeline anchorage ( 18 ) lifeline means component personal fall protection system consisting flexible line connection anchorage one end hang vertically ( vertical lifeline ) connection anchorages ends stretch horizontally (',\n",
       " 'rope wire rope strap generally connector end connecting body belt body harness deceleration device lifeline anchorage ( 18 ) lifeline means component personal fall protection system consisting flexible line connection anchorage one end hang vertically ( vertical lifeline ) connection anchorages ends stretch horizontally ( horizontal lifeline ) serves means connecting components system anchorage ( 19 ) personal fall arrest system means system used arrest employee fall walkingworking surface consists body harness anchorage connector means connection may include lanyard deceleration device lifeline suitable combination ( 20 ) personal fall protection system means system ( including components ) employer uses provide protection falling safely arrest employees fall one occurs examples personal fall protection systems include personal fall arrest systems positioning systems travel restraint systems ( 21 ) positioning system ( workpositioning system ) means system equipment connectors used body harness body belt allows employee supported elevated vertical surface wall window sill work hands free positioning systems also called “ positioning system devices ” “ work positioning equipment ” ( 22 ) qualified describes person possession recognized degree certificate professional standing extensive knowledge training experience successfully demonstrated ability solve resolve problems relating subject matter work project ( 23 ) rope grab means deceleration device travels lifeline automatically friction engages lifeline locks arrest fall employee rope grab usually employs principle inertial locking cam / lever locking ( 24 ) safety factor means ratio design load ultimate strength',\n",
       " 'relating subject matter work project ( 23 ) rope grab means deceleration device travels lifeline automatically friction engages lifeline locks arrest fall employee rope grab usually employs principle inertial locking cam / lever locking ( 24 ) safety factor means ratio design load ultimate strength material ( 25 ) selfretracting lifeline / lanyard means deceleration device containing drumwound line slowly extracted retracted onto drum slight tension normal movement employee onset fall device automatically locks drum arrests fall ( 26 ) snaphook means connector comprised hookshaped body normally closed gate similar arrangement may manually opened permit hook receive object released snaphook automatically closes retain object opening snaphook requires two separate actions snaphooks generally one two types ( 27 ) automaticlocking type ( permitted ) selfclosing selflocking gate remains closed locked intentionally unlocked opened connection disconnection ( 28 ) nonlocking type ( prohibited ) selfclosing gate remains closed locked intentionally opened connection disconnection ( 29 ) travel restraint ( tether ) line means rope wire rope used transfer forces body support anchorage anchorage connector travel restraint system ( 30 ) travel restraint system means combination anchorage anchorage connector lanyard ( or means connection ) body support employer uses eliminate possibility employee going edge walkingworking surface ( 31 ) window cleaners belt means positioning belt',\n",
       " 'used transfer forces body support anchorage anchorage connector travel restraint system ( 30 ) travel restraint system means combination anchorage anchorage connector lanyard ( or means connection ) body support employer uses eliminate possibility employee going edge walkingworking surface ( 31 ) window cleaners belt means positioning belt consists waist belt integral terminal runner strap belt terminals ( 32 ) window cleaners belt anchor ( window anchor ) means specifically designed fall preventing attachment points permanently affixed window frame building part immediately adjacent window frame direct attachment terminal portion window cleaners belt ( 33 ) window cleaners positioning system means system consists window cleaners belt secured window anchors',\n",
       " 'general requirements employer must ensure personal fall protection systems meet following requirements additional requirements personal fall arrest systems positioning systems contained paragraphs ( d ) ( e ) section respectively ( 1 ) connectors must drop forged pressed formed steel made equivalent materials ( 2 ) connectors must corrosionresistant finish surfaces edges must smooth prevent damage interfacing parts system ( 3 ) vertical lifelines used employee must attached separate lifeline ( 4 ) lanyards vertical lifelines must minimum breaking strength 22. 2 kn ( 5000 pounds ) ( 5 ) selfretracting lifelines lanyards automatically limit free fall distance 0. 61 ( 2 feet ) less must components capable sustaining minimum tensile load 13. 3 kn ( 3000 pounds ) applied device lifeline lanyard fully extended position ( 6 ) competent person qualified person must inspect knot lanyard vertical lifeline ensure meets requirements paragraphs ( c ) ( 4 ) ( 5 ) section employee uses lanyard lifeline ( 7 ) drings snap hooks carabiners must capable sustaining minimum tensile load 22. 2 kn ( 5000 pounds ) ( 8 ) drings snap hooks carabiners must proof tested minimum tensile load 16 kn ( 3600 pounds ) without cracking breaking incurring permanent deformation gate strength snap hooks carabiners must capable withstanding minimum',\n",
       " '. 2 kn ( 5000 pounds ) ( 8 ) drings snap hooks carabiners must proof tested minimum tensile load 16 kn ( 3600 pounds ) without cracking breaking incurring permanent deformation gate strength snap hooks carabiners must capable withstanding minimum load 16 kn ( 3600 pounds ) without gate separating nose snap hook carabiner body 3. 175 mm ( 0. 125 inches ) ( 9 ) snap hooks carabiners must automatic locking type require least two separate consecutive movements open ( 10 ) snap hooks carabiners must connected following unless designed connections ( i ) directly webbing rope wire rope ( ii ) ( iii ) dring another snap hook carabiner connector attached ( iv ) horizontal life line ( v ) object incompatibly shaped dimensioned relation snap hook carabiner unintentional disengagement could occur connected object depresses snap hook carabiner gate allowing components separate ( 11 ) employer must ensure horizontal lifeline ( i ) designed installed used supervision qualified person ( ii ) part complete personal fall arrest system maintains safety factor least two ( 12 ) anchorages used attach personal fall protection equipment must independent anchorage used suspend employees platforms employees work anchorages used attach personal fall protection equipment mobile work platforms powered industrial trucks must attached overhead member platform point',\n",
       " 'part complete personal fall arrest system maintains safety factor least two ( 12 ) anchorages used attach personal fall protection equipment must independent anchorage used suspend employees platforms employees work anchorages used attach personal fall protection equipment mobile work platforms powered industrial trucks must attached overhead member platform point located near center platform ( 13 ) anchorages except window cleaners belt anchors covered paragraph ( e ) section must ( i ) capable supporting least 22. 2 kn ( 5000 pounds ) employee attached ( ii ) designed installed used supervision qualified person part complete personal fall protection system maintains safety factor least two ( 14 ) travel restraint lines must capable sustaining tensile load least 22. 2 kn ( 5000 pounds ) ( 15 ) lifelines must made natural fiber rope polypropylene rope must contain ultraviolet ( uv ) light inhibitor ( 16 ) personal fall protection systems components must used exclusively employee fall protection purpose hoisting equipment materials ( 17 ) personal fall protection system components subjected impact loading must removed service immediately used competent person inspects system components determines damaged safe use employee personal fall protection ( 18 ) personal fall protection systems must inspected initial use workshift mildew wear damage deterioration defective components must removed service ( 19 ) ropes belts lanyards harnesses used personal fall protection must compatible connectors used ( 20 ) ropes belts lanyards lifelines',\n",
       " ') personal fall protection systems must inspected initial use workshift mildew wear damage deterioration defective components must removed service ( 19 ) ropes belts lanyards harnesses used personal fall protection must compatible connectors used ( 20 ) ropes belts lanyards lifelines harnesses used personal fall protection must protected cut abraded melted otherwise damaged ( 21 ) employer must provide prompt rescue employee event fall ( 22 ) personal fall protection systems must worn attachment point body harness located center employees back near shoulder level attachment point may located presternal position free fall distance limited 0. 6 ( 2 feet ) less',\n",
       " 'personal fall arrest systems ( 1 ) system performance criteria addition general requirements paragraph ( c ) section employer must ensure personal fall arrest systems ( i ) limit maximum arresting force employee 8 kn ( 1800 pounds ) ( ii ) bring employee complete stop limit maximum deceleration distance employee travels 1. 1 ( 3. 5 feet ) ( iii ) sufficient strength withstand twice potential impact energy employee free falling distance 1. 8 ( 6 feet ) free fall distance permitted system ( iv ) sustain employee within system / strap configuration without making contact employees neck chin area ( 2 ) system use criteria employer must ensure ( i ) horizontal lifeline may become vertical lifeline device used connect horizontal lifeline capable locking directions lifeline ( ii ) personal fall arrest systems rigged manner employee cannot free fall 1. 8 ( 6 feet ) contact lower level free fall may 1. 8 ( 6 feet ) provided employer demonstrate manufacturer designed system allow free fall 6 feet tested system ensure maximum arresting force 8 kn ( 1800 pounds ) exceeded ( 3 ) body belts body belts prohibited part personal fall arrest system',\n",
       " 'positioning systems ( 1 ) system performance requirements employer must ensure positioning system meets following requirements ( i ) general positioning systems except window cleaners positioning systems capable withstanding without failure drop test consisting 1. 2m ( 4foot ) drop 113kg ( 250pound ) weight ( ii ) window cleaners positioning systems window cleaners positioning systems must ( a ) capable withstanding without failure drop test consisting 1. 8m ( 6foot ) drop 113kg ( 250pound ) weight ( b ) limit initial arresting force falling employee 8. 9 kn ( 2000 pounds ) duration exceeding 2 milliseconds subsequent arresting forces 4. 5 kn ( 1000 pounds ) ( iii ) linemans body belt pole strap systems linemans body belt pole strap systems must meet following tests ( a ) dielectric test 819. 7 volts ac per centimeter ( 25000 volts per foot ) 3 minutes without visible deterioration ( b ) leakage test 98. 4 volts ac per centimeter ( 3000 volts per foot ) leakage current 1 ( c ) flammability test accordance table i – 7 section table 16 – flammability test test method criteria passing test vertically suspend 500mm ( 19. 7inch ) length strapping supporting 100 kg ( 220.',\n",
       " 'leakage current 1 ( c ) flammability test accordance table i – 7 section table 16 – flammability test test method criteria passing test vertically suspend 500mm ( 19. 7inch ) length strapping supporting 100 kg ( 220. 5lb ) weight use butane propane burner 76mm ( 3inch ) flame direct flame edge strapping distance 25mm ( 1inch ) remove falme 5 seconds wait flames positioning strap stop burning flames positioning strap must selfextinguish positioning strap must continue support 100kg ( 220. 5lb ) mass ( 2 ) system use criteria window cleaners positioning systems employer must ensure window cleaners positioning systems meet used accordance following ( i ) window cleaners belts designed constructed ( a ) belt terminals pass fastenings belt harness terminal comes loose window anchor ( b ) length runner terminal tip terminal tip 2. 44 ( 8 feet ) less ( ii ) window anchors belts fastened installed side frames mullions window point less 106. 7 cm ( 42 inches ) 129. 5 cm ( 51 inches ) window sill ( iii ) window anchor capable supporting minimum load 26. 5 kn ( 6000 pounds ) ( iv ) use installed window anchors purpose attaching window cleaners belt prohibited ( v ) window anchor',\n",
       " '42 inches ) 129. 5 cm ( 51 inches ) window sill ( iii ) window anchor capable supporting minimum load 26. 5 kn ( 6000 pounds ) ( iv ) use installed window anchors purpose attaching window cleaners belt prohibited ( v ) window anchor damaged deteriorated fastenings supports removed window anchor head detached anchor cannot used ( vi ) rope wear deterioration affects strength used ( vii ) terminals window cleaners belt attached separate window anchors cleaning operation ( viii ) employee works window sill ledge snow ice slippery condition one weakened rotted ( ix ) employee works window sill ledge unless ( a ) window sill ledge minimum 10 cm ( 4 inches ) wide slopes 15 degrees horizontal ( b ) 10cm minimum width window sill ledge increased 1 cm ( 0. 4 inches ) every degree sill ledge slopes beyond 15 degrees maximum 30 degrees ( x ) employee attaches least one belt terminal window anchor climbing window opening keeps least one terminal attached completely back inside window opening ( xi ) except provided paragraph ( d ) ( 2 ) ( xii ) section employee travels one window another returning inside window opening repeating belt terminal attachment procedure window accordance paragraph ( d ) ( 2 ) ( x ) section ( xii ) employee using window cleaners positioning system may travel one window another outside building provided ( a ) least',\n",
       " ') section employee travels one window another returning inside window opening repeating belt terminal attachment procedure window accordance paragraph ( d ) ( 2 ) ( x ) section ( xii ) employee using window cleaners positioning system may travel one window another outside building provided ( a ) least one belt terminal attached window anchor times ( b ) distance window anchors exceed 1. 2 ( 4 feet ) horizontally distance windows may increased 1. 8 ( 6 feet ) horizontally windowsill ledge least 0. 31 ( 1 foot ) wide slope less 5 degrees ( c ) sill ledge windows continuous ( d ) width windowsill ledge front mullions least 15. 2 cm ( 6 inches ) wide']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# data = [section['summarized_content'] if 'summarized_content' in section else section['content']  if 'summarized_content' in section else section['content'] for p in text_data for section in p['sections'] ]\n",
    "#chunked file:\n",
    "f = open(r'/notebooks/processed_data_custom_cleaned_corrected256.json')\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum token length in the list is: 9\n",
      "The maximum token length in the list is: 259\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the number of tokens for each content\n",
    "token_lengths = [len(tokenizer_dragon.encode(content, add_special_tokens=False)) for content in data]\n",
    "\n",
    "# Find the maximum token length\n",
    "max_token_length = max(token_lengths)\n",
    "# Find the maximum token length\n",
    "min_token_length = min(token_lengths)\n",
    "\n",
    "print(f\"The minimum token length in the list is: {min_token_length}\")\n",
    "print(f\"The maximum token length in the list is: {max_token_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n",
      "Top scores: [(10, 374.5437316894531), (9, 371.3961181640625), (50, 365.0831298828125), (49, 364.64715576171875), (14, 362.1315002441406), (11, 361.5710754394531), (21, 361.2860107421875), (46, 360.9688720703125), (31, 360.8604736328125), (47, 360.790283203125), (86, 360.5423583984375), (15, 360.17388916015625), (22, 360.110107421875), (35, 360.03875732421875), (38, 359.9537353515625), (0, 359.9000244140625), (29, 359.411376953125), (32, 359.3632507324219), (28, 359.35986328125), (16, 359.3353576660156), (48, 359.0351257324219), (51, 358.968994140625), (36, 358.9237365722656), (3, 358.89434814453125), (34, 358.8845520019531)]\n",
      "Top Docs:\n",
      " filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon arc welding operations plate thickness inches plate thickness mm minimum protective shade gas welding light 1 / 8 3. 2 4 medium 1 / 8 ½ 3. 2 12. 7 5 heavy ½ 12. 7 6 oxygen cutting light 1 25 3 medium 1 6 25 150 4 heavy 6 150 5 details found sasoen1938 personal eye protection – mesh eya face protectors saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ansi / isea z87. 1 – 2010 ansi z87. 1 – 2003 ansi z87. 1 – 1989 ( r – 1998 ) directive 89 / 686 / eec as / nfs1337. 1.\n",
      "general requirements ( 1 ) appropriate eye protection shall worn performing following tasks ( i ) using type adhesives and / or solvent solutions ( ii ) grinding leveling concrete surfaces ( iii ) working environments containing gases ( iv ) handling chemical materials ( v ) performing operations generate dust ( 2 ) employer shall provide means equipment prevent bad vision protect hazing ( saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ) ( 3 ) employer shall ensure affected employee uses eye protection provides side protection hazard flying objects detachable side protectors ( eg clipon slideon side shields ) meeting pertinent requirements section acceptable ( 4 ) employer shall ensure affected employee wears prescription lenses engaged operations involve eye hazards wears eye protection incorporates prescription design wears eye protection worn prescription lenses without disturbing proper position prescription lenses protective lenses ( 5 ) eye face ppe shall distinctly marked facilitate identification manufacturer ( 6 ) employer shall ensure affected employee uses equipment filter lenses shade number appropriate work performed protection injurious light radiation following listing appropriate shade numbers various operations 1 filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon\n",
      "class 3 filter operate longer either class 2 class 1 filter filter colour code per niosh ec ( 5 ) long gas filter effective gas filter longer functions properly carbon granules become saturated starts let pollutants contact reason gas filter needs replaced regular basis filter becomes totally saturated important know minimum breakthrough time required nf en 14387 a1 standard filter type class minimum breakdown time filter type class test gas test gas concentration ( ppm ) minimum breakdown time ( min ) ai cyclohexane 1000 70 chlore 1000 20 b1 hydrogen sulfide 1000 40 hydrogen cyanide 1000 25 el sulfur dioxide 1000 20 ki ammoniac 1000 50 a2 cyclohexane 5000 35 chlore 5000 20 b2 hydrogen sulfide 5000 40 hydrogen cyanide 5000 25 e2 sulfur dioxide 5000 20 k2 ammoniac 5000 40 a3 cyclohexane 8000 65 chlore 10000 30\n",
      "gas filters ( 1 ) gas filters provide protection vapours chemical substances toxic gases usually consist bed activated carbon described according 2 criteria filter type class ( 2 ) various types gas filter defined specific filter given gas family gases vapours indicated marking consisting letter strip certain colour filter designed protect several families gas simultaneously call combined filter designated juxtaposition letter corresponding colour strips example ab filters organic gases / vapours inorganic gases / vapours bk filters inorganic vapours ammonia ammonia derivatives ( 3 ) select right class efficiency gas filter aerosol filters three classes protective filters based capacity ( in words best balance volume effectiveness absorbent material ) ( i ) class 1 gas concentrations less 0. 1 volume lowest capacity ( filters half masks ) – eg a1 ( ii ) class 2 gas concentrations 0. 1 0. 5 volume medium capacity ( cartridge ) – eg abek2 ( iii ) class 3 gas concentrations 0. 5 1 volume largest capacity ( largecapacity canister worn waistlevel ) ( 4 ) equivalent ambient concentration level class 3 filter operate longer either class 2 class 1 filter filter colour code per niosh ec ( 5 ) long gas filter effective gas filter longer functions properly carbon granules become saturated starts let pollutants contact reason gas filter needs replaced regular basis filter becomes totally\n",
      "filter air purifying element means component used respirators remove solid liquid aerosols inspired air ( 11 ) filtering facepiece ( dust mask ) means negative pressure particulate respirator filter integral part facepiece entire facepiece composed filtering medium ( 12 ) fit factor means quantitative estimate fit particular respirator specific individual typically estimates ratio concentration substance ambient air concentration inside respirator worn ( 13 ) fit test means use protocol qualitatively quantitatively evaluate fit respirator individual ( see also qualitative fit test qlft quantitative fit test qnft ) ( 14 ) helmet means rigid respiratory inlet covering also provides head protection impact penetration ( 15 ) high efficiency particulate air ( hepa ) filter means filter least 99. 97 efficient removing monodisperse particles 0. 3 micrometers diameter ( 16 ) hood means respiratory inlet covering completely covers head neck may also cover portions shoulders torso ( 17 ) immediately dangerous life health ( idlh ) means atmosphere poses immediate threat life would cause irreversible adverse health effects would impair individuals ability escape dangerous atmosphere ( 18 ) interior structural firefighting means physical activity fire suppression rescue inside buildings enclosed structures involved fire situation beyond incipient stage ( 19 ) loosefitting facepiece means respiratory inlet covering designed form\n",
      "criteria protective eye face protection ( 1 ) protective eye face protection devices must comply relevant consensus standards following ( i ) saso technical regulation personal protective equipment clothing ( ii ) saso 1938 personal eye protection – mesh eya face protectors ( iii ) saso 4850 ( iso 4850 ) saso 174 saso 207 saso 208 saso 379 saso 1731 equivalent ( iv ) ansi / isea z87. 1 – 2010 occupational educational personal eye face protection devices ( v ) ansi z87. 1 – 2003 occupational educational personal eye face protection devices ( vi ) ansi z87. 1 – 1989 ( r – 1998 ) practice occupational educational eye face protection ( 2 ) protective eye face protection devices employer demonstrates least effective protective eye face protection devices constructed accordance one consensus standards deemed compliance requirements section ( 3 ) marking user must require marking product time purchase check receipt according standards used illustrated examples marking lenses frame accordance ansi 87\n",
      "solutions ( b ) grinding levelling concrete surfaces ( c ) working environments containing gases ( d ) handling chemical materials ( e ) performing operations generate dust ( f ) “ msds ” safety data sheet requirements “ section8 ’ ( v ) employer shall select respirators sufficient number respirator models sizes respirator acceptable correctly fits user ( 2 ) respirators idlh atmospheres ( i ) employer shall provide following respirators employee use idlh atmospheres ( a ) full facepiece pressure demand scba certified niosh authorities like ec minimum service life thirty minutes ( b ) combination full facepiece pressure demand suppliedair respirator ( sar ) auxiliary selfcontained air supply ( ii ) respirators provided escape idlh atmospheres shall nioshcertified authorities like ec escape atmosphere used ( iii ) oxygendeficient atmospheres shall considered idlh exception employer demonstrates foreseeable conditions oxygen concentration maintained within ranges specified table 4 section ( ie altitudes set table ) atmospheresupplying respirator may used ( 3 ) respirators atmospheres idlh ( i ) employer shall provide respirator adequate protect health employee ( a ) assigned protection factors ( apfs ) employers must use assigned protection factors\n",
      "types respiratory protection ( 1 ) two main types respiratory protection ( niosh ec ) — airpurifying respirators ( aprs ) atmospheresupplying respirators ( asrs ) respirator type provides different level protection based design therefore it ’ s important choose right type respirator specific exposure ( 2 ) nioshapproved particulate filtering respirators classification ten classes nioshapproved particulate filtering respirators types respirators use filters remove particles air breathed n r p designations refer filter ’ s oil resistance described table filter class per niosh filter class description n95 n99 n100 filters least 95 99 99. 97 airborne particles resistant oil r95 r99 r100 filters least 95 99 99. 97 airborne particles somewhat resistant oil p95 p99 p100 filters least 95 99 99. 97 airborne particles strongly resistant oil ( high efficiency particulate air ) filters least 99. 97 airborne particles use paprs paprs use filters ( 3 ) en 149 standard defines performance requirements three classes half masks ffp1 ffp2 ffp3. protection provided ffp2 ( or ffp3 ) mask includes protection provided mask lowernumbered classes mask conforming standard must class written along\n",
      "use respirators paragraph requires employers establish implement procedures proper use respirators requirements include prohibiting conditions may result facepiece seal leakage preventing employees removing respirators hazardous environments taking actions ensure continued effective respirator operation throughout work shift establishing procedures use respirators idlh atmospheres interior structural firefighting situations ( 1 ) facepiece seal protection ( i ) employer shall permit respirators tightfitting facepieces worn employees ( a ) facial hair comes sealing surface facepiece face interferes valve function ( b ) condition interferes facetofacepiece seal valve function ( ii ) employee wears corrective glasses goggles personal protective equipment employer shall ensure equipment worn manner interfere seal facepiece face user ( iii ) tightfitting respirators employer shall ensure employees perform user seal check time put respirator done procedures recommended respirator manufacturer employer demonstrates effective ( 2 ) continuing respirator effectiveness ( i ) appropriate surveillance shall maintained work area conditions degree employee exposure stress change work area conditions degree employee exposure stress may affect respirator effectiveness employer shall reevaluate continued effectiveness respirator ( ii ) employer shall ensure employees leave respirator use area ( a ) wash faces respirator facepieces necessary prevent eye skin irritation associated respi\n",
      "( 3 ) en 149 standard defines performance requirements three classes half masks ffp1 ffp2 ffp3. protection provided ffp2 ( or ffp3 ) mask includes protection provided mask lowernumbered classes mask conforming standard must class written along name standard year publication well applicable option codes eg “ en 1492001 ffp1 nr d ” manufacturers use addition colour elastic band identify mask class however en 149 standard specify colour coding different manufacturers used different colour schemes filter class per en 149 class6 filter penetration limit ( at 95 l / min air flow ) inward leakage typical elastic band ffp1 filters least 80 airborne particles 22 yellow ffp2 filters least 94 airborne particles 8 blue whiteffp3 filters least 99 airborne particles 2 red\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from termcolor import colored\n",
    "\n",
    "RELEVENCE_THREASHOLD =350\n",
    "\n",
    "# Define device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Function to generate responses\n",
    "def retrieve_docs(query, contexts, k=10, instruction=\"Answer the question based on the provided documents\"):\n",
    "    print('Loading RAG')\n",
    "    \n",
    "    # Prepare inputs\n",
    "    query_input = tokenizer_dragon(query, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    ctx_input = tokenizer_dragon(contexts, max_length=260, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    with torch.no_grad():\n",
    "        query_emb = query_encoder(**query_input).last_hidden_state[:, 0, :].to(device)\n",
    "        ctx_emb = context_encoder(**ctx_input).last_hidden_state[:, 0, :].to(device)\n",
    "    \n",
    "    # Compute similarity scores using dot product\n",
    "    scores = {i: (query_emb @ ctx_emb[i]).item() for i in range(len(ctx_emb))}\n",
    "    print('RAG Done')\n",
    "    \n",
    "    # Sort scores and select top documents\n",
    "    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    top = [(list(sorted_scores)[i][0], list(sorted_scores)[i][1]) for i in range(min(25, len(sorted_scores))) if list(sorted_scores)[i][1] >= RELEVENCE_THREASHOLD]\n",
    "    \n",
    "\n",
    "   #Top 25 chunks\n",
    "     \n",
    "    selected_docs = [contexts[doc[0]] for doc in top][:k]\n",
    "    formatted_docs = \"\\n\".join(selected_docs)\n",
    "    prompt_template = \"\"\"\n",
    "    system\n",
    "    {instruction} :\n",
    "    {query}\n",
    "    Provided docs: {top}\n",
    "    assistant\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(instruction=instruction, query=query, top=formatted_docs)\n",
    "\n",
    "    return formatted_docs, top, selected_docs\n",
    "\n",
    "\n",
    "query = \"Please Provide me Gas Welding minimum protective filter lenses for gas welding\"\n",
    "\n",
    "formatted_docs, top, selected_docs = retrieve_docs(query=query, contexts=data, k=10)\n",
    "\n",
    "print(\"Top scores:\", top)\n",
    "print(\"Top Docs:\\n\", formatted_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n",
      "Top scores: []\n",
      "Top Docs:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "formatted_docs, top, selected_docs = retrieve_docs(query='hello', contexts=data, k=10)\n",
    "\n",
    "print(\"Top scores:\", top)\n",
    "print(\"Top Docs:\\n\", formatted_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to generate responses\n",
    "def reranker(query, contexts=selected_docs, k=3, instruction=\"Answer the question based on the provided documents\"):\n",
    "    print('Loading RAG')\n",
    "    \n",
    "    # Prepare inputs\n",
    "    query_input = tokenizer_dragon_RoBERTa(query, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    ctx_input = tokenizer_dragon_RoBERTa(contexts, max_length=260, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    with torch.no_grad():\n",
    "        query_emb = query_encoder_RoBERTa(**query_input).last_hidden_state[:, 0, :].to(device)\n",
    "        ctx_emb = context_encoder_RoBERTa(**ctx_input).last_hidden_state[:, 0, :].to(device)\n",
    "    \n",
    "    # Compute similarity scores using dot product\n",
    "    scores = {i: (query_emb @ ctx_emb[i]).item() for i in range(len(ctx_emb))}\n",
    "    print('RAG Done')\n",
    "    \n",
    "    # Sort scores and select top documents\n",
    "    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    top = [(list(sorted_scores)[i][0], list(sorted_scores)[i][1]) for i in range(min(25, len(sorted_scores)))]\n",
    "    \n",
    "\n",
    "   #Top 25 chunks\n",
    "     \n",
    "    selected_docs = [contexts[doc[0]] for doc in top][:k]\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(selected_docs)\n",
    "    return formatted_docs, top, selected_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n"
     ]
    }
   ],
   "source": [
    "formatted_docs, top, selected_docs = retrieve_docs(query='PPE', contexts=data, k=10)\n",
    "formatted_docs, top, selected_docs = reranker(query, contexts=selected_docs, k=3, instruction=\"Answer the question based on the provided documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['general requirements ( 1 ) appropriate eye protection shall worn performing following tasks ( i ) using type adhesives and / or solvent solutions ( ii ) grinding leveling concrete surfaces ( iii ) working environments containing gases ( iv ) handling chemical materials ( v ) performing operations generate dust ( 2 ) employer shall provide means equipment prevent bad vision protect hazing ( saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ) ( 3 ) employer shall ensure affected employee uses eye protection provides side protection hazard flying objects detachable side protectors ( eg clipon slideon side shields ) meeting pertinent requirements section acceptable ( 4 ) employer shall ensure affected employee wears prescription lenses engaged operations involve eye hazards wears eye protection incorporates prescription design wears eye protection worn prescription lenses without disturbing proper position prescription lenses protective lenses ( 5 ) eye face ppe shall distinctly marked facilitate identification manufacturer ( 6 ) employer shall ensure affected employee uses equipment filter lenses shade number appropriate work performed protection injurious light radiation following listing appropriate shade numbers various operations 1 filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon',\n",
       " '##ible adverse health effects would impair individuals ability escape dangerous atmosphere ( 18 ) interior structural firefighting means physical activity fire suppression rescue inside buildings enclosed structures involved fire situation beyond incipient stage ( 19 ) loosefitting facepiece means respiratory inlet covering designed form partial seal face ( 20 ) maximum use concentration ( muc ) means maximum atmospheric concentration hazardous substance employee expected protected wearing respirator determined assigned protection factor respirator class respirators exposure limit hazardous substance muc determined mathematically multiplying assigned protection factor specified respirator required permissible exposure limit shortterm exposure limit ceiling limit exposure limit available hazardous substance employer must determine muc basis relevant available information informed professional judgment ( 21 ) negative pressure respirator ( tight fitting ) means respirator air pressure inside facepiece negative inhalation respect ambient air pressure outside respirator ( 22 ) oxygen deficient atmosphere means atmosphere oxygen content 19. 5 volume ( 23 ) physician licensed health care professional ( plhcp ) means individual whose legally permitted scope practice ( ie license registration certification ) allows independently provide delegated responsibility provide health care services required paragraph ( e ) section ( 24 ) positive pressure respirator means respirator pressure inside respiratory inlet covering exceeds ambient air pressure outside respirator ( 25 ) powered',\n",
       " 'marking ( 1 ) united states european union require specific standards design manufacturing testing product markings personal protective equipment ( ppe ) us niosh ( national institute occupational safety health ) approved n95 respirators filtering facepiece respirators ( ffr ) need marked approval number verified niosh certified equipment list ( cel ) niosh trustedsource page nioshapproved ffrs always one following designations n95 n99 n100 r95 r99 r100 p95 p99 p100. example exterior marking per niosh']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA.\n",
    "Your responses should be:\n",
    "- **Organized**: Clearly structured and easy to follow.\n",
    "- **Concise**: Only include information that directly answers the query. Avoid unnecessary details.\n",
    "- **Contextual**: Rely solely on the provided context or documents if available. Do not include external information.\n",
    " *    System: You are an AI assistant specializing in providing precise information from the Occupational Safety and Health Handbook of KSA.\n",
    "    Your responses should be organized, concise, and strictly based on the provided context. Do not provide additional information beyond what is requested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*prompt_template = \"\"\"\n",
    "System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual.\n",
    "System: This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "Context:\n",
    "{relevance_prompt}\n",
    "\n",
    "Please provide a full and complete answer to the question.\n",
    "\n",
    "<start_of_turn>user\n",
    "{query}\n",
    "<end_of_turn>\n",
    "<start_of_turn>assistant\n",
    "\"\"\"\n",
    "*    prompt_template = \"\"\"\n",
    "    System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA.\n",
    "    Your responses should be organized, concise, and contextual.\n",
    "    System: This is a chat between a user and an artificial intelligence assistant. \n",
    "    The assistant gives helpful, detailed, and polite answers to the user's questions based on the context. The assistant should also indicate when the answer cannot be found in the context.\n",
    "    If the query isn't related to OSHA, answer and IGNORE the context.\n",
    "    Ensure to provide references to the specific chunk source for each piece of information.\n",
    "    Context:\n",
    "    {relevance_prompt}\n",
    "    \n",
    "    Please give a full and complete answer for the question.\n",
    "    <start_of_turn>user\n",
    "    {query}\n",
    "    <end_of_turn>\\n<start_of_turn>model\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**do_sample=False   Use deterministic decoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**old prompts**:\n",
    "- `System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "\n",
    "    Context:\n",
    "    {relevance_prompt}\n",
    "\n",
    "    Please provide a full and complete answer to the following question.\n",
    "\n",
    "                <start_of_turn>user\n",
    "                {query}\n",
    "                <end_of_turn>\n",
    "                <start_of_turn>model\n",
    "\n",
    "                Chain of Thought:\n",
    "                1. **Understanding the Query**: Ensure you fully understand the user's question. Identify key terms and the main objective of the query.\n",
    "                2. **Contextual Matching**: Check the provided context for relevant information. Match the key terms from the query with the chunks of information in the context.\n",
    "                3. **Extracting Information**: Extract the most relevant information from the context. Ensure that the information directly addresses the user's query.\n",
    "                4. **Verifying Accuracy**: Verify that the extracted information is accurate and correctly interpreted from the context.\n",
    "                5. **Ensuring Completeness**: Ensure that the response fully answers the user's query without omitting important details.\n",
    "                6. **Conciseness and Clarity**: Make sure the final response is concise and easy to understand. Avoid unnecessary details.\n",
    "                7. **Reference to Sources**: Provide references to the specific chunk source for each piece of information used in the response.\n",
    "                8. **Final Review**: Review the entire response to ensure there are no errors in reasoning, and the answer is logical and coherent.<start_of_turn>model`\n",
    "\n",
    "- `    prompt_template = \"\"\"\n",
    "    System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "\n",
    "    Context:\n",
    "    {relevance_prompt}\n",
    "\n",
    "    Please provide a full and complete answer to the following question.\n",
    "\n",
    "    <start_of_turn>user\n",
    "    {query}\n",
    "    <end_of_turn>\n",
    "    <start_of_turn>model\"\"\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_docs_retreived = '''\n",
    "\u001b[1m\u001b[31mChapter 10.50 Respiratory Protection, section (h), Page 517\u001b[0m\n",
    "(1) employer shall ensure compressed air compressed oxygen liquid air liquid oxygen used respiration accords following specifications (2) Compressed liquid oxygen shall meet United States Pharmacopoeia requirements medical breathing oxygen Compressed breathing air shall meet least requirements Grade breathing air described ANSI/Compressed Gas Association Commodity Specification Air G–7.1– 1989 include (A) Oxygen content (v/v) 19.5–23.5 (B) Hydrocarbon (condensed) content 5 milligrams per cubic meter air less (C) Carbon monoxide (CO) content 10 ppm less (D) Carbon dioxide content 1000 ppm less (E) Lack noticeable odor (3) employer shall ensure compressed oxygen used atmospheresupplying respirators previously used compressed air (4) employer shall ensure oxygen concentrations greater 23.5 used equipment designed oxygen service distribution (5) employer shall ensure cylinders used supply breathing air respirators meet following requirements (i) Cylinders tested maintained (ii) Cylinders purchased breathing air certificate analysis supplier breathing air meets requirements Grade breathing air (iii) moisture content cylinder exceed dew point −50 °F (−45.6 °C) 1 atmosphere pressure (6) employer shall ensure compressors used supply breathing air respirators constructed situated (i) Prevent entry contaminated air airsupply system (ii) Minimize moisture content dew point 1 atmosphere pressure 10 degrees F (5.56 °C) ambient temperature\n",
    "\u001b[1m\u001b[31mChapter 10.50 Respiratory Protection, section (d), Page 505\u001b[0m\n",
    "(F) “MSDS” safety data sheet requirements “section8’ (v) employer shall select respirators sufficient number respirator models sizes respirator acceptable correctly fits user (2) Respirators IDLH atmospheres (i) employer shall provide following respirators employee use IDLH atmospheres (A) full facepiece pressure demand SCBA certified NIOSH authorities like EC minimum service life thirty minutes (B) combination full facepiece pressure demand suppliedair respirator (SAR) auxiliary selfcontained air supply (ii) Respirators provided escape IDLH atmospheres shall NIOSHcertified authorities like EC escape atmosphere used (iii) oxygendeficient atmospheres shall considered IDLH Exception employer demonstrates foreseeable conditions oxygen concentration maintained within ranges specified Table 4 section (ie altitudes set table) atmospheresupplying respirator may used (3) Respirators atmospheres IDLH (i) employer shall provide respirator adequate protect health employee (A) Assigned Protection Factors (APFs) Employers must use assigned protection factors listed Table 3 select respirator meets exceeds required level employee protection using combination respirator (eg airline respirators airpurifying filter) employers must ensure assigned protection factor appropriate mode operation respirator used Table 3—Assigned Protection Factors Type of respirator: Air-Purifying Respirator:\n",
    "  - Quarter mask: 5\n",
    "  - Half mask: 310\n",
    "  - Full facepiece: 50\n",
    "  - Helmet/hood: Not specified\n",
    "  - Loose-fitting facepiece: Not specified\n",
    "\n",
    "Type of respirator: Powered Air-Purifying Respirator (PAPR):\n",
    "  - Quarter mask: Not specified\n",
    "  - Half mask: 50\n",
    "  - Full facepiece: 1,000\n",
    "  - Helmet/hood: 425/1,000\n",
    "  - Loose-fitting facepiece: 25\n",
    "\n",
    "Type of respirator: Supplied-Air Respirator (SAR) or Airline Respirator:\n",
    "  Demand mode:\n",
    "    - Quarter mask: Not specified\n",
    "    - Half mask: 10\n",
    "    - Full facepiece: 50\n",
    "    - Helmet/hood: Not specified\n",
    "    - Loose-fitting facepiece: Not specified\n",
    "  Continuous flow mode:\n",
    "    - Quarter mask: Not specified\n",
    "    - Half mask: 50\n",
    "    - Full facepiece: 1,000\n",
    "    - Helmet/hood: 425/1,000\n",
    "    - Loose-fitting facepiece: 25\n",
    "  Pressure-demand or other positive-pressure mode:\n",
    "    - Quarter mask: Not specified\n",
    "    - Half mask: 50\n",
    "    - Full facepiece: 1,000\n",
    "    - Helmet/hood: Not specified\n",
    "    - Loose-fitting facepiece: Not specified\n",
    "\n",
    "Type of respirator: Self-Contained Breathing Apparatus (SCBA):\n",
    "  Demand mode:\n",
    "    - Quarter mask: Not specified\n",
    "    - Half mask: 10\n",
    "    - Full facepiece: 50\n",
    "    - Helmet/hood: 50\n",
    "    - Loose-fitting facepiece: Not specified\n",
    "  Pressure-demand or other positive-pressure mode (e.g., open/closed circuit):\n",
    "    - Quarter mask: Not specified\n",
    "    - Half mask: Not specified\n",
    "    - Full facepiece: 10,000\n",
    "    - Helmet/hood: 10,000\n",
    "    - Loose-fitting facepiece: Not specified\n",
    "\n",
    "\u001b[1m\u001b[31mChapter 10.50 Respiratory Protection, section (d), Page 508\u001b[0m\n",
    "(B) airpurifying respirator equipped filter certified NIOSH equivalent authorities (such EC) high efficiency particulate air (HEPA) filter airpurifying respirator equipped filter certified particulates NIOSH equivalent authorities (such EC) (C) contaminants consisting primarily particles mass median aerodynamic diameters (MMAD) least 2 micrometers airpurifying respirator equipped filter certified particulates NIOSH equivalent authorities (such EC) Table4 Oxygen Deficient Atmospheres (%O2) for which the employer may rely on atmosphere-supplying respirators:\n",
    "\n",
    "- Altitude: Less than 3,001 ft.\n",
    "  - Oxygen levels: 16.0-19.5%\n",
    "\n",
    "- Altitude: 3,001-4,000 ft.\n",
    "  - Oxygen levels: 16.4-19.5%\n",
    "\n",
    "- Altitude: 4,001-5,000 ft.\n",
    "  - Oxygen levels: 17.1-19.5%\n",
    "\n",
    "- Altitude: 5,001-6,000 ft.\n",
    "  - Oxygen levels: 17.8-19.5%\n",
    "\n",
    "- Altitude: 6,001-7,000 ft.\n",
    "  - Oxygen levels: 18.5-19.5%\n",
    "\n",
    "- Altitude: 7,001-8,000 ft.\n",
    "  - Oxygen levels: 19.3-19.5%\n",
    " 8000 feet exception apply Oxygenenriched breathing air must supplied 14000 feet\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oxygen level threshold for safe use of atmosphere-supplying respirators at an altitude of less than 3,001 ft is between **16.0% and 19.5%**.\n",
      "\n",
      "**Source:** Chapter 10.50 Respiratory Protection, section (d), Page 508, Table 4. \n",
      "<end_of_turn>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the oxygen level threshold at an altitude of less than 3,001 ft for safe use of atmosphere-supplying respirators?'\n",
    "# formatted_docs_retreived, top, selected_docs = retrieve_docs(query=query, contexts=data, k=5)\n",
    "\n",
    "\n",
    "input_text = tokenizer.apply_chat_template([{\"role\":\"user\",\"content\":f\"\"\"You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "                    1. **Understanding the Query**: Ensure you fully understand the user's question. Identify key terms and the main objective of the query.\n",
    "            2. **Contextual Matching**: Check the provided context for relevant information. Match the key terms from the query with the chunks of information in the context.\n",
    "            3. **Extracting Information**: Extract the most relevant information from the context. Ensure that the information directly addresses the user's query.\n",
    "            4. **Verifying Accuracy**: Verify that the extracted information is accurate and correctly interpreted from the context.\n",
    "            5. **Ensuring Completeness**: Ensure that the response fully answers the user's query without omitting important details.\n",
    "            6. **Conciseness and Clarity**: Make sure the final response is concise and easy to understand. Avoid unnecessary details.\n",
    "            7. **Reference to Sources**: Provide references to the specific chunk source for each piece of information used in the response.\n",
    "            8. **Final Review**: Review the entire response to ensure there are no errors in reasoning, and the answer is logical and coherent.\n",
    "        CONTEXT: {formatted_docs_retreived} QUESTION: {query}\"\"\"}], tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "from transformers import  TextStreamer\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=1000, streamer=streamer)\n",
    "# print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<bos><start_of_turn>user\\nYou are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\\n                    1. **Understanding the Query**: Ensure you fully understand the user's question. Identify key terms and the main objective of the query.\\n            2. **Contextual Matching**: Check the provided context for relevant information. Match the key terms from the query with the chunks of information in the context.\\n            3. **Extracting Information**: Extract the most relevant information from the context. Ensure that the information directly addresses the user's query.\\n            4. **Verifying Accuracy**: Verify that the extracted information is accurate and correctly interpreted from the context.\\n            5. **Ensuring Completeness**: Ensure that the response fully answers the user's query without omitting important details.\\n            6. **Conciseness and Clarity**: Make sure the final response is concise and easy to understand. Avoid unnecessary details.\\n            7. **Reference to Sources**: Provide references to the specific chunk source for each piece of information used in the response.\\n            8. **Final Review**: Review the entire response to ensure there are no errors in reasoning, and the answer is logical and coherent.\\n        CONTEXT: general requirements ( 1 ) appropriate eye protection shall worn performing following tasks ( i ) using type adhesives and / or solvent solutions ( ii ) grinding leveling concrete surfaces ( iii ) working environments containing gases ( iv ) handling chemical materials ( v ) performing operations generate dust ( 2 ) employer shall provide means equipment prevent bad vision protect hazing ( saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ) ( 3 ) employer shall ensure affected employee uses eye protection provides side protection hazard flying objects detachable side protectors ( eg clipon slideon side shields ) meeting pertinent requirements section acceptable ( 4 ) employer shall ensure affected employee wears prescription lenses engaged operations involve eye hazards wears eye protection incorporates prescription design wears eye protection worn prescription lenses without disturbing proper position prescription lenses protective lenses ( 5 ) eye face ppe shall distinctly marked facilitate identification manufacturer ( 6 ) employer shall ensure affected employee uses equipment filter lenses shade number appropriate work performed protection injurious light radiation following listing appropriate shade numbers various operations 1 filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon\\n\\n---\\n\\n##ible adverse health effects would impair individuals ability escape dangerous atmosphere ( 18 ) interior structural firefighting means physical activity fire suppression rescue inside buildings enclosed structures involved fire situation beyond incipient stage ( 19 ) loosefitting facepiece means respiratory inlet covering designed form partial seal face ( 20 ) maximum use concentration ( muc ) means maximum atmospheric concentration hazardous substance employee expected protected wearing respirator determined assigned protection factor respirator class respirators exposure limit hazardous substance muc determined mathematically multiplying assigned protection factor specified respirator required permissible exposure limit shortterm exposure limit ceiling limit exposure limit available hazardous substance employer must determine muc basis relevant available information informed professional judgment ( 21 ) negative pressure respirator ( tight fitting ) means respirator air pressure inside facepiece negative inhalation respect ambient air pressure outside respirator ( 22 ) oxygen deficient atmosphere means atmosphere oxygen content 19. 5 volume ( 23 ) physician licensed health care professional ( plhcp ) means individual whose legally permitted scope practice ( ie license registration certification ) allows independently provide delegated responsibility provide health care services required paragraph ( e ) section ( 24 ) positive pressure respirator means respirator pressure inside respiratory inlet covering exceeds ambient air pressure outside respirator ( 25 ) powered\\n\\n---\\n\\nmarking ( 1 ) united states european union require specific standards design manufacturing testing product markings personal protective equipment ( ppe ) us niosh ( national institute occupational safety health ) approved n95 respirators filtering facepiece respirators ( ffr ) need marked approval number verified niosh certified equipment list ( cel ) niosh trustedsource page nioshapproved ffrs always one following designations n95 n99 n100 r95 r99 r100 p95 p99 p100. example exterior marking per niosh QUESTION: Please Provide me Gas Welding minimum protective filter lenses for gas welding<end_of_turn>\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "formatted_docs_retreived, top, selected_docs = retrieve_docs(query=query, contexts=data, k=3)\n",
    "chat = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "                    1. **Understanding the Query**: Ensure you fully understand the user's question. Identify key terms and the main objective of the query.\n",
    "            2. **Contextual Matching**: Check the provided context for relevant information. Match the key terms from the query with the chunks of information in the context.\n",
    "            3. **Extracting Information**: Extract the most relevant information from the context. Ensure that the information directly addresses the user's query.\n",
    "            4. **Verifying Accuracy**: Verify that the extracted information is accurate and correctly interpreted from the context.\n",
    "            5. **Ensuring Completeness**: Ensure that the response fully answers the user's query without omitting important details.\n",
    "            6. **Conciseness and Clarity**: Make sure the final response is concise and easy to understand. Avoid unnecessary details.\n",
    "            7. **Reference to Sources**: Provide references to the specific chunk source for each piece of information used in the response.\n",
    "            8. **Final Review**: Review the entire response to ensure there are no errors in reasoning, and the answer is logical and coherent.\n",
    "        CONTEXT: {formatted_docs} QUESTION: {query}\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=False)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=2048) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Plasma Arc Welding with an arc current of 300 amps, a protective shade of **9** is recommended. \n",
      "\n",
      "Source: Plasma arc cutting:\n",
      "- Arc current: 300–400 (medium), Protective shade: 9 \n",
      "<end_of_turn>\n",
      "<eos>\n",
      "<bos><start_of_turn>user\n",
      "You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
      "                    1. **Understanding the Query**: Ensure you fully understand the user's question. Identify key terms and the main objective of the query.\n",
      "            2. **Contextual Matching**: Check the provided context for relevant information. Match the key terms from the query with the chunks of information in the context.\n",
      "            3. **Extracting Information**: Extract the most relevant information from the context. Ensure that the information directly addresses the user's query.\n",
      "            4. **Verifying Accuracy**: Verify that the extracted information is accurate and correctly interpreted from the context.\n",
      "            5. **Ensuring Completeness**: Ensure that the response fully answers the user's query without omitting important details.\n",
      "            6. **Conciseness and Clarity**: Make sure the final response is concise and easy to understand. Avoid unnecessary details.\n",
      "            7. **Reference to Sources**: Provide references to the specific chunk source for each piece of information used in the response.\n",
      "            8. **Final Review**: Review the entire response to ensure there are no errors in reasoning, and the answer is logical and coherent.\n",
      "        CONTEXT: Plasma arc welding:\n",
      "- Arc current: Less than 20, Protective shade: 6\n",
      "  - Arc current: 20–100, Protective shade: 8\n",
      "  - Arc current: 100–400, Protective shade: 10\n",
      "  - Arc current: 400–800, Protective shade: 11\n",
      "\n",
      "---\n",
      "\n",
      "Plasma arc cutting:\n",
      "- Arc current: Less than 300 (light), Protective shade: 8\n",
      "  - Arc current: 300–400 (medium), Protective shade: 9\n",
      "  - Arc current: 400–800 (heavy), Protective shade: 10\n",
      "\n",
      "---\n",
      "\n",
      "Shielded metal arc welding:\n",
      "- Electrode size 1/32 in:\n",
      "    - Arc current: Less than 60, Protective shade: 7\n",
      "    - Arc current: 60–160, Protective shade: 8\n",
      "    - Arc current: 160–250, Protective shade: 10\n",
      "    - Arc current: 250–550, Protective shade: 11 QUESTION: For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "For Plasma Arc Welding with an arc current of 300 amps, a protective shade of **9** is recommended. \n",
      "\n",
      "Source: Plasma arc cutting:\n",
      "- Arc current: 300–400 (medium), Protective shade: 9 \n",
      "<end_of_turn>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=2048, max_length=2048, streamer=streamer)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  TextStreamer\n",
    "\n",
    "        \n",
    "def get_completion(query: str, formatted_docs: str, model, tokenizer, relevance= True):\n",
    "\n",
    "    device = \"cuda:0\"  # Specifies using the first CUDA-capable GPU\n",
    "\n",
    "    if relevance:  # User wrote a relevant quote\n",
    "        relevance_prompt = f'''\n",
    "        Please refer to the specific chunk sources for each piece of information and perform any necessary calculations based on the provided data:\n",
    "\n",
    "        CONTEXT : {formatted_docs}\n",
    "        '''\n",
    "    else:\n",
    "        relevance_prompt = ''\n",
    "    prompt_template = \"\"\"\n",
    "    System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "\n",
    "    Context:\n",
    "    {relevance_prompt}\n",
    "\n",
    "    <start_of_turn>user\n",
    "    QUESTION: {query}\n",
    "    Please refer to the specific chunk sources for each piece of information and perform any necessary calculations based on the provided data.\n",
    "    <end_of_turn>\n",
    "    <start_of_turn>model\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(query=query, relevance_prompt=relevance_prompt)\n",
    "    tokenizer_settings = {\n",
    "        \"padding\": True,\n",
    "        \"truncation\": True,\n",
    "        \"max_length\": 1024,  # Adjust max length based on your context needs\n",
    "    }\n",
    "    encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True, **tokenizer_settings).to(device)  # Tokenizes the prompt\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "    # Print the length of the tokenized prompt\n",
    "    print(f\"The prompt length is: {encodeds['input_ids'].size(1)}\")\n",
    "    \n",
    "    # Generates a sequence of tokens from the model\n",
    "    generated_ids = model.generate(input_ids=encodeds['input_ids'], attention_mask=encodeds['attention_mask'], max_new_tokens=2024, streamer=streamer, do_sample=False, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "            \n",
    "    decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)  # Decodes the generated tokens to text\n",
    "    \n",
    "    return decoded\n",
    "    #model.generate(**model_inputs, max_new_tokens=250, streamer=streamer, do_sample=True, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "  # Returns the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon arc welding operations plate thickness inches plate thickness mm minimum protective shade gas welding light 1 / 8 3. 2 4 medium 1 / 8 ½ 3. 2 12. 7 5 heavy ½ 12. 7 6 oxygen cutting light 1 25 3 medium 1 6 25 150 4 heavy 6 150 5 details found sasoen1938 personal eye protection – mesh eya face protectors saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ansi / isea z87. 1 – 2010 ansi z87. 1 – 2003 ansi z87. 1 – 1989 ( r – 1998 ) directive 89 / 686 / eec as / nfs1337. 1.\n",
      "general requirements ( 1 ) appropriate eye protection shall worn performing following tasks ( i ) using type adhesives and / or solvent solutions ( ii ) grinding leveling concrete surfaces ( iii ) working environments containing gases ( iv ) handling chemical materials ( v ) performing operations generate dust ( 2 ) employer shall provide means equipment prevent bad vision protect hazing ( saso technical regulation personal protective equipment clothing – personal protective equipment face eyes ) ( 3 ) employer shall ensure affected employee uses eye protection provides side protection hazard flying objects detachable side protectors ( eg clipon slideon side shields ) meeting pertinent requirements section acceptable ( 4 ) employer shall ensure affected employee wears prescription lenses engaged operations involve eye hazards wears eye protection incorporates prescription design wears eye protection worn prescription lenses without disturbing proper position prescription lenses protective lenses ( 5 ) eye face ppe shall distinctly marked facilitate identification manufacturer ( 6 ) employer shall ensure affected employee uses equipment filter lenses shade number appropriate work performed protection injurious light radiation following listing appropriate shade numbers various operations 1 filter lenses protection radiant energy operations electrode size 1 / 32 arc current minimum protective shade shielded metal arc welding gas metal arc welding flux cored arc welding gas tungsten arc weldingair carbon arc cutting plasma arc welding plasma arc cutting torch brazing torch soldering carbon\n",
      "class 3 filter operate longer either class 2 class 1 filter filter colour code per niosh ec ( 5 ) long gas filter effective gas filter longer functions properly carbon granules become saturated starts let pollutants contact reason gas filter needs replaced regular basis filter becomes totally saturated important know minimum breakthrough time required nf en 14387 a1 standard filter type class minimum breakdown time filter type class test gas test gas concentration ( ppm ) minimum breakdown time ( min ) ai cyclohexane 1000 70 chlore 1000 20 b1 hydrogen sulfide 1000 40 hydrogen cyanide 1000 25 el sulfur dioxide 1000 20 ki ammoniac 1000 50 a2 cyclohexane 5000 35 chlore 5000 20 b2 hydrogen sulfide 5000 40 hydrogen cyanide 5000 25 e2 sulfur dioxide 5000 20 k2 ammoniac 5000 40 a3 cyclohexane 8000 65 chlore 10000 30\n"
     ]
    }
   ],
   "source": [
    "print(formatted_docs_retreived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mTable retriever :\n",
      "\u001b[0m\n",
      "Loading RAG\n",
      "RAG Done\n",
      "The prompt length is: 1024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m printt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTable retriever :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m formatted_docs_retreived, top, selected_docs \u001b[38;5;241m=\u001b[39m retrieve_docs(query\u001b[38;5;241m=\u001b[39mquery, contexts\u001b[38;5;241m=\u001b[39mdata, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_docs_retreived\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 42\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(query, formatted_docs, model, tokenizer, relevance)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe prompt length is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencodeds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Generates a sequence of tokens from the model\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencodeds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencodeds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m decoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Decodes the generated tokens to text\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:994\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    992\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1008\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:843\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    832\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    833\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    834\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m         cache_position,\n\u001b[1;32m    841\u001b[0m     )\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:601\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    599\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_feedforward_layernorm(hidden_states)\n\u001b[1;32m    600\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m--> 601\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_feedforward_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    604\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 164\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query ='For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?'\n",
    "printt('Table retriever :\\n')\n",
    "formatted_docs_retreived, top, selected_docs = retrieve_docs(query=query, contexts=data, k=10)\n",
    "results = get_completion(query, formatted_docs=formatted_docs_retreived, model = model , tokenizer = tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operations: Shielded metal arc welding:\\n    - Electrode size 1/32 in: Less than 3, Arc current: Less than 60, Minimum * protective shade: 7\\n    - Electrode size 1/32 in: 3-5, Arc current: 60–160, Minimum * protective shade: 8\\n    - Electrode size 1/32 in: 5-8 than 3, Arc current: 160–250, Minimum * protective shade: 10\\n    - Electrode size 1/32 in: More than 8, Arc current: 250–550, Minimum * protective shade: 11\\n\\nOperations: Gas metal arc welding and flux cored arc welding:\\n  - Arc current: Less than 60, Minimum * protective shade: 7\\n  - Arc current: 60–160, Minimum * protective shade: 10\\n  - Arc current: 160–250, Minimum * protective shade: 10\\n  - Arc current: 250–500, Minimum * protective shade: 10\\n\\nOperations: Gas Tungsten arc welding:\\n  - Arc current: Less than 50, Minimum * protective shade: 8\\n  - Arc current: 50–150, Minimum * protective shade: 8\\n  - Arc current: 150–500, Minimum * protective shade: 10\\n\\nOperations: Air carbon :\\n  - Electrode size 1/32 in: (Light), Arc current: Less than 500, Minimum * protective shade: 10\\n\\nOperations: Arc cutting:\\n  - Electrode size 1/32 in: (Heavy), Arc current: 500–1000, Minimum * protective shade: 11\\n\\nOperations: Plasma arc welding:\\n  - Arc current: Less than 20, Minimum * protective shade: 6\\n  - Arc current: 20–100, Minimum * protective shade: 8\\n  - Arc current: 100–400, Minimum * protective shade: 10\\n  - Arc current: 400–800, Minimum * protective shade: 11\\n\\nOperations: Plasma arc cutting:\\n  - Electrode size 1/32 in: (light)**, Arc current: Less than 300, Minimum * protective shade: 8\\n  - Electrode size 1/32 in: (medium)**, Arc current: 300–400, Minimum * protective shade: 9\\n  - Electrode size 1/32 in: (heavy)**, Arc current: 400–800, Minimum * protective shade: 10\\n\\nOperations: Torch brazing:\\n  - Minimum * protective shade: 3\\n\\nOperations: Torch soldering:\\n  - Minimum * protective shade: 2\\n\\nOperations: Carbon arc welding:\\n  - Minimum * protective shade: 14\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_docs_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt length is: 881\n",
      " According to the provided text, the recommended shade for an arc current of **50–150 amps** for a 1/32\" electrode is **10**. \n",
      "\n",
      "    The text does not provide information on the recommended shade for 300 amps. \n",
      "\n",
      "    Please note that this information is not sufficient to determine the appropriate shade for all situations. The text only provides a range of 300 amps for a specific task. \n",
      "\n",
      "    The context suggests that the text may be referring to a specific type of welding process. \n",
      "\n",
      "    **Please refer to the appropriate safety regulations and guidelines for the specific welding process and the appropriate shade for the specific task. **\n",
      "\n",
      "    The recommended shade for a 1/32\" electrode is **10**, and the text implies this is likely the same for the other types of welding you mentioned. \n",
      "\n",
      "    **However, the text does not state that this is the case.**\n",
      "\n",
      "    Please consult the manufacturer's instructions for the specific welding process and the appropriate safety standards for the most accurate information.<end_of_turn><eos>\n"
     ]
    }
   ],
   "source": [
    "query ='For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?'\n",
    "# printt('Table retriever :\\n')\n",
    "# formatted_docs_retreived, top, selected_docs = retrieve_docs(query=query, contexts=chunks, k=10)\n",
    "results = get_completion(query, formatted_docs=formatted_docs_gpt, model = model , tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table readabilty evaluation PROMPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Splittibg technique could be `split()`, then combining till we ge to the needed chunk size each time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operations: Shielded metal arc welding:\\n    - Electrode size 1/32 in: Less than 3, Arc current: Less than 60, Minimum * protective shade: 7\\n    - Electrode size 1/32 in: 3-5, Arc current: 60–160, Minimum * protective shade: 8\\n    - Electrode size 1/32 in: 5-8 than 3, Arc current: 160–250, Minimum * protective shade: 10\\n    - Electrode size 1/32 in: More than 8, Arc current: 250–550, Minimum * protective shade: 11\\n\\nOperations: Gas metal arc welding and flux cored arc welding:\\n  - Arc current: Less than 60, Minimum * protective shade: 7\\n  - Arc current: 60–160, Minimum * protective shade: 10\\n  - Arc current: 160–250, Minimum * protective shade: 10\\n  - Arc current: 250–500, Minimum * protective shade: 10\\n\\nOperations: Gas Tungsten arc welding:\\n  - Arc current: Less than 50, Minimum * protective shade: 8\\n  - Arc current: 50–150, Minimum * protective shade: 8\\n  - Arc current: 150–500, Minimum * protective shade: 10\\n\\nOperations: Air carbon :\\n  - Electrode size 1/32 in: (Light), Arc current: Less than 500, Minimum * protective shade: 10\\n\\nOperations: Arc cutting:\\n  - Electrode size 1/32 in: (Heavy), Arc current: 500–1000, Minimum * protective shade: 11\\n\\nOperations: Plasma arc welding:\\n  - Arc current: Less than 20, Minimum * protective shade: 6\\n  - Arc current: 20–100, Minimum * protective shade: 8\\n  - Arc current: 100–400, Minimum * protective shade: 10\\n  - Arc current: 400–800, Minimum * protective shade: 11\\n\\nOperations: Plasma arc cutting:\\n  - Electrode size 1/32 in: (light)**, Arc current: Less than 300, Minimum * protective shade: 8\\n  - Electrode size 1/32 in: (medium)**, Arc current: 300–400, Minimum * protective shade: 9\\n  - Electrode size 1/32 in: (heavy)**, Arc current: 400–800, Minimum * protective shade: 10\\n\\nOperations: Torch brazing:\\n  - Minimum * protective shade: 3\\n\\nOperations: Torch soldering:\\n  - Minimum * protective shade: 2\\n\\nOperations: Carbon arc welding:\\n  - Minimum * protective shade: 14\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_docs_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'perations', 'Shielded metal arc welding', '\\n    - Electrode size 1/32 in: Less than 3, Arc current: Less than 60, Minimum * protective shade: 7\\n    - Electrode size 1/32 in: 3-5, Arc current: 60–160, Minimum * protective shade: 8\\n    - Electrode size 1/32 in: 5-8 than 3, Arc current: 160–250, Minimum * protective shade: 10\\n    - Electrode size 1/32 in: More than 8, Arc current: 250–550, Minimum * protective shade: 11\\n\\n', 'perations', 'Gas metal arc welding and flux cored arc welding', '\\n  - Arc current: Less than 60, Minimum * protective shade: 7\\n  - Arc current: 60–160, Minimum * protective shade: 10\\n  - Arc current: 160–250, Minimum * protective shade: 10\\n  - Arc current: 250–500, Minimum * protective shade: 10\\n\\n', 'perations', 'Gas Tungsten arc welding', '\\n  - Arc current: Less than 50, Minimum * protective shade: 8\\n  - Arc current: 50–150, Minimum * protective shade: 8\\n  - Arc current: 150–500, Minimum * protective shade: 10\\n\\n', 'perations', 'Air carbon ', '\\n  - Electrode size 1/32 in: (Light), Arc current: Less than 500, Minimum * protective shade: 10\\n\\n', 'perations', 'Arc cutting', '\\n  - Electrode size 1/32 in: (Heavy), Arc current: 500–1000, Minimum * protective shade: 11\\n\\n', 'perations', 'Plasma arc welding', '\\n  - Arc current: Less than 20, Minimum * protective shade: 6\\n  - Arc current: 20–100, Minimum * protective shade: 8\\n  - Arc current: 100–400, Minimum * protective shade: 10\\n  - Arc current: 400–800, Minimum * protective shade: 11\\n\\n', 'perations', 'Plasma arc cutting', '\\n  - Electrode size 1/32 in: (light)**, Arc current: Less than 300, Minimum * protective shade: 8\\n  - Electrode size 1/32 in: (medium)**, Arc current: 300–400, Minimum * protective shade: 9\\n  - Electrode size 1/32 in: (heavy)**, Arc current: 400–800, Minimum * protective shade: 10\\n\\n', 'perations', 'Torch brazing', '\\n  - Minimum * protective shade: 3\\n\\n', 'perations', 'Torch soldering', '\\n  - Minimum * protective shade: 2\\n\\n', 'perations', 'Carbon arc welding', '\\n  - Minimum * protective shade: 14\\n']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m section_headers \u001b[38;5;241m=\u001b[39m section_header_regex\u001b[38;5;241m.\u001b[39msplit(formatted_docs_gpt)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(section_headers)\n\u001b[0;32m---> 16\u001b[0m section_headers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msection_headers\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(section_headers)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Split the text by section headers, keeping the headers\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m section_headers \u001b[38;5;241m=\u001b[39m section_header_regex\u001b[38;5;241m.\u001b[39msplit(formatted_docs_gpt)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(section_headers)\n\u001b[0;32m---> 16\u001b[0m section_headers \u001b[38;5;241m=\u001b[39m [\u001b[43mtup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mtup[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m section_headers]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(section_headers)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Split the text by section headers, keeping the headers\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "TABLES_PATH = '/notebooks/tablesGPTformat'\n",
    "# Read the contents of the text file\n",
    "with open(TABLES_PATH+'/table6.txt', 'r') as file:\n",
    "    formatted_docs_gpt = file.read()\n",
    "    \n",
    "# Regular expression to match section headers (lines ending with a colon and followed by a newline with no space)\n",
    "section_header_regex = re.compile(r'^.([A-Za-z\\s]+):\\s([A-Za-z\\s]+):$', re.MULTILINE)#(r'\\n+([A-Za-z]+):')\n",
    "\n",
    "\n",
    "# Find all section headers\n",
    "section_headers = section_header_regex.split(formatted_docs_gpt)\n",
    "print(section_headers)\n",
    "\n",
    "section_headers = [tup[0] +': '+tup[1] for tup in section_headers]\n",
    "print(section_headers)\n",
    "# Split the text by section headers, keeping the headers\n",
    "split_text = section_header_regex.split(formatted_docs_gpt)\n",
    "\n",
    "# Create a dictionary to store the sections\n",
    "sections = {}\n",
    "\n",
    "# Populate the dictionary with headers and their corresponding text\n",
    "for i in range(1, len(split_text), 2):\n",
    "    header = split_text[i].strip()\n",
    "    content = split_text[i + 1].strip()\n",
    "    sections[header] = content\n",
    "chunks =[]\n",
    "# Print the sections to verify the result\n",
    "for header, content in sections.items():\n",
    "    print(f\"HEADER {header}:\\n{content}\\n\")\n",
    "    chunks.append(f\"{header}:\\n{content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Operations',\n",
       " 'Shielded metal arc welding',\n",
       " '\\n    - Electrode size 1/32 in: Less than 3, Arc current: Less than 60, Minimum * protective shade: 7\\n    - Electrode size 1/32 in: 3-5, Arc current: 60–160, Minimum * protective shade: 8\\n    - Electrode size 1/32 in: 5-8 than 3, Arc current: 160–250, Minimum * protective shade: 10\\n    - Electrode size 1/32 in: More than 8, Arc current: 250–550, Minimum * protective shade: 11\\n',\n",
       " 'Operations',\n",
       " 'Gas metal arc welding and flux cored arc welding',\n",
       " '\\n  - Arc current: Less than 60, Minimum * protective shade: 7\\n  - Arc current: 60–160, Minimum * protective shade: 10\\n  - Arc current: 160–250, Minimum * protective shade: 10\\n  - Arc current: 250–500, Minimum * protective shade: 10\\n',\n",
       " 'Operations',\n",
       " 'Gas Tungsten arc welding',\n",
       " '\\n  - Arc current: Less than 50, Minimum * protective shade: 8\\n  - Arc current: 50–150, Minimum * protective shade: 8\\n  - Arc current: 150–500, Minimum * protective shade: 10\\n',\n",
       " 'Operations',\n",
       " 'Air carbon ',\n",
       " '\\n  - Electrode size 1/32 in: (Light), Arc current: Less than 500, Minimum * protective shade: 10\\n',\n",
       " 'Operations',\n",
       " 'Arc cutting',\n",
       " '\\n  - Electrode size 1/32 in: (Heavy), Arc current: 500–1000, Minimum * protective shade: 11\\n',\n",
       " 'Operations',\n",
       " 'Plasma arc welding',\n",
       " '\\n  - Arc current: Less than 20, Minimum * protective shade: 6\\n  - Arc current: 20–100, Minimum * protective shade: 8\\n  - Arc current: 100–400, Minimum * protective shade: 10\\n  - Arc current: 400–800, Minimum * protective shade: 11\\n',\n",
       " 'Operations',\n",
       " 'Plasma arc cutting',\n",
       " '\\n  - Electrode size 1/32 in: (light)**, Arc current: Less than 300, Minimum * protective shade: 8\\n  - Electrode size 1/32 in: (medium)**, Arc current: 300–400, Minimum * protective shade: 9\\n  - Electrode size 1/32 in: (heavy)**, Arc current: 400–800, Minimum * protective shade: 10\\n',\n",
       " 'Operations',\n",
       " 'Torch brazing',\n",
       " '\\n  - Minimum * protective shade: 3\\n',\n",
       " 'Operations',\n",
       " 'Torch soldering',\n",
       " '\\n  - Minimum * protective shade: 2\\n',\n",
       " 'Operations',\n",
       " 'Carbon arc welding',\n",
       " '\\n  - Minimum * protective shade: 14\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Operations:\\n- Minimum * protective shade: 14']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Operations: Shielded metal arc welding:\\n    - Electrode size 1/32 in: Less than 3, Arc current: Less than 60, Minimum * protective shade: 7\\n    - Electrode size 1/32 in: 3-5, Arc current: 60–160, Minimum * protective shade: 8\\n    - Electrode size 1/32 in: 5-8 than 3, Arc current: 160–250, Minimum * protective shade: 10\\n    - Electrode size 1/32 in: More than 8, Arc current: 250–550, Minimum * protective shade: 11',\n",
       " 'Operations: Gas metal arc welding and flux cored arc welding:\\n  - Arc current: Less than 60, Minimum * protective shade: 7\\n  - Arc current: 60–160, Minimum * protective shade: 10\\n  - Arc current: 160–250, Minimum * protective shade: 10\\n  - Arc current: 250–500, Minimum * protective shade: 10',\n",
       " 'Operations: Gas Tungsten arc welding:\\n  - Arc current: Less than 50, Minimum * protective shade: 8\\n  - Arc current: 50–150, Minimum * protective shade: 8\\n  - Arc current: 150–500, Minimum * protective shade: 10',\n",
       " 'Operations: Air carbon :\\n  - Electrode size 1/32 in: (Light), Arc current: Less than 500, Minimum * protective shade: 10',\n",
       " 'Operations: Arc cutting:\\n  - Electrode size 1/32 in: (Heavy), Arc current: 500–1000, Minimum * protective shade: 11',\n",
       " 'Operations: Plasma arc welding:\\n  - Arc current: Less than 20, Minimum * protective shade: 6\\n  - Arc current: 20–100, Minimum * protective shade: 8\\n  - Arc current: 100–400, Minimum * protective shade: 10\\n  - Arc current: 400–800, Minimum * protective shade: 11',\n",
       " 'Operations: Plasma arc cutting:\\n  - Electrode size 1/32 in: (light)**, Arc current: Less than 300, Minimum * protective shade: 8\\n  - Electrode size 1/32 in: (medium)**, Arc current: 300–400, Minimum * protective shade: 9\\n  - Electrode size 1/32 in: (heavy)**, Arc current: 400–800, Minimum * protective shade: 10',\n",
       " 'Operations: Torch brazing:\\n  - Minimum * protective shade: 3',\n",
       " 'Operations: Torch soldering:\\n  - Minimum * protective shade: 2',\n",
       " 'Operations: Carbon arc welding:\\n  - Minimum * protective shade: 14\\n']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE:  Operations: Shielded metal arc welding:\n",
      "    - Electrode size 1/32 in: Less than 3, Arc current: Less than 60, Minimum * protective shade: 7\n",
      "    - Electrode size 1/32 in: 3-5, Arc current: 60–160, Minimum * protective shade: 8\n",
      "    - Electrode size 1/32 in: 5-8 than 3, Arc current: 160–250, Minimum * protective shade: 10\n",
      "    - Electrode size 1/32 in: More than 8, Arc current: 250–550, Minimum * protective shade: 11\n",
      "LINE:  Operations: Gas metal arc welding and flux cored arc welding:\n",
      "  - Arc current: Less than 60, Minimum * protective shade: 7\n",
      "  - Arc current: 60–160, Minimum * protective shade: 10\n",
      "  - Arc current: 160–250, Minimum * protective shade: 10\n",
      "  - Arc current: 250–500, Minimum * protective shade: 10\n",
      "LINE:  Operations: Gas Tungsten arc welding:\n",
      "  - Arc current: Less than 50, Minimum * protective shade: 8\n",
      "  - Arc current: 50–150, Minimum * protective shade: 8\n",
      "  - Arc current: 150–500, Minimum * protective shade: 10\n",
      "LINE:  Operations: Air carbon :\n",
      "  - Electrode size 1/32 in: (Light), Arc current: Less than 500, Minimum * protective shade: 10\n",
      "LINE:  Operations: Arc cutting:\n",
      "  - Electrode size 1/32 in: (Heavy), Arc current: 500–1000, Minimum * protective shade: 11\n",
      "LINE:  Operations: Plasma arc welding:\n",
      "  - Arc current: Less than 20, Minimum * protective shade: 6\n",
      "  - Arc current: 20–100, Minimum * protective shade: 8\n",
      "  - Arc current: 100–400, Minimum * protective shade: 10\n",
      "  - Arc current: 400–800, Minimum * protective shade: 11\n",
      "LINE:  Operations: Plasma arc cutting:\n",
      "  - Electrode size 1/32 in: (light)**, Arc current: Less than 300, Minimum * protective shade: 8\n",
      "  - Electrode size 1/32 in: (medium)**, Arc current: 300–400, Minimum * protective shade: 9\n",
      "  - Electrode size 1/32 in: (heavy)**, Arc current: 400–800, Minimum * protective shade: 10\n",
      "LINE:  Operations: Torch brazing:\n",
      "  - Minimum * protective shade: 3\n",
      "LINE:  Operations: Torch soldering:\n",
      "  - Minimum * protective shade: 2\n",
      "LINE:  Operations: Carbon arc welding:\n",
      "  - Minimum * protective shade: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TABLES_PATH = '/notebooks/tablesGPTformat'\n",
    "# Read the contents of the text file\n",
    "with open(TABLES_PATH+'/table6.txt', 'r') as file:\n",
    "    formatted_docs_gpt = file.read()\n",
    "\n",
    "# Split the data into lines\n",
    "chunks = formatted_docs_gpt.split('\\n\\n')\n",
    "\n",
    "# Remove any empty lines\n",
    "lines = [line for line in lines if line.strip()]\n",
    "for line in lines:\n",
    "    print('LINE: ',line)\n",
    "# # Split the lines into chunks, assuming each chunk starts with a header\n",
    "# chunks = []\n",
    "# chunk = []\n",
    "# for line in lines:\n",
    "#     chunk.append(line)\n",
    "\n",
    "# # Add the last chunk if it's not empty\n",
    "# if chunk:\n",
    "#     chunks.append(chunk)\n",
    "\n",
    "# # Print the chunks\n",
    "# for i, chunk in enumerate(chunks):\n",
    "#     print(f'Chunk {i+1}:')\n",
    "#     for line in chunk:\n",
    "#         print(line)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gas Welding:\\n  - Plate Thickness: Light\\n    - Inches: Under 1/8\\n    - Millimeters: Under 3.2\\n    - Minimum Protective Shade: 4\\n  - Plate Thickness: Medium\\n    - Inches: 1/8 to ½\\n    - Millimeters: 3.2 to 12.7\\n    - Minimum Protective Shade: 5\\n  - Plate Thickness: Heavy\\n    - Inches: Over ½\\n    - Millimeters: Over 12.7\\n    - Minimum Protective Shade: 6\\n\\nOxygen Cutting:\\n  - Plate Thickness: Light\\n    - Inches: Under 1\\n    - Millimeters: Under 25\\n    - Minimum Protective Shade: 3\\n  - Plate Thickness: Medium\\n    - Inches: 1 to 6\\n    - Millimeters: 25 to 150\\n    - Minimum Protective Shade: 4\\n  - Plate Thickness: Heavy\\n    - Inches: Over 6\\n    - Millimeters: Over 150\\n    - Minimum Protective Shade: 5\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [chunk[0] for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum token length in the list is: 9\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of tokens for each content\n",
    "token_lengths = len(tokenizer_dragon.encode('''Carbon arc welding:\n",
    "  - Protective shade: 14\n",
    "''', add_special_tokens=False))\n",
    "\n",
    "print(f\"The minimum token length in the list is: {token_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n",
      "Top scores: [(3, 385.5513916015625), (4, 383.090087890625), (0, 381.81585693359375), (1, 381.6806945800781), (2, 381.0158386230469), (7, 375.2063903808594), (6, 370.4612121582031), (5, 369.9852600097656)]\n",
      "Top Docs:\n",
      " Plasma arc welding:\n",
      "- Arc current: Less than 20, Protective shade: 6\n",
      "  - Arc current: 20–100, Protective shade: 8\n",
      "  - Arc current: 100–400, Protective shade: 10\n",
      "  - Arc current: 400–800, Protective shade: 11\n",
      "\n",
      "---\n",
      "\n",
      "Plasma arc cutting:\n",
      "- Arc current: Less than 300 (light), Protective shade: 8\n",
      "  - Arc current: 300–400 (medium), Protective shade: 9\n",
      "  - Arc current: 400–800 (heavy), Protective shade: 10\n",
      "\n",
      "---\n",
      "\n",
      "Shielded metal arc welding:\n",
      "- Electrode size 1/32 in:\n",
      "    - Arc current: Less than 60, Protective shade: 7\n",
      "    - Arc current: 60–160, Protective shade: 8\n",
      "    - Arc current: 160–250, Protective shade: 10\n",
      "    - Arc current: 250–550, Protective shade: 11\n"
     ]
    }
   ],
   "source": [
    "formatted_docs, top, selected_docs = retrieve_docs(query=query, contexts=chunks, k=3)\n",
    "\n",
    "print(\"Top scores:\", top)\n",
    "print(\"Top Docs:\\n\", formatted_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mTable retriever :\n",
      "\u001b[0m\n",
      "Loading RAG\n",
      "RAG Done\n",
      "The prompt length is: 473\n",
      "For Plasma Arc Welding with an arc current of 300 amps, a protective shade of **9** is recommended. \n",
      "\n",
      "---\n",
      "Source: Plasma arc cutting:\n",
      "- Arc current: 300–400 (medium), Protective shade: 9 \n",
      "<end_of_turn>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "printt('Table retriever :\\n')\n",
    "formatted_docs_retreived, top, selected_docs = retrieve_docs(query=query, contexts=chunks, k=3)\n",
    "results = get_completion(query, formatted_docs=formatted_docs_retreived, model = model , tokenizer = tokenizer)\n",
    "\n",
    "# printt('GPT data format : \\n')\n",
    "# results = get_completion(query, formatted_docs=formatted_docs_gpt, model = model , tokenizer = tokenizer)\n",
    "\n",
    "# printt('CSV data format : \\n')\n",
    "# results = get_completion(query, formatted_docs=formatted_docs_csv, model = model , tokenizer = tokenizer)\n",
    "\n",
    "# #My workers are currently sanding wood surfaces, should they wear any kind of eye protection ?\n",
    "# results = get_completion(query='My workers are currently sanding wood surfaces, should they wear any kind of eye protection ?', model = model , tokenizer = tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    The provided text states that for Gas Welding, a plate thickness of over ½ inch requires a minimum protective shade of 6.  \\n\\nSource: Gas Welding: Heavy - Inches: Over ½ - Minimum Protective Shade: 6\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.split('model\\n')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://01f30c2956d52d80ef.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://01f30c2956d52d80ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the main function\n",
    "def gen_tab(query, k=2, contexts=chunks, model=model, tokenizer=tokenizer):\n",
    "    print(contexts)\n",
    "    formatted_docs_retreived, top, selected_docs = retrieve_docs(query, contexts, k)\n",
    "    results = get_completion(query, formatted_docs_retreived, model, tokenizer)\n",
    "    return results.split('model\\n')[-1]\n",
    "\n",
    "# Define the flag function\n",
    "def flag_example(query, k, comment):\n",
    "    # Save the flagged example (query, k, comment) as needed\n",
    "    with open(\"flagged_examples.txt\", \"a\") as file:\n",
    "        file.write(f\"Query: {query}, k: {k}, Comment: {comment}\\n\")\n",
    "    return \"Flagged successfully!\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "demo = gr.Interface(\n",
    "    title='OSHA-KSA ChatBot TABLE ONLY + RETREIVER',\n",
    "    fn=gen_tab,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Query\"),\n",
    "        gr.Slider(1,10, value=3, label=\"k Value\"),\n",
    "        # gr.Textbox(label=\"Comment\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    cache_examples=True,\n",
    "    allow_flagging=\"manual\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Arc current: Less than 300 (light), Protective shade: 8<eos>\n"
     ]
    }
   ],
   "source": [
    "# Your tokenizer settings\n",
    "tokenizer_settings = {\n",
    "    \"padding\": True,\n",
    "    \"truncation\": True,\n",
    "    \"max_length\": 512,  # Adjust max length based on your context needs\n",
    "}\n",
    "\n",
    "# Text to encode\n",
    "text = '''Arc current: Less than 300 (light), Protective shade: 8'''\n",
    "\n",
    "# Encoding the text\n",
    "encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True, **tokenizer_settings)\n",
    "\n",
    "# Decoding the tokens\n",
    "decoded_text = tokenizer.decode(encodeds['input_ids'][0])\n",
    "\n",
    "print(decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT : \n",
      "     \n",
      "For gas welding, the minimum protective filter lens shade is **5**. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BOT :', results.split('model')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agnetic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**old prompts**:\n",
    "    -     prompt_template_1 = \"\"\"\n",
    "    System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual.This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.Read the The csv table and extract the key words from the query that corresponds.\n",
    "    Context:\n",
    "    {relevance_prompt}\n",
    "\n",
    "    Please provide a full and complete answer to the question.\n",
    "    <start_of_turn>user\n",
    "    {query}\n",
    "    <end_of_turn>\\n<start_of_turn>model\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "def get_completion_agentic(query: str, formatted_docs: str, model, tokenizer, relevance=True, COT_INSTRUCTION=''):\n",
    "    device = \"cuda:0\"  # Specifies using the first CUDA-capable GPU\n",
    "\n",
    "    if relevance:  # User wrote a relevant quote\n",
    "        relevance_prompt = f'''CONTEXT : {formatted_docs}\n",
    "        '''\n",
    "    else:\n",
    "        relevance_prompt = ''\n",
    "\n",
    "    prompt_template_1 = \"\"\"\n",
    "    System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\n",
    "\n",
    "    Context:\n",
    "    {relevance_prompt}\n",
    "\n",
    "    <start_of_turn>user\n",
    "    QUESTION: {query}\n",
    "    Please refer to the specific chunk sources for each piece of information and perform any necessary calculations based on the provided data.\n",
    "    <end_of_turn>\n",
    "    <start_of_turn>model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template_2 = \"\"\"\n",
    "    System: You are an AI assistant and an expert in interpreting and analyzing table data. You will review the initial response for accuracy and completeness based on the Occupational Safety and Health Handbook of KSA. After reviewing, finalize the response to ensure it is concise, clear, and directly addresses the user's query.\n",
    "\n",
    "    Ensure that the response meets the following criteria:\n",
    "    1. **Accuracy**: The response must be correct and based on the provided context, especially with regard to the data in tables. Start with a general overview and drill down into the details to ensure all interpretations and calculations are correct. Match the key words from the chunks and query, and ensure the correct field of information extraction is chosen.\n",
    "    2. **Completeness**: The response should fully answer the query without omitting important details.\n",
    "    3. **Correction**: If any errors or inaccuracies are found in the initial response, correct them and provide the accurate information.\n",
    "    4. **Conciseness**: The final response should be free of unnecessary details and to the point.\n",
    "    5. **Clarity**: Ensure the final response is easy to understand and directly addresses the query.\n",
    "        \n",
    "    Query:\n",
    "    {query}\n",
    "\n",
    "    Context:\n",
    "    {formatted_docs}\n",
    "\n",
    "    <start_of_turn>user\n",
    "    {initial_response}\n",
    "    <end_of_turn>\n",
    "    <start_of_turn>model\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#     prompt_template_3 = \"\"\"\n",
    "# System: You are an AI assistant finalizing the response to ensure it is concise and clearly answers the user's query based on the Occupational Safety and Health Handbook of KSA.\n",
    "# Make sure the response is:\n",
    "# - **Concise**: Free of unnecessary details and to the point.\n",
    "# - **Clear**: Easy to understand and directly addressing the query.\n",
    "# - **Corrected**: Ensure all information provided is accurate and any errors from the initial response have been corrected.\n",
    "# - **Well-Structured**: Ensure the final response is well-structured and flows logically.\n",
    "\n",
    "# User Query:\n",
    "# {query}\n",
    "\n",
    "# <start_of_turn>user\n",
    "# {reviewed_response}\n",
    "# <end_of_turn>\\n<start_of_turn>model\n",
    "# \"\"\"\n",
    "\n",
    "    # Initial response with Model 1\n",
    "    prompt_1 = prompt_template_1.format(query=query, relevance_prompt=relevance_prompt)\n",
    "    tokenizer_settings = {\n",
    "        \"padding\": True,\n",
    "        \"truncation\": True,\n",
    "        \"max_length\": 1024,  # Adjust max length based on your context needs\n",
    "    }\n",
    "\n",
    "    printt(f\"Initial Response: \")\n",
    "    encodeds_1 = tokenizer(prompt_1, return_tensors=\"pt\", add_special_tokens=True, **tokenizer_settings).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_ids_1 = model.generate(input_ids=encodeds_1['input_ids'], attention_mask=encodeds_1['attention_mask'], max_new_tokens=1024, streamer=TextStreamer(tokenizer, skip_prompt=True), do_sample=False, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "    decoded_response_1 = tokenizer.decode(generated_ids_1[0], skip_special_tokens=True)\n",
    "    print(50*'-',f'''{decoded_response_1.split(\"model\")[-1]}''', 50*'-')\n",
    "    printt(f\"Refined Response: \")\n",
    "    # Refined response with Model 2\n",
    "    prompt_2 = prompt_template_2.format(query=query, initial_response=decoded_response_1, formatted_docs=formatted_docs, COT_INSTRUCTION=COT_INSTRUCTION)\n",
    "    encodeds_2 = tokenizer(prompt_2, return_tensors=\"pt\", add_special_tokens=True, **tokenizer_settings).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_ids_2 = model.generate(input_ids=encodeds_2['input_ids'], attention_mask=encodeds_2['attention_mask'], max_new_tokens=1024, streamer=TextStreamer(tokenizer, skip_prompt=True), do_sample=False, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "    final_response = tokenizer.decode(generated_ids_2[0], skip_special_tokens=True)\n",
    "    \n",
    "    # printt(f\"Final Response: \", 'green')\n",
    "    # # Final response with Model 3\n",
    "    # prompt_3 = prompt_template_3.format(query=query, reviewed_response=decoded_response_2)\n",
    "    # encodeds_3 = tokenizer(prompt_3, return_tensors=\"pt\", add_special_tokens=True, **tokenizer_settings).to(device)\n",
    "    # with torch.no_grad():\n",
    "    #     generated_ids_3 = model.generate(input_ids=encodeds_3['input_ids'], attention_mask=encodeds_3['attention_mask'], max_new_tokens=1024, streamer=TextStreamer(tokenizer, skip_prompt=True), do_sample=False, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "    # final_response = tokenizer.decode(generated_ids_3[0], skip_special_tokens=True)\n",
    "    \n",
    "\n",
    "    return final_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plasma arc welding:\n",
      "- Arc current: Less than 20, Protective shade: 6\n",
      "  - Arc current: 20–100, Protective shade: 8\n",
      "  - Arc current: 100–400, Protective shade: 10\n",
      "  - Arc current: 400–800, Protective shade: 11\n",
      "Plasma arc cutting:\n",
      "- Arc current: Less than 300 (light), Protective shade: 8\n",
      "  - Arc current: 300–400 (medium), Protective shade: 9\n",
      "  - Arc current: 400–800 (heavy), Protective shade: 10\n",
      "Shielded metal arc welding:\n",
      "- Electrode size 1/32 in:\n",
      "    - Arc current: Less than 60, Protective shade: 7\n",
      "    - Arc current: 60–160, Protective shade: 8\n",
      "    - Arc current: 160–250, Protective shade: 10\n",
      "    - Arc current: 250–550, Protective shade: 11\n",
      "Gas metal arc welding and flux cored arc welding:\n",
      "- Arc current: Less than 60, Protective shade: 7\n",
      "  - Arc current: 60–160, Protective shade: 10\n",
      "  - Arc current: 160–250, Protective shade: 10\n",
      "  - Arc current: 250–500, Protective shade: 10\n",
      "Gas Tungsten arc welding:\n",
      "- Arc current: Less than 50, Protective shade: 8\n",
      "  - Arc current: 50–150, Protective shade: 8\n",
      "  - Arc current: 150–500, Protective shade: 10\n",
      "\n",
      "Air carbon (Light):\n",
      "  - Arc current: Less than 500, Protective shade: 10\n",
      "\n",
      "Arc cutting (Heavy):\n",
      "  - Arc current: 500–1000, Protective shade: 11\n",
      "Carbon arc welding:\n",
      "- Protective shade: 14\n"
     ]
    }
   ],
   "source": [
    "print(formatted_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mTable retriever :\n",
      "\u001b[0m\n",
      "Loading RAG\n",
      "RAG Done\n",
      "\u001b[1m\u001b[31mInitial Response: \u001b[0m\n",
      "For Plasma Arc Welding with an arc current of 300 amps, a protective shade of **10** is recommended.\n",
      "\n",
      "**Source:** CONTEXT : \n",
      "**Plasma Arc Welding:**\n",
      "- Arc Current: 100–400, Protective Shade: 10<end_of_turn>\n",
      "<eos>\n",
      "-------------------------------------------------- \n",
      "\n",
      "    For Plasma Arc Welding with an arc current of 300 amps, a protective shade of **10** is recommended.\n",
      "\n",
      "**Source:** CONTEXT : \n",
      "**Plasma Arc Welding:**\n",
      "- Arc Current: 100–400, Protective Shade: 10\n",
      " --------------------------------------------------\n",
      "\u001b[1m\u001b[31mRefined Response: \u001b[0m\n",
      "Shade: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m printt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTable retriever :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m formatted_docs, top, selected_docs \u001b[38;5;241m=\u001b[39m retrieve_docs(query\u001b[38;5;241m=\u001b[39mquery, contexts\u001b[38;5;241m=\u001b[39mchunks, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion_agentic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m**Shielded Metal Arc Welding:**\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m- **Electrode Size 1/32 in:**\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m  - Arc Current: Less than 60, Protective Shade: 7\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m  - Arc Current: 60–160, Protective Shade: 8\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m  - Arc Current: 160–250, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m  - Arc Current: 250–550, Protective Shade: 11\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m**Plasma Arc Welding:**\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m- Arc Current: Less than 20, Protective Shade: 6\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m- Arc Current: 20–100, Protective Shade: 8\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43m- Arc Current: 100–400, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m- Arc Current: 400–800, Protective Shade: 11\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m**Plasma Arc Cutting:**\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;43m- Arc Current: Less than 300 (light), Protective Shade: 8\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m- Arc Current: 300–400 (medium), Protective Shade: 9\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43m- Arc Current: 400–800 (heavy), Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43m**Gas Metal Arc Welding and Flux Cored Arc Welding:**\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43m- Arc Current: Less than 60, Protective Shade: 7\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43m- Arc Current: 60–160, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43m- Arc Current: 160–250, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43m- Arc Current: 250–500, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43m**Gas Tungsten Arc Welding:**\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43m- Arc Current: Less than 50, Protective Shade: 8\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43m- Arc Current: 50–150, Protective Shade: 8\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43m- Arc Current: 150–500, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;43m**Air Carbon (Light):**\u001b[39;49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;43m- Arc Current: Less than 500, Protective Shade: 10\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;43m**Arc Cutting (Heavy):**\u001b[39;49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;43m- Arc Current: 500–1000, Protective Shade: 11\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;43m**Carbon Arc Welding:**\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43m- Protective Shade: 14\u001b[39;49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOT_INSTRUCTION\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOT_INSTRUCTION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# printt('GPT data format : \\n', 'blue')\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# results = get_completion_agentic(query, formatted_docs=formatted_docs_gpt, model = model , tokenizer = tokenizer)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# printt('CSV data format : \\n', 'blue')\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# results = get_completion_agentic(query, formatted_docs=formatted_docs_csv, model = model , tokenizer = tokenizer)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[133], line 82\u001b[0m, in \u001b[0;36mget_completion_agentic\u001b[0;34m(query, formatted_docs, model, tokenizer, relevance, COT_INSTRUCTION)\u001b[0m\n\u001b[1;32m     80\u001b[0m encodeds_2 \u001b[38;5;241m=\u001b[39m tokenizer(prompt_2, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_settings)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 82\u001b[0m     generated_ids_2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencodeds_2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencodeds_2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTextStreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     83\u001b[0m final_response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids_2[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# printt(f\"Final Response: \", 'green')\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# # Final response with Model 3\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# prompt_3 = prompt_template_3.format(query=query, reviewed_response=decoded_response_2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#     generated_ids_3 = model.generate(input_ids=encodeds_3['input_ids'], attention_mask=encodeds_3['attention_mask'], max_new_tokens=1024, streamer=TextStreamer(tokenizer, skip_prompt=True), do_sample=False, pad_token_id=tokenizer.eos_token_id).to(device)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# final_response = tokenizer.decode(generated_ids_3[0], skip_special_tokens=True)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:999\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    996\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 999\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1013\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:847\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    836\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    837\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    838\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    844\u001b[0m         cache_position,\n\u001b[1;32m    845\u001b[0m     )\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 847\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:599\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    590\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    591\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    592\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    602\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma2/modeling_gemma2.py:120\u001b[0m, in \u001b[0;36mGemma2RMSNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    121\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_norm(x\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# Llama does x.to(float16) * w whilst Gemma2 is (x * w).to(float16)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# See https://github.com/huggingface/transformers/pull/29402\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "COT_INSTRUCTION = '### Important: Do not rewrite the context or the prompt. Only focus on refining the initial response provided.'\n",
    "#'Give the two possible responses, then choose one'\n",
    "\n",
    "query = f'''For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?\n",
    "\n",
    "'''\n",
    "printt('Table retriever :\\n', 'blue')\n",
    "formatted_docs, top, selected_docs = retrieve_docs(query=query, contexts=chunks, k=6)\n",
    "results = get_completion_agentic(query, formatted_docs='''\n",
    "**Shielded Metal Arc Welding:**\n",
    "- **Electrode Size 1/32 in:**\n",
    "  - Arc Current: Less than 60, Protective Shade: 7\n",
    "  - Arc Current: 60–160, Protective Shade: 8\n",
    "  - Arc Current: 160–250, Protective Shade: 10\n",
    "  - Arc Current: 250–550, Protective Shade: 11\n",
    "\n",
    "**Plasma Arc Welding:**\n",
    "- Arc Current: Less than 20, Protective Shade: 6\n",
    "- Arc Current: 20–100, Protective Shade: 8\n",
    "- Arc Current: 100–400, Protective Shade: 10\n",
    "- Arc Current: 400–800, Protective Shade: 11\n",
    "\n",
    "**Plasma Arc Cutting:**\n",
    "- Arc Current: Less than 300 (light), Protective Shade: 8\n",
    "- Arc Current: 300–400 (medium), Protective Shade: 9\n",
    "- Arc Current: 400–800 (heavy), Protective Shade: 10\n",
    "\n",
    "**Gas Metal Arc Welding and Flux Cored Arc Welding:**\n",
    "- Arc Current: Less than 60, Protective Shade: 7\n",
    "- Arc Current: 60–160, Protective Shade: 10\n",
    "- Arc Current: 160–250, Protective Shade: 10\n",
    "- Arc Current: 250–500, Protective Shade: 10\n",
    "\n",
    "**Gas Tungsten Arc Welding:**\n",
    "- Arc Current: Less than 50, Protective Shade: 8\n",
    "- Arc Current: 50–150, Protective Shade: 8\n",
    "- Arc Current: 150–500, Protective Shade: 10\n",
    "\n",
    "**Air Carbon (Light):**\n",
    "- Arc Current: Less than 500, Protective Shade: 10\n",
    "\n",
    "**Arc Cutting (Heavy):**\n",
    "- Arc Current: 500–1000, Protective Shade: 11\n",
    "\n",
    "**Carbon Arc Welding:**\n",
    "- Protective Shade: 14\n",
    "''', model = model , tokenizer = tokenizer, COT_INSTRUCTION=COT_INSTRUCTION)\n",
    "\n",
    "# printt('GPT data format : \\n', 'blue')\n",
    "# results = get_completion_agentic(query, formatted_docs=formatted_docs_gpt, model = model , tokenizer = tokenizer)\n",
    "\n",
    "# printt('CSV data format : \\n', 'blue')\n",
    "# results = get_completion_agentic(query, formatted_docs=formatted_docs_csv, model = model , tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    System: You are an AI assistant and an expert in interpreting and analyzing table data. You will review the initial response for accuracy and completeness based on the Occupational Safety and Health Handbook of KSA. After reviewing, finalize the response to ensure it is concise, clear, and directly addresses the user's query.\\n\\n    Ensure that the response meets the following criteria:\\n    1. **Accuracy**: The response must be correct and based on the provided context, especially with regard to the data in tables. Start with a general overview and drill down into the details to ensure all interpretations and calculations are correct. Match the key words from the chunks and query, and ensure the correct field of information extraction is chosen.\\n    2. **Completeness**: The response should fully answer the query without omitting important details.\\n    3. **Correction**: If any errors or inaccuracies are found in the initial response, correct them and provide the accurate information.\\n    4. **Conciseness**: The final response should be free of unnecessary details and to the point.\\n    5. **Clarity**: Ensure the final response is easy to understand and directly addresses the query.\\n        \\n    User Query:\\n    For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?\\n\\n\\n\\n    Context:\\n    Plasma arc welding:\\n- Arc current: Less than 20, Protective shade: 6\\n  - Arc current: 20–100, Protective shade: 8\\n  - Arc current: 100–400, Protective shade: 10\\n  - Arc current: 400–800, Protective shade: 11\\n\\n---\\n\\nPlasma arc cutting:\\n- Arc current: Less than 300 (light), Protective shade: 8\\n  - Arc current: 300–400 (medium), Protective shade: 9\\n  - Arc current: 400–800 (heavy), Protective shade: 10\\n\\n---\\n\\nShielded metal arc welding:\\n- Electrode size 1/32 in:\\n    - Arc current: Less than 60, Protective shade: 7\\n    - Arc current: 60–160, Protective shade: 8\\n    - Arc current: 160–250, Protective shade: 10\\n    - Arc current: 250–550, Protective shade: 11\\n\\n---\\n\\nGas metal arc welding and flux cored arc welding:\\n- Arc current: Less than 60, Protective shade: 7\\n  - Arc current: 60–160, Protective shade: 10\\n  - Arc current: 160–250, Protective shade: 10\\n  - Arc current: 250–500, Protective shade: 10\\n\\n---\\n\\nGas Tungsten arc welding:\\n- Arc current: Less than 50, Protective shade: 8\\n  - Arc current: 50–150, Protective shade: 8\\n  - Arc current: 150–500, Protective shade: 10\\n\\nAir carbon (Light):\\n  - Arc current: Less than 500, Protective shade: 10\\n\\nArc cutting (Heavy):\\n  - Arc current: 500–1000, Protective shade: 11\\n\\n    Initial Response:\\n    user\\n    \\n    System: You are an AI assistant specialized in delivering precise information from the Occupational Safety and Health Handbook of KSA. Your responses should be organized, concise, and contextual. This is a chat between a user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the provided context. The assistant should indicate when the answer cannot be found in the context. If the query isn't related to OSHA, answer it and IGNORE the context. Ensure to provide references to the specific chunk source for each piece of information.\\n\\n    Context:\\n    \\n        Please refer to the specific chunk sources for each piece of information and perform any necessary calculations based on the provided data.\\n        Plasma arc welding:\\n- Arc current: Less than 20, Protective shade: 6\\n  - Arc current: 20–100, Protective shade: 8\\n  - Arc current: 100–400, Protective shade: 10\\n  - Arc current: 400–800, Protective shade: 11\\n\\n---\\n\\nPlasma arc cutting:\\n- Arc current: Less than 300 (light), Protective shade: 8\\n  - Arc current: 300–400 (medium), Protective shade: 9\\n- Arc current: 400–800 (heavy), Protective shade: 10\\n\\n---\\n\\nShielded metal arc welding:\\n- Electrode size 1/32 in:\\n    - Arc current: Less than 60, Protective shade: 7\\n    - Arc current: 60–160, Protective shade: 8\\n    - Arc current: 160–250, Protective shade: 10\\n    - Arc current: 250–550, Protective shade: 11\\n\\n---\\n\\nGas metal arc welding and flux cored arc welding:\\n- Arc current: Less than 60, Protective shade: 7\\n  - Arc current: 60–160, Protective shade: 10\\n  - Arc current: 160–250, Protective shade: 10\\n  - Arc current: 250–500, Protective shade: 10\\n\\n---\\n\\nGas Tungsten arc welding:\\n- Arc current: Less than 50, Protective shade: 8\\n  - Arc current: 50–150, Protective shade: 8\\n  - Arc current: 150–500, Protective shade: 10\\n\\nAir carbon (Light):\\n  - Arc current: Less than 500, Protective shade: 10\\n\\nArc cutting (Heavy):\\n  - Arc current: 500–1000, Protective shade: 11\\n\\n    User Query:\\n    For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?\\n\\n\\n\\n    Initial Response:\\n    For Plasma Arc Welding with an arc current of 300 amps, a protective shade of 10 is recommended. (Plasma arc welding: Arc current: 100–400, Protective shade: 10)\\n\\n    \\n    Final Response:\\n    For Plasma Arc Welding with an arc current of 300 amps, a protective shade of 10 is recommended. (Plasma arc welding: Arc current: 100–400, Protective shade: 10) \\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table REadabilty evaluation Agentic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "Running on public URL: https://b00489434669a73f95.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b00489434669a73f95.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shielded metal arc welding:\\n- Electrode size 1/32 in:\\n    - Arc current: Less than 60, Protective shade: 7\\n    - Arc current: 60–160, Protective shade: 8\\n    - Arc current: 160–250, Protective shade: 10\\n    - Arc current: 250–550, Protective shade: 11', 'Gas metal arc welding and flux cored arc welding:\\n- Arc current: Less than 60, Protective shade: 7\\n  - Arc current: 60–160, Protective shade: 10\\n  - Arc current: 160–250, Protective shade: 10\\n  - Arc current: 250–500, Protective shade: 10', 'Gas Tungsten arc welding:\\n- Arc current: Less than 50, Protective shade: 8\\n  - Arc current: 50–150, Protective shade: 8\\n  - Arc current: 150–500, Protective shade: 10\\n\\nAir carbon (Light):\\n  - Arc current: Less than 500, Protective shade: 10\\n\\nArc cutting (Heavy):\\n  - Arc current: 500–1000, Protective shade: 11', 'Plasma arc welding:\\n- Arc current: Less than 20, Protective shade: 6\\n  - Arc current: 20–100, Protective shade: 8\\n  - Arc current: 100–400, Protective shade: 10\\n  - Arc current: 400–800, Protective shade: 11', 'Plasma arc cutting:\\n- Arc current: Less than 300 (light), Protective shade: 8\\n  - Arc current: 300–400 (medium), Protective shade: 9\\n  - Arc current: 400–800 (heavy), Protective shade: 10', 'Torch brazing:\\n- Protective shade: 3', 'Torch soldering:\\n- Protective shade: 2', 'Carbon arc welding:\\n- Protective shade: 14']\n",
      "Loading RAG\n",
      "RAG Done\n",
      "[(3, 385.5513916015625), (4, 383.090087890625), (0, 381.81585693359375), (1, 381.6806945800781), (2, 381.0158386230469), (7, 375.2063903808594), (6, 370.4612121582031), (5, 369.9852600097656)]\n",
      "\u001b[1m\u001b[31mInitial Response: \u001b[0m\n",
      "For Plasma Arc Welding with an arc current of 300 amps, a protective shade of **9** is recommended. \n",
      "\n",
      "This information is found in the \"Plasma arc cutting\" section of the provided text:\n",
      "\n",
      "*Arc current: 300–400 (medium), Protective shade: 9* \n",
      "<end_of_turn>\n",
      "<eos>\n",
      "\u001b[1m\u001b[31mRefined Response: \u001b[0m\n",
      "–400 (medium), Protective shade: 9*<end_of_turn>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the main function\n",
    "def gen_tab_agentic(query, k=3, contexts=chunks, model=model, tokenizer=tokenizer):\n",
    "    print(contexts)\n",
    "    formatted_docs_retreived, top, selected_docs = retrieve_docs(query, contexts, k)\n",
    "    print(top)\n",
    "    results = get_completion_agentic(query, formatted_docs_retreived, model, tokenizer)\n",
    "    return results.split('model\\n')[-1]\n",
    "\n",
    "# Define the flag function\n",
    "def flag_example(query, k, comment):\n",
    "    # Save the flagged example (query, k, comment) as needed\n",
    "    with open(\"flagged_examples.txt\", \"a\") as file:\n",
    "        file.write(f\"Query: {query}, k: {k}, Comment: {comment}\\n\")\n",
    "    return \"Flagged successfully!\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "demo = gr.Interface(\n",
    "    title='OSHA-KSA ChatBot TABLE ONLY + RETREIVER  AGENTIC',\n",
    "    fn=gen_tab_agentic,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Query\"),\n",
    "        gr.Slider(1,10, value=3, label=\"k Value\"),\n",
    "        # gr.Textbox(label=\"Comment\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    cache_examples=True,\n",
    "    allow_flagging=\"manual\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_llm_generation(query, contexts=data, k=3, model = model , tokenizer = tokenizer):\n",
    "    _, top , selected_docs= retrieve_docs(query=query, contexts=contexts, k=10)\n",
    "    if top != []:\n",
    "        formatted_docs, _, final_selected_docs = reranker(query, contexts=selected_docs, k=3)\n",
    "        results = get_completion(query, formatted_docs=formatted_docs, model = model , tokenizer = tokenizer)\n",
    "        return results.split('model')[-1]\n",
    "    else :\n",
    "        results = get_completion(query, formatted_docs=None,  model = model , tokenizer = tokenizer, relevence= False)\n",
    "        return results.split('model')[-1]\n",
    "    # return get_completion(query, formatted_docs=formatted_docs, model = model , tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_llm_generation_agentic(query, contexts=data, k=3, model = model , tokenizer = tokenizer):\n",
    "    _, top , selected_docs= retrieve_docs(query=query, contexts=contexts, k=10)\n",
    "    if top != []:\n",
    "        formatted_docs, _, final_selected_docs = reranker(query, contexts=selected_docs, k=3)\n",
    "        results = get_completion_agentic(query, formatted_docs=formatted_docs, model = model , tokenizer = tokenizer)\n",
    "        return results.split('model')[-1]\n",
    "    else :\n",
    "        results = get_completion_agentic(query, formatted_docs=None,  model = model , tokenizer = tokenizer, relevence= False)\n",
    "        return results.split('model')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "\u001b[1m\u001b[31mInitial Response: \u001b[0m\n",
      "The purpose of eye and face protection is to protect against hazards such as:\n",
      "\n",
      "* **Flying objects:**  This could include particles, chips, and sparks.\n",
      "* **Chemicals:** Splashes and fumes can cause serious eye and skin damage.\n",
      "* **Radiation:** Certain types of radiation, such as ultraviolet (UV) light, can damage the eyes.\n",
      "\n",
      "The specific type of eye and face protection required will depend on the hazards present in the workplace.\n",
      "\n",
      "**Source:** This information is based on general knowledge of workplace safety practices and is not directly sourced from a specific chunk of text. \n",
      "<end_of_turn>\n",
      "<eos>\n",
      "\u001b[1m\u001b[31mRefined Response: \u001b[0m\n",
      "According to the Occupational Safety and Health Handbook of KSA, eye and face protection is crucial for safeguarding against workplace hazards that can cause injuries to the eyes and face. \n",
      "\n",
      "These hazards include:\n",
      "\n",
      "* **Flying objects:** Such as particles, chips, and sparks.\n",
      "* **Chemicals:** Splashes and fumes.\n",
      "* **Radiation:** Including ultraviolet (UV) light.\n",
      "\n",
      "The specific type of eye and face protection needed depends on the particular hazards present in the work environment.\n",
      "\n",
      " **Please note:** I do not have access to the content of the Occupational Safety and Health Handbook of KSA to provide specific references. \n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "<eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    According to the Occupational Safety and Health Handbook of KSA, eye and face protection is crucial for safeguarding against workplace hazards that can cause injuries to the eyes and face. \\n\\nThese hazards include:\\n\\n* **Flying objects:** Such as particles, chips, and sparks.\\n* **Chemicals:** Splashes and fumes.\\n* **Radiation:** Including ultraviolet (UV) light.\\n\\nThe specific type of eye and face protection needed depends on the particular hazards present in the work environment.\\n\\n **Please note:** I do not have access to the content of the Occupational Safety and Health Handbook of KSA to provide specific references. \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_llm_generation_agentic('What is the purpose of eye and face protection according to the OSH handbook?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://dcdef380ffc6b015b9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dcdef380ffc6b015b9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "PPE, including eye and face protection, is provided and maintained to protect workers from hazards that could cause injury or impairment.  These hazards can include chemicals, radiation, mechanical irritants, and anything capable of causing injury through absorption, inhalation, or physical contact. (Application, 1) \n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "According to the provided text, the employer is responsible for ensuring the adequacy of employee-owned protective equipment, including proper maintenance and sanitation. (Source: Chunk 1) \n",
      "\n",
      "\n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "\n",
      "\n",
      "Employers shall provide a program for maintaining and caring for respirators, including cleaning, disinfecting, inspecting, repairing, and storing them properly. \n",
      "\n",
      "**Here are some key points from the OSH handbook:**\n",
      "\n",
      "* **Cleaning and Disinfecting:** Respiraors should be cleaned and disinfected following the manufacturer's recommendations or with equivalent procedures proven to be effective. The frequency of cleaning depends on usage: daily for respirators used exclusively by one employee, after each use for respirators used by different individuals, and after each use for emergency use and fit testing. \n",
      "* **Storage:** Respirators should be stored to protect them from damage, contamination, dust, sunlight, extreme temperatures, excessive moisture, and damaging chemicals.\n",
      "\n",
      "Let me know if you'd like more details on any specific aspect of respirator maintenance. \n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "<eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      " According to the OSH handbook, the two main types of respiratory protection are air-purifying respirators (APR) and atmospheresupplying respirators (ASR). \n",
      "\n",
      "\n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      ". Yes, your employees should wear a helmet.\n",
      "\n",
      "  According to the Occupational Safety and Health Handbook of KSA,  they should wear a helmet that is classified as **Class 1**. \n",
      "\n",
      "This type of helmet is designed to reduce the risk of head injury from falling objects and also offers protection against low-voltage electrical conductors (details found in Saso Guide: Occupational Safety and Health (Safety Helmet) – General Requirements Saso3001). \n",
      "<end_of_turn>\n",
      "<eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      ": Yes, your employees should wear a helmet when working near exposed platinum electrical conductors. \n",
      "\n",
      "    They should wear a Class B helmet, as these are designed to reduce the danger of contact with high-voltage electrical conductors. Information found in  \"types head protection\"  chunk. \n",
      "\n",
      "\n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      " \n",
      "Yes, your employees should wear a helmet designed to reduce electrical shock hazards when working near platinum electrical conductors. \n",
      "\n",
      "Refer to ANSI Z89.1 – Industrial Head Protection and section 2 of the  provided \"types of head protection\" chunk for details on helmet classes. You'll need a Class B or Class C helmet.  This type of helmet is tested to withstand high voltages and offers extra protection against electrical shock. \n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Your workers should wear eye protection when sanding wood surfaces.  \n",
      "\n",
      "    **Source:** (1) **Appropriate eye protection shall be worn performing the following tasks... (v) performing operations generate dust** \n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "\n",
      "\n",
      "For Gas Tungsten Arc Welding with an arc current less than 50 amps, the minimum required protective shade number for filter lenses is **medium** (shade 5). \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      " body armor to be used by armed personnel must comply with the standards of the Saudi Arabian Standards Organization (SASO). \n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn><eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "\n",
      "\n",
      "Yes, your employees should wear a protective helmet when working near exposed low-voltage electrical conductors.  \n",
      "\n",
      "They should wear a **Type 1 Class A** helmet. \n",
      "\n",
      "This type of helmet provides  protection from falling objects and is certified to reduce the danger of contact with low-voltage electrical conductors.  \n",
      "\n",
      "\n",
      "References:\n",
      "* Chunk 2  - Electrical Performance\n",
      "* Chunk 1 - Employer Responsibilities \n",
      "<end_of_turn>\n",
      "<eos>\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Loading RAG\n",
      "RAG Done\n",
      "Yes, your employees should wear a helmet during maintenance work near exposed low-voltage electrical conductors.\n",
      "\n",
      "    They need a **Class 1** helmet, as defined in ANSI Z89.1. These helmets are designed to reduce the force of impact from falling objects and offer protection from contact with low-voltage electrical conductors.  Details can be found in the ANSI Z89.1 standard. \n",
      "<end_of_turn><eos>\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    title='OSHA-KSA ChatBot',\n",
    "    show_progress = 'full',\n",
    "\n",
    "    fn=full_llm_generation,\n",
    "    inputs=[\"text\"],\n",
    "    outputs=[\"text\"],\n",
    "    cache_examples =True\n",
    "    \n",
    "    # live=True\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def full_llm_generation(query, contexts=data, k=3, model=model, tokenizer=tokenizer):\n",
    "    _, top, selected_docs = retrieve_docs(query=query, contexts=contexts, k=10)\n",
    "    if top != []:\n",
    "        formatted_docs, _, final_selected_docs = reranker(query, contexts=selected_docs, k=3)\n",
    "        results = get_completion(query, formatted_docs=formatted_docs, model=model, tokenizer=tokenizer)\n",
    "        return results.split('model')[-1]\n",
    "    else:\n",
    "        results = get_completion(query, formatted_docs=None, model=model, tokenizer=tokenizer, relevence=False)\n",
    "        return results.split('model')[-1]\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "def generate_response(request: QueryRequest):\n",
    "    try:\n",
    "        result = full_llm_generation(request.query)\n",
    "        return {\"result\": result}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb1f7190a90>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:497\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py:395\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:1289\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1289\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:1048\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1048\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m \n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:986\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py:243\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py:218\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fb1f7190a90>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb1f7190a90>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://127.0.0.1:8000/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_query_here\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb1f7190a90>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:8000/generate\", json={\"query\": \"your_query_here\"})\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.9.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.9 (from langchain-community)\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.23 (from langchain-community)\n",
      "  Downloading langchain_core-0.2.27-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
      "  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.9->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.8.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.23->langchain-community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.27-py3-none-any.whl (379 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.8/379.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, mypy-extensions, marshmallow, jsonpatch, typing-inspect, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 2.21.0\n",
      "    Uninstalling marshmallow-2.21.0:\n",
      "      Successfully uninstalled marshmallow-2.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\n",
      "gradient 2.0.6 requires marshmallow<3.0, but you have marshmallow 3.21.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 jsonpatch-1.33 langchain-0.2.12 langchain-community-0.2.10 langchain-core-0.2.27 langchain-text-splitters-0.2.2 langsmith-0.1.96 marshmallow-3.21.3 mypy-extensions-1.0.0 tenacity-8.5.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.27)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain) (2020.6.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n",
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.43.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.1.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.16.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.11.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.85.tar.gz (49.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (1.26.3)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.4)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.85-cp311-cp311-linux_x86_64.whl size=2850123 sha256=e4be42d0625cb7293fe419bf8a570521ad8a5467700cc199a7a42fff1e5fa554\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/49/90/42743b59290803ffaf9f60b8439239225e181ae2faaa83640c\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.85\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7896\n",
      "Running on public URL: https://b95523d525fa809d54.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b95523d525fa809d54.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  write me a apragraph about ML\n",
      " \n",
      "Let's \n",
      "say \n",
      "you \n",
      "have \n",
      "a \n",
      "list \n",
      "of \n",
      "\n",
      "words. \n",
      "You \n",
      "want \n",
      "to \n",
      "find \n",
      "the \n",
      "word \n",
      "that \n",
      "is \n",
      "most \n",
      "likely \n",
      "to \n",
      "be \n",
      "in \n",
      "the \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "do \n",
      "this \n",
      "by \n",
      "using \n",
      "a \n",
      "\n",
      "dictionary. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You \n",
      "can \n",
      "use \n",
      "a \n",
      "dictionary \n",
      "to \n",
      "find \n",
      "the \n",
      "most \n",
      "likely \n",
      "word \n",
      "in \n",
      "a \n",
      "\n",
      "list. \n",
      "You\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from typing import Optional\n",
    "from transformers import TextIteratorStreamer\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    streamer: Optional[TextIteratorStreamer] = None\n",
    "\n",
    "    def _call(self, prompt, stop=None, run_manager=None) -> str:\n",
    "        self.streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, Timeout=5)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        kwargs = dict(input_ids=inputs[\"input_ids\"], streamer=self.streamer, max_new_tokens=200)\n",
    "        thread = Thread(target=model.generate, kwargs=kwargs)\n",
    "        thread.start()\n",
    "        return \"\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    llm = CustomLLM()\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        print(\"Question: \", history[-1][0])\n",
    "        llm_chain.run(question=history[-1][0])\n",
    "        history[-1][1] = \"\"\n",
    "        for character in llm.streamer:\n",
    "            print(character)\n",
    "            history[-1][1] += character\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(bot, chatbot, chatbot)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_llm_generation(query, contexts=data, k=3, model = model , tokenizer = tokenizer):\n",
    "    _, top , selected_docs= retrieve_docs(query=query, contexts=contexts, k=10)\n",
    "    if top != []:\n",
    "        formatted_docs, _, final_selected_docs = reranker(query, contexts=selected_docs, k=3)\n",
    "        results = get_completion(query, formatted_docs=formatted_docs, model = model , tokenizer = tokenizer)\n",
    "        return 'BOT : \\n' + results.split('\\nmodel')[-1]\n",
    "    else :\n",
    "        results = get_completion(query, formatted_docs=None,  model = model , tokenizer = tokenizer, relevence= False)\n",
    "        return 'BOT : \\n' + results.split('\\nmodel')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  TextStreamer\n",
    "\n",
    "        \n",
    "def get_completion(query: str, formatted_docs: str, model, tokenizer, relevence= True):\n",
    "\n",
    "    device = \"cuda:0\"  # Specifies using the first CUDA-capable GPU\n",
    "\n",
    "    if relevence: # user wrote a relevent quote\n",
    "        relvence_prompt = f'''\n",
    "        Ensure to provide references to the specific chunk source for each piece of information and make calculations if needed.\n",
    "        Here are the 3 chunks:\n",
    "        {formatted_docs}\n",
    "        '''\n",
    "    else:\n",
    "        relvence_prompt = ''\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    System: You are an AI assistant specialized in providing accurate information from the Occupational Safety and Health Handbook of KSA.\n",
    "    Your responses should be organized, concise, and in your own words in no more than 128 tokens. DO NOT ANSWER MORE THAN YOU ARE REQUESTED.\n",
    "    {relvence_prompt}\n",
    "    \n",
    "    <start_of_turn>user\n",
    "    Below is an instruction that describes a task. Write a clear and concise response answering specifically the user's need:\n",
    "    {query}\n",
    "    <end_of_turn>\\n<start_of_turn>model\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(query=query, relvence_prompt=relvence_prompt)\n",
    "    tokenizer_settings = {\n",
    "        \"padding\": True,\n",
    "        \"truncation\": True,\n",
    "        \"max_length\": 512,  # Adjust max length based on your context needs\n",
    "        \"return_tensors\": \"pt\"\n",
    "    }\n",
    "    encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)  # Tokenizes the prompt\n",
    "    model_inputs = encodeds.to(device)  # Moves the tokenized inputs to the GPU\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "    # Generates a sequence of tokens from the model\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=250, streamer=streamer, do_sample=True, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "            \n",
    "    decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)  # Decodes the generated tokens to text\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from typing import Optional\n",
    "from transformers import TextIteratorStreamer\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    streamer: Optional[TextIteratorStreamer] = None\n",
    "\n",
    "    def _call(self, prompt, stop=None, run_manager=None) -> str:\n",
    "        self.streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, Timeout=5)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        kwargs = dict(input_ids=inputs[\"input_ids\"], streamer=self.streamer, max_new_tokens=200)\n",
    "        thread = Thread(target=model.generate, kwargs=kwargs)\n",
    "        thread.start()\n",
    "        return \"\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    llm = CustomLLM()\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        print(\"Question: \", history[-1][0])\n",
    "        llm_chain.run(query=history[-1][0])\n",
    "        history[-1][1] = \"\"\n",
    "        for character in llm.streamer:\n",
    "            print(character)\n",
    "            history[-1][1] += character\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(bot, chatbot, chatbot)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7899\n",
      "Running on public URL: https://1b457cd2c5381a0737.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1b457cd2c5381a0737.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:  hello\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hello\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hello\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hello\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hello\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hello\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that\n",
      "user:  hi\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "hi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that\n",
      "user:  wrtie a peom\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wrtie \n",
      "a \n",
      "\n",
      "peom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wrtie \n",
      "a \n",
      "\n",
      "peom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wrtie \n",
      "a \n",
      "\n",
      "peom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>user\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wrtie \n",
      "a \n",
      "\n",
      "peom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<start_of_turn>model\n",
      "\n",
      "\n",
      "Below \n",
      "is \n",
      "an \n",
      "instruction \n",
      "that \n",
      "describes \n",
      "a \n",
      "\n",
      "task. \n",
      "Write \n",
      "a \n",
      "clear \n",
      "and \n",
      "concise \n",
      "response \n",
      "answering \n",
      "specifically \n",
      "the \n",
      "user's \n",
      "\n",
      "need:\n",
      "\n",
      "\n",
      "\n",
      "wrt\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from typing import Optional\n",
    "from transformers import TextIteratorStreamer\n",
    "# {relevance_prompt}\n",
    "\n",
    "# Define the prompt template for relevance\n",
    "relevance_prompt_template = \"\"\"\n",
    "System: You are an AI assistant specialized in providing accurate information from the Occupational Safety and Health Handbook of KSA.\n",
    "Your responses should be organized, concise, and in your own words in no more than 128 tokens. DO NOT ANSWER MORE THAN YOU ARE REQUESTED.\n",
    "\n",
    "\n",
    "<start_of_turn>user\n",
    "Below is an instruction that describes a task. Write a clear and concise response answering specifically the user's need:\n",
    "{query}\n",
    "<end_of_turn>\\n<start_of_turn>model\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(template=relevance_prompt_template, input_variables=[\"query\"])\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    streamer: Optional[TextIteratorStreamer] = None\n",
    "\n",
    "    def _call(self, prompt, stop=None, run_manager=None) -> str:\n",
    "        self.streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, Timeout=5)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        kwargs = dict(input_ids=inputs[\"input_ids\"], streamer=self.streamer, max_new_tokens=200)\n",
    "        thread = Thread(target=model.generate, kwargs=kwargs)\n",
    "        thread.start()\n",
    "        return \"\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    llm = CustomLLM()\n",
    "    llm_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    "\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        print(\"user: \", history[-1][0])\n",
    "        llm_chain.run(query=history[-1][0])\n",
    "        history[-1][1] = \"\"\n",
    "        for character in llm.streamer:\n",
    "            print(character)\n",
    "            history[-1][1] += character\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(bot, chatbot, chatbot)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CHATQA8B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279d9f37b1ac4264b835564b60c68805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec64f955fb3d423d9e8b555c59b18f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00015.safetensors:   0%|          | 0.00/9.72G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer\n\u001b[1;32m      5\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia/Llama3-ChatQA-1.5-70B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model_ChatQA \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, quantization_config=bnb_config , device_map=\"auto\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tokenizer_ChatQA \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, add_eos_token \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3681\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3678\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3680\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3681\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3690\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3692\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3694\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3697\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3698\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3699\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3700\u001b[0m ):\n\u001b[1;32m   3701\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:1079\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 936\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    877\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 879\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    811\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 814\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer\n",
    "\n",
    "\n",
    "\n",
    "# Define the local cache directory\n",
    "cache_dir = './my_local_cache'\n",
    "\n",
    "model_id = \"nvidia/Llama3-ChatQA-1.5-70B\"\n",
    "\n",
    "# Load the model and tokenizer, specifying the cache directory\n",
    "model_ChatQA = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, cache_dir=cache_dir)\n",
    "tokenizer_ChatQA = AutoTokenizer.from_pretrained(model_id, add_eos_token=True, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAG\n",
      "RAG Done\n",
      "Top scores: [(56, 375.39276123046875), (54, 375.22943115234375), (51, 375.0307922363281), (61, 374.26171875), (52, 373.6058349609375), (58, 373.4103088378906), (59, 373.2324523925781), (69, 373.1734619140625), (55, 372.695068359375), (46, 372.27685546875), (71, 372.1029968261719), (49, 371.8247375488281), (43, 371.25970458984375), (60, 370.9649658203125), (72, 370.4818420410156), (53, 370.4784240722656), (63, 369.8695373535156), (62, 369.8118896484375), (73, 369.53216552734375), (0, 369.4805908203125), (40, 369.22491455078125), (48, 369.21099853515625), (44, 369.0694274902344), (47, 368.8979187011719), (4, 368.75433349609375)]\n",
      "Top Docs: and parts manipulation necessitate unusually high finger dexterity. ( b ) if the voltage does not exceed 250 volts, ac, or 375 volts, dc, protector gloves need not be used with class 00 gloves, under limited - use conditions, when small equipment and parts manipulation necessitate unusually high finger dexterity. ( c ) any other class of glove may be used without protector gloves, under limited - use conditions, when small equipment and parts manipulation necessitate unusually high finger dexterity but only if the employer can demonstrate that the possibility of physical damage to the gloves is small and if the class of glove is one class higher than that required for the voltage involved. ( d ) insulating gloves that have been used without protector gloves may not be reused until they have been tested under the provisions of paragraphs ( c ) ( 2 ) ( viii ) and ( c ) ( 2 ) ( ix ) of this section. ( viii ) electrical protective equipment shall be subjected to periodic electrical tests. test voltages and the maximum intervals between tests shall be in accordance with table 11 and table 12. ( ix ) the test method used under paragraphs ( c ) ( 2 ) ( viii ) and ( c ) ( 2 ) ( xi ) of this section shall reliably indicate whether the insulating equipment can withstand the voltages involved. details on test methods can be found in : astm d120 – 09, astm d178 – 01 ( 2010 ), astm d1048 – 12, astm d1049 – 98 ( 2010 ), astm d1050 – 05 ( 2011 ), astm d1051 – 08, astm f478 – 09, astm f479 – 06 ( 2011 ), astm f496 – 08. ( x ) insulating equipment failing to pass inspections or electrical tests may not be used by employees, except as follows : ( a ) rubber insulating line hose may be used in shorter lengths with the defective portion cut off. ( b ) rubber insulating blankets may be salvaged by severing the defective area from the undamaged portion of the blanket. the resulting undamaged area may not be smaller than 560 millimeters by 560 millimeters ( 22 inches by 22 inches ) for class 1, 2, 3, and 4 blankets. ( c ) rubber insulating blankets may be repaired using a compatible patch that results in physical and electrical properties equal to those of the\n",
      "\n",
      "---\n",
      "\n",
      "design requirements for other types of electrical protective equipment. the following requirements apply to the design and manufacture of electrical protective equipment that is not covered by paragraph ( a ) of this section : ( 1 ) voltage withstands : insulating equipment used for the protection of employees shall be capable of withstanding, without failure, the voltages that may be imposed upon it. ( 2 ) equipment current : ( i ) protective equipment used for the primary insulation of employees from energized circuit parts shall be capable of passing a current test when subjected to the highest nominal voltage on which the equipment is to be used. ( ii ) when insulating equipment is tested in accordance with paragraph ( b ) ( 2 ) ( i ) of this section, the equipment current may not exceed 1 microampere per kilovolt of phase - to - phase applied voltage.\n",
      "\n",
      "---\n",
      "\n",
      "design requirements for specific types of electrical protective equipment. rubber insulating blankets, rubber insulating matting, rubber insulating covers, rubber insulating line hose, rubber insulating gloves, and rubber insulating sleeves shall meet the following requirements : ( 1 ) the characteristics of protective equipment shall be determined with respect to their function, which may be, e. g., protection against the effects of : ( i ) overcurrent ( overload, short - circuit ) ; ( ii ) earth fault current ; ( iii ) overvoltage ; ( iv ) undervoltage and no - voltage. the protective devices shall operate at values of current, voltage and time, which are suitably related to the characteristics of the circuits and to the possibilities of danger. ( sbc 401 electrical : chapter 12 ; 12 - 2. 8 : protective equipment ). ( 2 ) manufacture and marking of rubber insulating equipment. ( i ) blankets, gloves, and sleeves shall be produced by a seamless process. ( ii ) each item shall be clearly marked as follows : ( a ) class 00 equipment shall be marked class 00. ( b ) class 0 equipment shall be marked class 0. ( c ) class 1 equipment shall be marked class 1. ( d ) class 2 equipment shall be marked class 2. ( e ) class 3 equipment shall be marked class 3. ( f ) class 4 equipment shall be marked class 4. ( g ) nonozone - resistant equipment shall be marked type i. ( h ) ozone - resistant equipment shall be marked type ii. ( i ) other relevant markings, such as the manufacturer's identification and the size of the equipment, may also be provided. ( iii ) markings shall be nonconducting and shall be applied in such a manner as not to impair the insulating qualities of the equipment. ( iv ) markings on gloves shall be confined to the cuff portion of the glove. ( 3 ) electrical requirements. ( i ) equipment shall be capable of withstanding the ac proof - test voltage specified in table 8 or the dc proof - test voltage specified in table 9. ( a ) the proof test shall reliably indicate that the equipment can withstand the voltage involved. ( b ) the test voltage shall be applied continuously for 3 minutes for equipment other than matting and shall be applied continuously for 1 minute for matting. ( c ) gloves shall also be capable of separately withstanding the ac proof - test voltage specified in table\n",
      "\n",
      "---\n",
      "\n",
      "electrical protection : 2 / 5 electrical protection : insulation provided by gloves when in direct contact with live electrical components, classified as follows : voltage ratings : ( 1 ) 1 / 2 / 5 volts : 500 ac - 750 dc ( 2 ) 2 / 2 / 5 volts : 1000 ac - 1500 dc ( 3 ) 3 / 2 / 5 volts : 7500 ac - 11250 dc ( 4 ) 4 / 2 / 5 volts : 17000 ac - 25500 dc ( 5 ) 5 / 2 / 5 volts : 26500 ac - 39500 dc ( 6 ) 6 / 2 / 5 volts : 36000 ac - 54000 dc\n",
      "\n",
      "---\n",
      "\n",
      "shall be capable of withstanding the ac proof - test voltage specified in table 8 or the dc proof - test voltage specified in table 9. ( a ) the proof test shall reliably indicate that the equipment can withstand the voltage involved. ( b ) the test voltage shall be applied continuously for 3 minutes for equipment other than matting and shall be applied continuously for 1 minute for matting. ( c ) gloves shall also be capable of separately withstanding the ac proof - test voltage specified in table 8after a 16 - hour water soak. ( ii ) when the ac proof test is used on gloves, the 60 - hertz proof - test current may not exceed the values specified in table 8 at any time during the test period. ( a ) if the ac proof test is made at a frequency other than 60 hertz, the permissible proof - test current shall be computed from the direct ratio of the frequencies. ( b ) for the test, gloves ( right side out ) shall be filled with tap water and immersed in water to a depth that is in accordance with table 10. water shall be added to or removed from the glove, as necessary, so that the water level is the same inside and outside the glove. ( c ) after the 16 - hour water soak, the 60 - hertz proof - test current may not exceed the values given in table 8by more than 2 milliamperes. ( iii ) equipment that has been subjected to a minimum breakdown voltage test may not be used for electrical protection. ( iv ) material used for type ii insulating equipment shall be capable of withstanding an ozone test, with no visible effects. the ozone test shall reliably indicate that the material will resist ozone exposure in actual use. any visible signs of ozone deterioration of the material, such as checking, cracking, breaks, or pitting, is evidence of failure to meet the requirements for ozone - resistant material. ( 4 ) workmanship and finish ( i ) equipment shall be free of physical irregularities that can adversely affect the insulating properties of the equipment and that can be detected by the tests or inspections required under this section. ( ii ) surface irregularities that may be present on all rubber goods ( because of imperfections on forms or molds or because of inherent difficulties in the manufacturing process ) and that may appear as indentations, protuberances, or imbedded foreign material are acceptable under the following conditions : ( a ) the ind\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from termcolor import colored\n",
    "\n",
    "# Define device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Function to generate responses\n",
    "def retrieve_docs(query, contexts, k=10, instruction=\"Answer the question based on the provided documents\"):\n",
    "    print('Loading RAG')\n",
    "    \n",
    "    # Prepare inputs\n",
    "    query_input = tokenizer_dragon(query, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    ctx_input = tokenizer_dragon(contexts, max_length=200, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Compute embeddings\n",
    "    with torch.no_grad():\n",
    "        query_emb = query_encoder(**query_input).last_hidden_state[:, 0, :].to(device)\n",
    "        ctx_emb = context_encoder(**ctx_input).last_hidden_state[:, 0, :].to(device)\n",
    "    \n",
    "    # Compute similarity scores using dot product\n",
    "    scores = {i: (query_emb @ ctx_emb[i]).item() for i in range(len(ctx_emb))}\n",
    "    print('RAG Done')\n",
    "    \n",
    "    # Sort scores and select top documents\n",
    "    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    top = [(list(sorted_scores)[i][0], list(sorted_scores)[i][1]) for i in range(min(25, len(sorted_scores)))]\n",
    "    \n",
    "\n",
    "   #Top 25 chunks\n",
    "     \n",
    "    selected_docs = [contexts[doc[0]] for doc in top][:k]\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join(selected_docs)\n",
    "    prompt_template = \"\"\"\n",
    "    system\n",
    "    {instruction} :\n",
    "    Provided docs: {top}\n",
    "    {query}\n",
    "    \n",
    "    assistant\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(instruction=instruction, query=query, top=formatted_docs)\n",
    "\n",
    "    return formatted_docs, top\n",
    "\n",
    "\n",
    "query = \"My electric workers work on lines with 10 Amperes and resistance of R=100 Ω minimum, what type of hand protection shall they wear ?\"\n",
    "\n",
    "formatted_docs, top = retrieve_docs(query=query, contexts=data, k=5)\n",
    "\n",
    "print(\"Top scores:\", top)\n",
    "print(\"Top Docs:\", formatted_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ChatQA = model_ChatQA.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_docs = '''\n",
    "{\n",
    "  \"operations\": [\n",
    "    {\n",
    "      \"name\": \"Shielded metal arc welding\",\n",
    "      \"electrode_size\": \"1/32 in\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"Less than 60\", \"protective_shade\": 7},\n",
    "        {\"range\": \"60–160\", \"protective_shade\": 8},\n",
    "        {\"range\": \"160–250\", \"protective_shade\": 10},\n",
    "        {\"range\": \"250–550\", \"protective_shade\": 11}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Gas metal arc welding and flux cored arc welding\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"Less than 60\", \"protective_shade\": 7},\n",
    "        {\"range\": \"60–160\", \"protective_shade\": 10},\n",
    "        {\"range\": \"160–250\", \"protective_shade\": 10},\n",
    "        {\"range\": \"250–500\", \"protective_shade\": 10}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Gas Tungsten arc welding\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"Less than 50\", \"protective_shade\": 8},\n",
    "        {\"range\": \"50–150\", \"protective_shade\": 8},\n",
    "        {\"range\": \"150–500\", \"protective_shade\": 10}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Air carbon (Light)\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"Less than 500\", \"protective_shade\": 10}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Arc cutting (Heavy)\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"500–1000\", \"protective_shade\": 11}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Plasma arc welding\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"Less than 20\", \"protective_shade\": 6},\n",
    "        {\"range\": \"20–100\", \"protective_shade\": 8},\n",
    "        {\"range\": \"100–400\", \"protective_shade\": 10},\n",
    "        {\"range\": \"400–800\", \"protective_shade\": 11}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Plasma arc cutting\",\n",
    "      \"arc_currents\": [\n",
    "        {\"range\": \"Less than 300 (light)\", \"protective_shade\": 8},\n",
    "        {\"range\": \"300–400 (medium)\", \"protective_shade\": 9},\n",
    "        {\"range\": \"400–800 (heavy)\", \"protective_shade\": 10}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Torch brazing\",\n",
    "      \"arc_currents\": [\n",
    "        {\"protective_shade\": 3}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Torch soldering\",\n",
    "      \"arc_currents\": [\n",
    "        {\"protective_shade\": 2}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Carbon arc welding\",\n",
    "      \"arc_currents\": [\n",
    "        {\"protective_shade\": 14}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "'''\n",
    "query ='''\n",
    "For Plasma Arc Welding with an arc current of 300 amps, what protective shade is recommended?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        {\"range\": \"100–500\", \"protective_shade\": 10},\n",
      "        {\"range\": \"500–1000\", \"protective_shade\": 11}\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}  \"operations\": [\n",
      "    {\n",
      "      \"name\": \"Shielded metal arc welding\",\n",
      "      \"electrode_size\": \"1/32 in\",\n",
      "      \"arc_currents\": [\n",
      "        {\"range\": \"Less than 60\", \"protective_shade\": 7},\n",
      "        {\"range\": \"60–160\", \"protective_shade\": 8},\n",
      "        {\"range\": \"160–250\", \"protective_shade\": 10},\n",
      "        {\"range\": \"250–550\", \"protective_shade\": 11}\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Gas metal arc welding and flux cored arc welding\",\n",
      "      \"arc_currents\": [\n",
      "        {\"range\": \"Less than 60\", \"protective_shade\": 7},\n",
      "        {\"range\": \"60–160\", \"protective_shade\": 10},\n",
      "        {\"range\": \"160–250\", \"protective_shade\": 10},\n",
      "        {\"range\": \"250–500\", \"protective_shade\": 10}\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Gas Tungsten arc welding\",\n",
      "      \"arc_currents\": [\n",
      "        {\"range\": \"Less than 50\", \"protective_shade\": 8},\n",
      "        {\"range\": \"50–150\", \"protective_shade\": 8},\n",
      "        {\"range\": \"150–500\", \"protective_shade\": 10}\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Air carbon (Light)\",\n",
      "      \"arc_currents\": [\n",
      "        {\"range\": \"Less than 500\", \"protective_shade\": 10}\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Arc cutting (Heavy)\",\n",
      "      \"arc_currents\": [\n",
      "        {\"range\": \"500–1000\", \"protective_shade\": 11}\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Plasma arc welding\",\n",
      "      \"arc_currents\": [\n",
      "        {\"range\": \"Less than 20\", \"protective_shade\": 6},\n",
      "        {\"range\": \"20–100\", \"protective_shade\": 8},\n",
      "        {\"range\": \"100–500\", \"protective_shade\": 10},\n",
      "        {\"range\": \"500–1000\", \"protect\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import copy \n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]\n",
    "\n",
    "document = formatted_docs\n",
    "\n",
    "def get_formatted_input(messages, context):\n",
    "    messages = copy.deepcopy(messages)\n",
    "    system = \"\"\"System: .You are an AI assistant specialized in providing accurate information from the Occupational Safety and Health Handbook.\n",
    "    Your responses should be organized, concise. Elaborate with bullet points .\n",
    "    Ensure to provide references to the specific chunk source for each piece of information. \n",
    "    If the query is unclear, ask clarifying questions to gather the necessary json context below:\"\"\"\n",
    "    instruction = \"Below is an instruction that describes a task. specify the section that contains the answer , then answer:\"\n",
    "\n",
    "    for item in messages:\n",
    "        if item['role'] == \"user\":\n",
    "            ## only apply this instruction for the first user turn\n",
    "            item['content'] = instruction + \" \" + item['content']\n",
    "            break\n",
    "\n",
    "    conversation = '\\n\\n'.join([\"User: \" + item[\"content\"] if item[\"role\"] == \"user\" else \"Assistant: \" + item[\"content\"] for item in messages]) + \"\\n\\nAssistant:\"\n",
    "    formatted_input = system + \"\\n\\n\" + context + \"\\n\\n\" + conversation\n",
    "    \n",
    "    return formatted_input\n",
    "tokenizer = tokenizer_ChatQA\n",
    "model = model_ChatQA\n",
    "\n",
    "formatted_input = get_formatted_input(messages, document)\n",
    "tokenizer_settings = {\n",
    "        \"padding\": True,\n",
    "        \"truncation\": True,\n",
    "        \"max_length\": 512,  # Adjust max length based on your context needs\n",
    "    }\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenized_prompt = tokenizer(tokenizer.bos_token + formatted_input, return_tensors=\"pt\", **tokenizer_settings).to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=tokenized_prompt.input_ids, attention_mask=tokenized_prompt.attention_mask ,min_new_tokens=64, max_new_tokens=512, eos_token_id=terminators)\n",
    "\n",
    "response = outputs[0][tokenized_prompt.input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_llm_generation_ChatQA (query, contexts=data, k=3, model = model_ChatQA , tokenizer = tokenizer_ChatQA):\n",
    "    formatted_docs, _ = retrieve_docs(query=query, contexts=contexts, k=k)\n",
    "    messages = [\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    document = formatted_docs.replace('/', '//')\n",
    "    print(formatted_docs)\n",
    "    formatted_input = get_formatted_input(messages, document)\n",
    "    tokenizer_settings = {\n",
    "            \"padding\": True,\n",
    "            \"truncation\": True,\n",
    "            \"max_length\": 512,  # Adjust max length based on your context needs\n",
    "            \"return_tensors\": \"pt\"\n",
    "        }\n",
    "    tokenized_prompt = tokenizer(tokenizer.bos_token + formatted_input, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=tokenized_prompt.input_ids, attention_mask=tokenized_prompt.attention_mask,min_new_tokens = 128 , max_new_tokens=512, eos_token_id=terminators)\n",
    "\n",
    "    response = outputs[0][tokenized_prompt.input_ids.shape[-1]:]\n",
    "    response =tokenizer.decode(response, skip_special_tokens=True)\n",
    "    return 'BOT : \\n' + response.split('\\nAssistant')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_llm_generation_ChatQA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfull_llm_generation_ChatQA\u001b[49m(query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMy electric workers work on lines with 10 Amperes and resistance of R=100 Ω minimum, what type of hand protection shall they wear ?\u001b[39m\u001b[38;5;124m'\u001b[39m, contexts\u001b[38;5;241m=\u001b[39mdata, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, model \u001b[38;5;241m=\u001b[39m model_ChatQA , tokenizer \u001b[38;5;241m=\u001b[39m tokenizer_ChatQA) )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_llm_generation_ChatQA' is not defined"
     ]
    }
   ],
   "source": [
    "print(full_llm_generation_ChatQA(query = 'My electric workers work on lines with 10 Amperes and resistance of R=100 Ω minimum, what type of hand protection shall they wear ?', contexts=data, k=4, model = model_ChatQA , tokenizer = tokenizer_ChatQA) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
